[
  
  {
    "title": "acapy/issue/3353: ACA-Py failing to start, gives KeyError: 'pattern'",
    "url": "/github-discussions/acapy/issue/3353/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-11-25 07:25:18 -0800",
    





    
    "snippet": "ACA-py started failing to start in the Interop Test Pipeline over the weekend. This is the error. The pipeline pull from main to build acapy.2024-11-25 15:13:18,787 acapy_agent.core.plugin_registry...",
    "content": "ACA-py started failing to start in the Interop Test Pipeline over the weekend. This is the error. The pipeline pull from main to build acapy.2024-11-25 15:13:18,787 acapy_agent.core.plugin_registry ERROR Module doesn't exist: redis_events.v1_0.redis_queue.events2024-11-25 15:13:19,438 acapy_agent.commands.start ERROR Exception during startup:Traceback (most recent call last):  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/commands/start.py\", line 72, in init    await startup  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/commands/start.py\", line 28, in start_app    await conductor.setup()  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/core/conductor.py\", line 128, in setup    context = await self.context_builder.build_context()              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/config/default_context.py\", line 78, in build_context    await self.load_plugins(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/config/default_context.py\", line 183, in load_plugins    await plugin_registry.init_context(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/core/plugin_registry.py\", line 207, in init_context    await plugin.setup(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/__init__.py\", line 62, in setup    await universal_resolver.setup(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 66, in setup    supported_did_regex = await self._get_supported_did_regex()                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 115, in _get_supported_did_regex    return _compile_supported_did_regex(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 24, in _compile_supported_did_regex    for pattern in patterns                   ^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 116, in &lt;genexpr&gt;    driver[\"http\"][\"pattern\"] for driver in props.values()    ~~~~~~~~~~~~~~^^^^^^^^^^^KeyError: 'pattern'Shutting down"
  },
  
  {
    "title": "identus-mediator/issue/382: Support for subdirectory in SERVICE_ENDPOINTS",
    "url": "/github-discussions/identus-mediator/issue/382/",
    "categories": "W3C",
    "tags": "identus-mediator",
    "date": "2024-11-23 16:04:25 -0800",
    





    
    "snippet": "Sometimes is desirable to run the mediator endpoint in a subdirectory of a webapp to avoid CORS issues, for example, defining SERVICE_ENDPOINTS='https://www.myapp.com/mediator'. If you setup the Pr...",
    "content": "Sometimes is desirable to run the mediator endpoint in a subdirectory of a webapp to avoid CORS issues, for example, defining SERVICE_ENDPOINTS='https://www.myapp.com/mediator'. If you setup the ProxyPass on webserver correctly, when you try to load the endpoint it fails trying to load https://www.myapp.com/public/webapp-fastopt-bundle.js because the mediator server endpoint is assuming the SERVICE_ENDPOINT is not on a subdirectory and on a web root."
  },
  
  {
    "title": "did-extensions/issue/597: SUPER/META PROPOSAL: Authentication of unique DID Method names: allowing for multiple approaches",
    "url": "/github-discussions/did-extensions/issue/597/",
    "categories": "W3C",
    "tags": "did-extensions",
    "date": "2024-11-22 07:09:36 -0800",
    





    
    "snippet": "@msporny proposed restricted approach here: https://github.com/w3c/did-extensions/issues/595In this Super/Meta Proposal, I want to suggest that the DID method registration section in the spec be mo...",
    "content": "@msporny proposed restricted approach here: https://github.com/w3c/did-extensions/issues/595In this Super/Meta Proposal, I want to suggest that the DID method registration section in the spec be modified to support more than one Authentication of unique DID Method names approach that covers the following objectives:  Removes the burden from the reviewers  Removes the W3C from having to arbitrate DID method uniqueness issues  Produces a tangible result in terms of authenticating the uniqueness of new DID Method registration applicationsThe idea is to support, in the specification, more than one trivially easy-to-access Authentication of unique DID Method names  approach - with the goal of giving registrants/controllers at least a couple choices that they can choose from based on time, effort, and cost.  For example, tradmarking is costly especially for registrants who do not have in-house legal council - more cost effective solution(s) are also needed.  The wording of the specification cannot be prejudiced for or against any registrant.  In addition, a DID Method name may not be trademarkable: https://github.com/w3c/did-extensions/issues/595#issuecomment-2494098759So what’s on the table in terms of approaches (in order of strength: effectiveness, cost, time, and effort):  DNS Registration: Leveraging what is already available using Internet Doman Name System (DNS) domain name registration. Examples of such an approach can be found in https://github.com/w3c/did-extensions/issues/590  Registered trademarks per the concepts outlined here: https://github.com/w3c/did-extensions/issues/595  Unregistered trademarks  No authentication of uniqueness supplied in the applicationNOTE: The implication of point 4 is that we add a field to the DID Method Name registration file to specify the registrant’s Authentication of unique DID Method names approach/evidence.  This can be a simple text field with a link to the domain registration, a trademark statement, etc.  An empty or missing field would default to class 4: No authentication of uniqueness provided.  This field can also be used to ajudicate new applications that have or claim to have a stronger authentication.Q: any additional Authentication of unique DID Method names approaches that would be simple in terms of effort, time and cost for the registrant and as well the reviewers and the W3C?Other thoughts?"
  },
  
  {
    "title": "acapy/pr/3344: Restore `--base-wallet-routes` flag functionality",
    "url": "/github-discussions/acapy/pr/3344/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-11-21 10:21:14 -0800",
    





    
    "snippet": "Resolves #3283The tenant_authentication has been updated to also allow access to the base wallet when the route matches a path defined using --base-wallet-routes.Please note that, when compared to ...",
    "content": "Resolves #3283The tenant_authentication has been updated to also allow access to the base wallet when the route matches a path defined using --base-wallet-routes.Please note that, when compared to the previous implementation, the matcher has been made more greedy to tighten security: if an extra route of /test is specified, the matcher will only match that and not /testA or /test-something-else as it appears it would have done before.One drawback of having to use this matcher inside the decorator is that I could not think of an elegant way of caching the compiled pattern for reuse - suggestions on how to achieve that, if desirable/required, will be welcome."
  },
  
  {
    "title": "webauthn/issue/2211: CR: Need a way to detect \"cancel\"",
    "url": "/github-discussions/webauthn/issue/2211/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-21 09:31:50 -0800",
    





    
    "snippet": "Proposed ChangeNeed a way to programmatically detect when the user has cancelled the “Use passkey from another device” browser native prompt by clicking the “Cancel” button. This could be achieved ...",
    "content": "Proposed ChangeNeed a way to programmatically detect when the user has cancelled the “Use passkey from another device” browser native prompt by clicking the “Cancel” button. This could be achieved by adding a new property or event to the prompt that indicates whether the user has cancelled the prompt.^ the “cancel” button there."
  },
  
  {
    "title": "did-extensions/issue/595: Clarify the registration process wrt. trademarks and copyrights",
    "url": "/github-discussions/did-extensions/issue/595/",
    "categories": "W3C",
    "tags": "did-extensions",
    "date": "2024-11-21 08:51:14 -0800",
    





    
    "snippet": "The current specification doesn’t say that in order to block or remove a registration that a /registered/ trademark is required. The language around copyright is also problematic (granting a copyri...",
    "content": "The current specification doesn’t say that in order to block or remove a registration that a /registered/ trademark is required. The language around copyright is also problematic (granting a copyright holder the broad ability to block a registration). The text needs to be updated to remove much of the evaluation burden from the maintainers (by requiring that the trademark owner has the burden of proof). The purpose of this issue is to track this desired clarification."
  },
  
  {
    "title": "webauthn/pr/2209: Add test vectors",
    "url": "/github-discussions/webauthn/pr/2209/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-20 10:38:52 -0800",
    





    
    "snippet": "Closes #1633. Sorry it took so long!The test vectors proposed in #1633 use RP IDs of real websites unaffiliated with W3C, which felt out of place to me, so I chose to generate new ones instead. Als...",
    "content": "Closes #1633. Sorry it took so long!The test vectors proposed in #1633 use RP IDs of real websites unaffiliated with W3C, which felt out of place to me, so I chose to generate new ones instead. Also in order to pre-empt any worry that there could be something nefarious hidden in these values, they are all generated deterministically from disclosed PRNG seeds. Consequently the attestation statements are synthetic values rather than real attestations from the corresponding trusted source, which unfortunately means there’s more room for error, but I think it’s worth it to have the examples self-contained and transparent. I invite library authors to try running their registration and authentication procedures on these examples so that we may work out any inconsistencies.I plan to also share the code used to generate these, but I needed to patch some of the libraries I used, so I need to resolve that first.Preview | Diff"
  },
  
  {
    "title": "identus-cloud-agent/issue/1459:  proof request there's no information on holder ",
    "url": "/github-discussions/identus-cloud-agent/issue/1459/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-20 02:34:25 -0800",
    





    
    "snippet": "Is this a regression?NODescriptionRight know when we have a proof request there’s no information on holder side of what’s being requested.Holder webhook data:PresentationStatusAdapter(presentationI...",
    "content": "Is this a regression?NODescriptionRight know when we have a proof request there’s no information on holder side of what’s being requested.Holder webhook data:PresentationStatusAdapter(presentationId=94acbe0f-ed87-4477-9757-4b4ba8c3461d, thid=d080d2b5-0498-42aa-a829-22cf021ff3cf, role=PROVER, status=REQUEST_RECEIVED, metaRetries=5, proofs=[], data=[], connectionId=null)GET /present-proof/presentations/$presentationId{    “presentationId”: “94acbe0f-ed87-4477-9757-4b4ba8c3461d”,    “thid”: “d080d2b5-0498-42aa-a829-22cf021ff3cf”,    “role”: “Prover”,    “status”: “RequestReceived”,    “proofs”: [],\"data\": [    ],\"requestData\": [    \"{\\n  \\\"options\\\" : {\\n    \\\"domain\\\" : \\\"https://example-verifier.com\\\",\\n    \\\"challenge\\\" : \\\"11c91493-01b3-4c4d-ac36-b336bab5bddf\\\"\\n  },\\n  \\\"presentation_definition\\\" : {\\n    \\\"format\\\" : null,\\n    \\\"name\\\" : null,\\n    \\\"purpose\\\" : null,\\n    \\\"id\\\" : \\\"345b056f-2889-458a-9f59-25d1ab249557\\\",\\n    \\\"input_descriptors\\\" : [\\n    ]\\n  }\\n}\"],\"metaRetries\": 5 }The data is available in the RequestPresentation Attachment but we don’t expose it on the endpoint This will be helpful fro cloud agnet  while testing testPlease provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "acapy/issue/3343: DID Management Proposed Update",
    "url": "/github-discussions/acapy/issue/3343/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-11-19 08:58:08 -0800",
    





    
    "snippet": "In light of our current push to add support for more DID Methods to ACA-Py, some primitives within ACA-Py need some updates. This issue outlines the updates I propose. I plan to update this further...",
    "content": "In light of our current push to add support for more DID Methods to ACA-Py, some primitives within ACA-Py need some updates. This issue outlines the updates I propose. I plan to update this further as the topic is discussed or as implementations better inform decisions.Proposed UpdatesDID Storage (updating DIDInfo)Current StateAt present, the DIDInfo object looks like this:https://github.com/openwallet-foundation/acapy/blob/f5c49b0710dd180ea31c45f73bc82ef06f9523b4/acapy_agent/wallet/did_info.py#L20-L29This is stored in the wallet with a category of did, the primary identifier being the DID value, and the following tags:  method: the method name  verkey: the verkey element of the tuple where it is the base58 encoding of the public key  verkey_type: the key type of the verkey (e.g. ed25519)As currently used, metadata will include:  posted: a boolean value representing whether this did has been published to an indy network  endpoint: a string value representing associated with the endpoint attrib of this did on an indy network.EvaluationAs is plain to see, the structure, tags, and metadata of the DIDInfo object are very Indy-oriented. This structure has been in use for years.Currently, ACA-Py will retrieve a DIDInfo object in order to use the key associated with the “DID.” It will do this by taking a “DID” as input (usually, actually more like a “nym” value, i.e. 16 base58 encoded bytes without a did: prefix), then using the verkey value to retrieve a Key object that it can then use to perform a signature or pack a DIDComm message.SolutionDIDs should have multiple keys associated with them rather than a single key. To achieve this while also having an efficient lookup mechanism, we should reorient our storage as outlined below.Quick background on AskarAskar is a secure storage solution used by ACA-Py. Askar encrypts all data and provides a tagging mechanism to enable lookup of encrypted records. An entry in Askar is composed of the following elements:  Category: The major group or “bucket” that the entry belongs to.  Name: The primary identifier for the record; this is roughly equivalent to primary keys on a traditional DB table. The most efficient lookup possible is by name.  Value: The value stored in the entry. This is usually a serialized JSON object.  Tags: A mapping of strings to strings or lists of strings. These values can be used with the “Wallet Query Language (WQL)” to look up encrypted Askar entries efficiently.Askar has a dedicated API for storage and retrieval of keys. However, this API is conceptually just a shorthand for record storage and retrieval from a “private” key category with the key itself as the value of the entry. Key entries behave almost exactly the same as non-key entries, including names and tags.Key StorageBuilding off of Patrick’s contributions of managing keys by multikey instead of “verkey,” the multikey representation of a key should be the default identifier for keys in the wallet.  Name: multikey representation of the key  Tags:          Implicit tag for the KeyAlg (automatically included on every key)      did: the DID (or a list of DIDs) the key is associated with      vm_id: an absolute DID URL (or a list of DID URLs) representing the verification method ID(s) of the key      rel: A list of verification relationships as defined by the DID Core spec; e.g. [\"authentication\", \"assertionMethod\"]. This represents the intended use of this key.      alias: A human-friendly alias (or list of aliases) that can help identify a key to a user      These sets of tags enable us to look up keys with a combination of did and rel; when these tags are lists, Askar will return all keys that contain the tag filter value in their respective list. This permits the controller to continue to specify just a DID as the issuer/signer/sender of a value without having to know exactly which key ACA-Py should use to perform the operation. This also permits the controller to continue to use the verification method ID directly to specify a key that might not normally be selected first. Additionally, when a specific proof type is desired, Askar can also filter by KeyAlg so a simple mapping from proof type to appropriate KeyAlgs can efficiently accomplish this filtering.DID StorageDIDs should be altered to be stored in a way that simply acknowledges that we own the DID and not as the primary key retrieval mechanism.  Category: did  Name: the DID itself  Value:          …        Tags:          method: a string representing the DID Method      (Maybe?) features: the list of features the DID is capable of      Other things it would be valuable to use to look up the DID?      MigrationExisting ACA-Py wallets should have the following migration performed to accommodate this reorientation:  Migrate all existing records in the did category to the new structure and also duplicate the record to a legacy nym category          If the did value is unqualified, “move” to the new did category and map old values onto new, adding did:sov: to the front.      If the did value is unqualified, also create a record in the new nym category with a structure matching the original DIDInfo object, where a verkey is closely associated with the nym. This should enable us to continue using the builtin Indy support in a way that distinguishes the old from the new.      For did values that are qualified, move to the new did category and make sure the associated key entries are properly tagged. This will depend on the DID Method. Plugged in DID Methods may need to account for their own DID methods in a separate migration process.      "
  },
  
  {
    "title": "webauthn/issue/2208: \"Verify\" is undefined",
    "url": "/github-discussions/webauthn/issue/2208/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-18 07:50:14 -0800",
    





    
    "snippet": "For example, https://w3c.github.io/webauthn/#sctn-registering-a-new-credential has a step that reads  Verify that the value of C.type is webauthn.create.but it’s not at all clear what this means or...",
    "content": "For example, https://w3c.github.io/webauthn/#sctn-registering-a-new-credential has a step that reads  Verify that the value of C.type is webauthn.create.but it’s not at all clear what this means or what should happen when it cannot be true. If it’s always meant to be true unless something outside of the scope of the specification has happened, it would be more appropriate to use Infra’s Assert primitive.If it can actually have other values, you’ll need to define how to handle those."
  },
  
  {
    "title": "webauthn/issue/2207: JSON parsing should be on top of Infra primitives",
    "url": "/github-discussions/webauthn/issue/2207/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-18 05:58:14 -0800",
    





    
    "snippet": "I suspect that most can be replaced by https://infra.spec.whatwg.org/#parse-json-bytes-to-an-infra-value. This will also require some changes to the following steps as they now have an Infra value....",
    "content": "I suspect that most can be replaced by https://infra.spec.whatwg.org/#parse-json-bytes-to-an-infra-value. This will also require some changes to the following steps as they now have an Infra value. This should also allow for the removal of the notes as now this is all well-defined instead of somewhat hand-wavy."
  },
  
  {
    "title": "webauthn/issue/2206: Use of \"valid domain\" seems wrong",
    "url": "/github-discussions/webauthn/issue/2206/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-18 05:55:36 -0800",
    





    
    "snippet": "No user agent implements “valid domain”. I suspect that instead you simply want to do a type check that the host of an origin is a domain.Also, what kind of schemes can this origin have and do thos...",
    "content": "No user agent implements “valid domain”. I suspect that instead you simply want to do a type check that the host of an origin is a domain.Also, what kind of schemes can this origin have and do those need to be checked?"
  },
  
  {
    "title": "webauthn/issue/2205: Usage of \"effective domain\" seems wrong",
    "url": "/github-discussions/webauthn/issue/2205/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-18 05:54:16 -0800",
    





    
    "snippet": "No other specification really ought to use “effective domain”. That’s only for document.domain-related business. I suspect you just want to grab an origin’s host and ignore this operation.",
    "content": "No other specification really ought to use “effective domain”. That’s only for document.domain-related business. I suspect you just want to grab an origin’s host and ignore this operation."
  },
  
  {
    "title": "identus-cloud-agent/issue/1451: Verifiable Credential Issued in JWT uses longform of prism DID in the iss field of JWT",
    "url": "/github-discussions/identus-cloud-agent/issue/1451/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-18 05:19:24 -0800",
    





    
    "snippet": "Is this a regression?NoDescriptionA Verifiable Credential issued in JWT format currently uses the long-form of a Prism DID in the iss field of the JWT. We should update this to use the short-form P...",
    "content": "Is this a regression?NoDescriptionA Verifiable Credential issued in JWT format currently uses the long-form of a Prism DID in the iss field of the JWT. We should update this to use the short-form Prism DID instead. Below is an example of a VC issued in JWT format, and upon decoding, the iss field displays the long-form DIDeyJ0eXAiOiJKV1QiLCJhbGciOiJFZERTQSJ9.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.BlhAJdhgJO58y17Xe21iKnOkrj2JNcK_R2tfUAfCh_KO8jjOepCVLZWJWqcV–XkBMraUJCT8R4H1KhIlAIyBQ```{  “iss”: “did:prism:f2ebecf1b5e94edd6b0fc456ce2fba0cb78a17352e1af5cd86e2fa02ad7a8d77:CpsCCpgCEkYKFW15LWtleS1hdXRoZW50aWNhdGlvbhAESisKB0VkMjU1MTkSINnhhfj-t1wuAjKHT3mYMQ44QMqwJ4lo4HOdkNMcIAxnEkcKFm15LWtleS1hc3NlcnRpb25NZXRob2QQAkorCgdFZDI1NTE5EiCboM2DRna–XtFO_E34EWhTa34LjFD7FdE3qnyZMt5uBI7CgdtYXN0ZXIwEAFKLgoJc2VjcDI1NmsxEiEC1fopauP-Kz-7szZFWAnf_xEiF9YOScS6CfmvQm7PWRsaSAoOYWdlbnQtYmFzZS11cmwSEExpbmtlZFJlc291cmNlVjEaJGh0dHA6Ly8xOTIuMTY4LjEuODY6ODAwMC9jbG91ZC1hZ2VudA”,  “sub”: “did:prism:ce30775196fe449f6731dda2eafee1a620fee224a7e6f631ba748afca6155093:CpcCCpQCEj8KC215LWF1dGgta2V5EARKLgoJc2VjcDI1NmsxEiEC2qHVEawblVd8nnGN8HMhpHpfFd0TRLuRY9GU-w0ZPtcSSgoWbXkta2V5LWFzc2VydGlvbk1ldGhvZBACSi4KCXNlY3AyNTZrMRIhA5G9MWNRRr8SHxSHah1cvj7eXdsYzW-x-eqVAWsTxPcyEjsKB21hc3RlcjAQAUouCglzZWNwMjU2azESIQMmLm5mHjWMuF5RZn4Vb1j4hGtHIsQht1wHVCwv1Qv1ZRpICg5hZ2VudC1iYXNlLXVybBIQTGlua2VkUmVzb3VyY2VWMRokaHR0cDovLzE5Mi4xNjguMS44Njo5MDAwL2Nsb3VkLWFnZW50”,  “nbf”: 1731927195,  “exp”: 1731930795,  “vc”: {    “credentialSchema”: [      {        “id”: “http://192.168.1.86:8000/cloud-agent/schema-registry/schemas/7b4b0f23-d995-3e7a-bf9d-19bbe10e2d4b”,        “type”: “CredentialSchema2022”      }    ],    “credentialSubject”: {      “emailAddress”: “alice@wonderland.com”,      “drivingClass”: 3,      “familyName”: “Wonderland”,      “givenName”: “Alice”,      “drivingLicenseID”: “12345”,      “id”: “did:prism:ce30775196fe449f6731dda2eafee1a620fee224a7e6f631ba748afca6155093:CpcCCpQCEj8KC215LWF1dGgta2V5EARKLgoJc2VjcDI1NmsxEiEC2qHVEawblVd8nnGN8HMhpHpfFd0TRLuRY9GU-w0ZPtcSSgoWbXkta2V5LWFzc2VydGlvbk1ldGhvZBACSi4KCXNlY3AyNTZrMRIhA5G9MWNRRr8SHxSHah1cvj7eXdsYzW-x-eqVAWsTxPcyEjsKB21hc3RlcjAQAUouCglzZWNwMjU2azESIQMmLm5mHjWMuF5RZn4Vb1j4hGtHIsQht1wHVCwv1Qv1ZRpICg5hZ2VudC1iYXNlLXVybBIQTGlua2VkUmVzb3VyY2VWMRokaHR0cDovLzE5Mi4xNjguMS44Njo5MDAwL2Nsb3VkLWFnZW50”,      “dateOfIssuance”: “2020-11-13T20:20:39+00:00”    },    “type”: [      “VerifiableCredential”    ],    “@context”: [      “https://www.w3.org/2018/credentials/v1”    ],    “issuer”: {      “id”: “did:prism:f2ebecf1b5e94edd6b0fc456ce2fba0cb78a17352e1af5cd86e2fa02ad7a8d77:CpsCCpgCEkYKFW15LWtleS1hdXRoZW50aWNhdGlvbhAESisKB0VkMjU1MTkSINnhhfj-t1wuAjKHT3mYMQ44QMqwJ4lo4HOdkNMcIAxnEkcKFm15LWtleS1hc3NlcnRpb25NZXRob2QQAkorCgdFZDI1NTE5EiCboM2DRna–XtFO_E34EWhTa34LjFD7FdE3qnyZMt5uBI7CgdtYXN0ZXIwEAFKLgoJc2VjcDI1NmsxEiEC1fopauP-Kz-7szZFWAnf_xEiF9YOScS6CfmvQm7PWRsaSAoOYWdlbnQtYmFzZS11cmwSEExpbmtlZFJlc291cmNlVjEaJGh0dHA6Ly8xOTIuMTY4LjEuODY6ODAwMC9jbG91ZC1hZ2VudA”,      “type”: “Profile”    },    “credentialStatus”: {      “statusPurpose”: “Revocation”,      “statusListIndex”: 2,      “id”: “http://192.168.1.86:8000/cloud-agent/credential-status/a71b2646-af9d-4453-97bd-4825aec31d2c#2”,      “type”: “StatusList2021Entry”,      “statusListCredential”: “http://192.168.1.86:8000/cloud-agent/credential-status/a71b2646-af9d-4453-97bd-4825aec31d2c”    }  }}``Please provide the exception or error you sawNAPlease provide the environment you discovered this bug inNA"
  },
  
  {
    "title": "identus-cloud-agent/issue/1450: Add support for SDJWT  trustedIssuer and credential SchemaId Validation ",
    "url": "/github-discussions/identus-cloud-agent/issue/1450/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-18 05:13:03 -0800",
    





    
    "snippet": "Is this a regression?NoDescriptionSDJWT is similar flow as JWT so need to support  similar to JWT { “connectionId”: “{{VERIFIER_CONNECTION_ID}}”, “proofs”: [            {                “schemaId”:...",
    "content": "Is this a regression?NoDescriptionSDJWT is similar flow as JWT so need to support  similar to JWT { “connectionId”: “{{VERIFIER_CONNECTION_ID}}”, “proofs”: [            {                “schemaId”: “{{baseUrl}}/schema-registry/schemas/{{SCHEMA_ID}}”,                “trustIssuers”: [                    “did:prism:invalidddddđ”                ]            }], “options”: {    “challenge”: “11c91493-01b3-4c4d-ac36-b336bab5bddf”,    “domain”: “https://prism-verifier.com”  },  “credentialFormat”: “SDJWT”,  “claims”: {        “emailAddress”: {},        “givenName”: {},        “country” :{}     }}Please provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "identus-cloud-agent/pr/1442: test: add new tests and refactoring",
    "url": "/github-discussions/identus-cloud-agent/pr/1442/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-15 15:02:41 -0800",
    





    
    "snippet": "Description:Adds more tests and refactoringChecklist:  My PR follows the contribution guidelines of this project  My PR is free of third-party dependencies that don’t comply with the Allowlist  I h...",
    "content": "Description:Adds more tests and refactoringChecklist:  My PR follows the contribution guidelines of this project  My PR is free of third-party dependencies that don’t comply with the Allowlist  I have commented my code, particularly in hard-to-understand areas  I have made corresponding changes to the documentation  I have added tests that prove my fix is effective or that my feature works  I have checked the PR title to follow the conventional commit specification"
  },
  
  {
    "title": "identus-cloud-agent/issue/1440: docs/ Docker error",
    "url": "/github-discussions/identus-cloud-agent/issue/1440/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-14 17:27:38 -0800",
    





    
    "snippet": "Is this a regression?YesDescriptionReading docs/README.md there are instructions for seeing swagger docs. They didn’t work for mePlease provide the exception or error you sawdocker compose -f docs/...",
    "content": "Is this a regression?YesDescriptionReading docs/README.md there are instructions for seeing swagger docs. They didn’t work for mePlease provide the exception or error you sawdocker compose -f docs/docker-compose.yml upWARN[0000] /home/projects/IDENTUS/identus-cloud-agent/docs/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion[+] Running 1/2 ✘ atala-structurizr-lite Error pull access denied for atala-struc...                               4.0s ⠏ swagger-ui Pulling                                                                               4.0sError response from daemon: pull access denied for atala-structurizr-lite, repository does not exist or may require 'docker login': denied: requested access to the resource is deniedPlease provide the environment you discovered this bug inLinux: Debian/Ubuntu 22.04Docker: version 27.3.1, build ce12230Anything else?Note I had to run docker compose not docker-compose … i forget why docker split these out / when … generally it’s not a problem to swap those commands but it is a deviation from the documented command to run"
  },
  
  {
    "title": "web-did-resolver/pr/134: build(deps): bump express from 4.18.2 to 4.19.2 in /afj",
    "url": "/github-discussions/web-did-resolver/pr/134/",
    "categories": "DIF",
    "tags": "web-did-resolver",
    "date": "2024-11-14 14:09:16 -0800",
    





    
    "snippet": "Bumps express from 4.18.2 to 4.19.2.Release notesSourced from express's releases.4.19.2What's ChangedImproved fix for open redirect allow list bypassFull Changelog: https://github.com/expressjs/exp...",
    "content": "Bumps express from 4.18.2 to 4.19.2.Release notesSourced from express's releases.4.19.2What's ChangedImproved fix for open redirect allow list bypassFull Changelog: https://github.com/expressjs/express/compare/4.19.1...4.19.24.19.1What's ChangedFix ci after location patch by @​wesleytodd in expressjs/express#5552fixed un-edited version in history.md for 4.19.0 by @​wesleytodd in expressjs/express#5556Full Changelog: https://github.com/expressjs/express/compare/4.19.0...4.19.14.19.0What's Changedfix typo in release date by @​UlisesGascon in expressjs/express#5527docs: nominating @​wesleytodd to be project captian by @​wesleytodd in expressjs/express#5511docs: loosen TC activity rules by @​wesleytodd in expressjs/express#5510Add note on how to update docs for new release by @​crandmck in expressjs/express#5541Prevent open redirect allow list bypass due to encodeurlRelease 4.19.0 by @​wesleytodd in expressjs/express#5551New Contributors@​crandmck made their first contribution in expressjs/express#5541Full Changelog: https://github.com/expressjs/express/compare/4.18.3...4.19.04.18.3Main ChangesFix routing requests without methoddeps: body-parser@1.20.2Fix strict json error message on Node.js 19+deps: content-type@~1.0.5deps: raw-body@2.5.2Other ChangesUse https: protocol instead of deprecated git: protocol by @​vcsjones in expressjs/express#5032build: Node.js@16.18 and Node.js@18.12 by @​abenhamdine in expressjs/express#5034ci: update actions/checkout to v3 by @​armujahid in expressjs/express#5027test: remove unused function arguments in params by @​raksbisht in expressjs/express#5124Remove unused originalIndex from acceptParams by @​raksbisht in expressjs/express#5119Fixed typos by @​raksbisht in expressjs/express#5117examples: remove unused params by @​raksbisht in expressjs/express#5113fix: parameter str is not described in JSDoc by @​raksbisht in expressjs/express#5130fix: typos in History.md by @​raksbisht in expressjs/express#5131build : add Node.js@19.7 by @​abenhamdine in expressjs/express#5028test: remove unused function arguments in params by @​raksbisht in expressjs/express#5137... (truncated)ChangelogSourced from express's changelog.4.19.2 / 2024-03-25Improved fix for open redirect allow list bypass4.19.1 / 2024-03-20Allow passing non-strings to res.location with new encoding handling checks4.19.0 / 2024-03-20Prevent open redirect allow list bypass due to encodeurldeps: cookie@0.6.04.18.3 / 2024-02-29Fix routing requests without methoddeps: body-parser@1.20.2Fix strict json error message on Node.js 19+deps: content-type@~1.0.5deps: raw-body@2.5.2deps: cookie@0.6.0Add partitioned optionCommits04bc627 4.19.2da4d763 Improved fix for open redirect allow list bypass4f0f6cc 4.19.1a003cfa Allow passing non-strings to res.location with new encoding handling checks f...a1fa90f fixed un-edited version in history.md for 4.19.011f2b1d build: fix build due to inconsistent supertest behavior in older versions084e365 4.19.00867302 Prevent open redirect allow list bypass due to encodeurl567c9c6 Add note on how to update docs for new release (#5541)69a4cf2 deps: cookie@0.6.0Additional commits viewable in compare viewMaintainer changesThis version was pushed to npm by wesleytodd, a new releaser for express since your current version.Dependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hyperledger/aries-mediator-service/network/alerts).&lt;/details&gt;"
  },
  
  {
    "title": "webauthn/issue/2204: Should steps 28 and 29 occur before Step 27 in the registration ceremony",
    "url": "/github-discussions/webauthn/issue/2204/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-14 13:07:57 -0800",
    





    
    "snippet": "Currently step 27 occurs before steps 28 and 29; however it seems weird to “create and store a new credential record in the user account” before successfully completing steps 28 and 29, right? This...",
    "content": "Currently step 27 occurs before steps 28 and 29; however it seems weird to “create and store a new credential record in the user account” before successfully completing steps 28 and 29, right? This means one could save a credential even though the ceremony fails later.A similar issue exists for the authentication ceremony where step 23 occurs before steps 24 and 25.I think moving those steps last makes the most sense since this way any credential creation or update occurs iff the ceremony succeeds."
  },
  
  {
    "title": "identus/issue/86: Cardano Connector for SDK",
    "url": "/github-discussions/identus/issue/86/",
    "categories": "Hyperledger",
    "tags": "identus",
    "date": "2024-11-14 08:12:54 -0800",
    





    
    "snippet": "Short DescriptionA connector for the SDKs to submit the PRISM Block to the Cardano Blockchain.Value statementAs a community we already agreed this is value coming from the discussion in https://git...",
    "content": "Short DescriptionA connector for the SDKs to submit the PRISM Block to the Cardano Blockchain.Value statementAs a community we already agreed this is value coming from the discussion in https://github.com/hyperledger/identus/discussions/80But just the summarize:The PRISM Node can be view as a Cardano Connector. But is a component that is able to do much more that simple submit transaction with metadata.But this is a very common use case in Cardano.The value of this come from bypassing this dedicated component of the did:prism method. With a generic component that uses infrastructure that already exists and that is largely available.Again, the ONLY concern that we care about in here is the Writing Path.We don’t care about the status of DID in here. But to create valid PRISM Block you need to know the status of the DID. For that you have the Reading Path. Both PRISM Node or the universal resolver cover that.For example when you create a new did:prism you already know the state of the DID, because it is no existed.So let’s split responsibility:  The SDKs needs to produce the bytes that constitute a valid PRISM Block.Note the PRISM Block is already sign with the private keys if the DID, so the Keys is never shared with the connector.  The Cardano Connector receive the bytes of the PRISM Block (which is a protobuf) and create a transactions with those bytes on the metadata and a metadata id 21325.See Appendix A &amp; B on the PRISM DID method specs for more for more information.  Private keys. There are you two pairs of Private keys, one is the Master key on the DID and another is the key of the wallet.          The Master private key of the DID is never shared with the Connector. This key is used to sign the PRISM Object in order to make the PRISM Block.      The private key of the wallet its also never shared to other components. This key is used to sign the Cardano transactions.      I propose we do a proof of concept of a connector that will be a Chrome extension and use the TS SDK to call the Lace wallet and make a transaction via the Lace wallet.The idea is to explore CIP30 API and try to build from there https://cips.cardano.org/cip/CIP-30ComponentsProof of concept for a new company ComponentWriting path of the did:prism method using the TS SDK"
  },
  
  {
    "title": "webauthn/issue/2203: Replace `USVString` with `DOMString`",
    "url": "/github-discussions/webauthn/issue/2203/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-14 07:08:41 -0800",
    





    
    "snippet": "It would appear that the same justification that was used for #2115 applies to the remaining areas where USVString is used:  As recommended by the Web IDL spec:      Specifications should only use ...",
    "content": "It would appear that the same justification that was used for #2115 applies to the remaining areas where USVString is used:  As recommended by the Web IDL spec:      Specifications should only use USVString for APIs that perform text processing and need a string of scalar values to operate on. Most APIs that use strings should instead be using DOMString, which does not make any interpretations of the code units in the string. When in doubt, use DOMString.  Currently the only places where USVString is used are the following extensions:  appid  appidExclude  prfShould these all be changed to DOMString?"
  },
  
  {
    "title": "webauthn/issue/2202: AttestationFormats may have duplicate entries",
    "url": "/github-discussions/webauthn/issue/2202/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-13 18:19:50 -0800",
    





    
    "snippet": "Proposed ChangeIn the spec, we introduce attestationFormats for RPs to indicate the attestation statement format preference for create options.The definition in the spec is as follows.  attestation...",
    "content": "Proposed ChangeIn the spec, we introduce attestationFormats for RPs to indicate the attestation statement format preference for create options.The definition in the spec is as follows.  attestationFormats, of type sequence&lt;DOMString&gt;, defaulting to []The Relying Party MAY use this OPTIONAL member to specify a preference regarding the attestation statement format used by the authenticator. Values SHOULD be taken from the IANA “WebAuthn Attestation Statement Format Identifiers” registry [IANA-WebAuthn-Registries] established by [RFC8809]. Values are ordered from most preferable to least preferable. This parameter is advisory and the authenticator MAY use an attestation statement not enumerated in this parameter.Since the value itself is the list of ordered preferences, it implies that the element of the fields would be unique.The sequence&lt;’T’&gt; does not have any such constraints for uniqueness.Thus, duplicated entries in the attestationFormats may be valid input as per the current spec. We may add some constraints around the field itself or we could describe the way for authenticator and client to handle such duplicated entries without throwing errors.This issue is related to the #2145 and maybe we could resolve this issue with similar manner."
  },
  
  {
    "title": "identus-cloud-agent/issue/1438: Proofs from presentation request not work",
    "url": "/github-discussions/identus-cloud-agent/issue/1438/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-13 18:19:10 -0800",
    





    
    "snippet": "Is this a regression?YesDescriptionHello, regarding the request body for the presentation request:I don’t understand the fields proofs.schemaId and proofs.trustIssuers. Although I sent a credential...",
    "content": "Is this a regression?YesDescriptionHello, regarding the request body for the presentation request:I don’t understand the fields proofs.schemaId and proofs.trustIssuers. Although I sent a credential that does not match the schemaId and issuerDid, the status in the cloud agent still returns “PresentationVerified.”Is that a bug?{    \"connectionId\": \"bee34719-def5-4420-8d4f-35318e72e916\",    \"proofs\": [        {            \"schemaId\": \"ddec9bf9-b187-3862-897d-dd11d1c1eb53\",            \"trustIssuers\": [                \"did:prism:invalidddddđ\"            ]        }    ],    \"options\": {        \"challenge\": \"{{$randomUUID}}\",        \"domain\": \"https://prism-verifier.com\"    },    \"credentialFormat\": \"JWT\"}Please provide the exception or error you sawNo responsePlease provide the environment you discovered this bug in1.39.1-104-1c7c38eAnything else?No response"
  },
  
  {
    "title": "webauthn/issue/2198: WebAuthn Clients should NOT zero out AAGUIDs from security keys when attestation is none",
    "url": "/github-discussions/webauthn/issue/2198/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-11-13 12:51:20 -0800",
    





    
    "snippet": "There has been some confusion across multiple issues, so creating another one 🫠.In #2058, spec text was added to only zero out AAGUIDs for none attestations when the authenticator was not a platfor...",
    "content": "There has been some confusion across multiple issues, so creating another one 🫠.In #2058, spec text was added to only zero out AAGUIDs for none attestations when the authenticator was not a platform authenticator.Proposal is to remove this change altogether, which would allow AAGUIDs from security keys to not be zeroed out.Remove:If authenticator is not a [platform authenticator](https://w3c.github.io/webauthn/#platform-authenticators) then replace the [aaguid](https://w3c.github.io/webauthn/#authdata-attestedcredentialdata-aaguid) in the [attested credential data](https://w3c.github.io/webauthn/#attested-credential-data) with 16 zero bytes.This makes the behavior the same across all authenticator types from the client perspective."
  },
  
  {
    "title": "org/issue/57: Scalability and Performance Optimization",
    "url": "/github-discussions/org/issue/57/",
    "categories": "DIF",
    "tags": "org",
    "date": "2024-11-13 10:04:46 -0800",
    





    
    "snippet": "Optimize scalability and performance when interacting with decentralized web nodes, ensuring a reliable and efficient user experience.",
    "content": "Optimize scalability and performance when interacting with decentralized web nodes, ensuring a reliable and efficient user experience."
  },
  
  {
    "title": "did-extensions/issue/590: SPEC/PROCESS PROPOSAL: To secure a unique method name, require the registration of the corresponding Internet DNS name: did-<method>. directory ",
    "url": "/github-discussions/did-extensions/issue/590/",
    "categories": "W3C",
    "tags": "did-extensions",
    "date": "2024-11-10 14:57:39 -0800",
    





    
    "snippet": "For example,  did:ns -&gt; http://did-ns.directory  did: object -&gt; http://did-object.directoryThere would be no requirement to implement or use the registered domain. It would be like buying an ...",
    "content": "For example,  did:ns -&gt; http://did-ns.directory  did: object -&gt; http://did-object.directoryThere would be no requirement to implement or use the registered domain. It would be like buying an automobile license plate and never placing it on a vehicle (which is OK).Second, this would remove the W3C from the conflicting method name problem.Third, existing W3C registrations would be “grandfathered in”; i.e. not required to have the DNS name registration but it would still be recommended.Other thoughts?"
  },
  
  {
    "title": "did-extensions/issue/586: Objection: approval of did:tdw",
    "url": "/github-discussions/did-extensions/issue/586/",
    "categories": "Hyperledger",
    "tags": "did-extensions",
    "date": "2024-11-07 09:37:26 -0800",
    





    
    "snippet": "I have a commercial objection to the approval of did:tdw.“tdw” overlaps significantly with the Trusted Digital Web, the parent project of the Web 7.0 Ultraweb.Reference: https://github.com/mwherman...",
    "content": "I have a commercial objection to the approval of did:tdw.“tdw” overlaps significantly with the Trusted Digital Web, the parent project of the Web 7.0 Ultraweb.Reference: https://github.com/mwherman2000/TrustedDigitalWebSee PR  https://github.com/w3c/did-extensions/pull/581#issuecomment-2462828639 for the details."
  },
  
  {
    "title": "did-extensions/issue/585: https://www.w3.org/TR/did-extensions-methods/ is unresolvable ",
    "url": "/github-discussions/did-extensions/issue/585/",
    "categories": "W3C",
    "tags": "did-extensions",
    "date": "2024-11-07 09:23:22 -0800",
    





    
    "snippet": "In the Extensions document, the DID Methods document link doesn’t resolve.See https://w3c.github.io/did-extensions/#extensions@msporny",
    "content": "In the Extensions document, the DID Methods document link doesn’t resolve.See https://w3c.github.io/did-extensions/#extensions@msporny"
  },
  
  {
    "title": "credential-schemas/issue/23: Support Verification in SDK - Anoncreds",
    "url": "/github-discussions/credential-schemas/issue/23/",
    "categories": "DIF",
    "tags": "credential-schemas",
    "date": "2024-11-05 09:54:02 -0800",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "credential-schemas/issue/21: Fix mac-os build",
    "url": "/github-discussions/credential-schemas/issue/21/",
    "categories": "DIF",
    "tags": "credential-schemas",
    "date": "2024-11-04 05:41:24 -0800",
    





    
    "snippet": "See https://github.com/hyperledger/indy-cli-rs/pull/20",
    "content": "See https://github.com/hyperledger/indy-cli-rs/pull/20"
  },
  
  {
    "title": "webauthn/issue/2192: The authenticator may hide the credential even if the RP signals unknown credentials",
    "url": "/github-discussions/webauthn/issue/2192/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-10-30 02:03:05 -0700",
    





    
    "snippet": "Proposed ChangeIn the spec, there are some description and recommendation how the authenticator handles signal APIs.Currently, in many parts, there are description like this.  WebAuthn Relying Part...",
    "content": "Proposed ChangeIn the spec, there are some description and recommendation how the authenticator handles signal APIs.Currently, in many parts, there are description like this.  WebAuthn Relying Parties may use these signal methods to inform authenticators of the state of public key credentials, so that incorrect or revoked credentials may be updated, removed, or hidden.The authenticator may decide not to remove the credential at the time of receiving the signal and it may remove it after certain amount of time passes. It implies that the credential would not delete the credential and for some reasons the hidden credential would be changed to active credential.In the case of the user directly goes through the authenticator dedicated UI and then delete the credential, it would not be reported to the RP and which causes credential mismatch. So, for this case, the authenticator would hide the credential if the user deletes the credential through menu and it would be restored depending on some cases, and it would still work without any issue.For this scenario, the hidden feature might be a good choice as an authenticator to prevent the credential is accidentally removed so that the user avoid user lock out case.However, for the signal APIs, RP indicates that the acceptable credentials with an intention, so It would be better for authenticators to delete or update credentials if it is required to meet the original requirement (synchronization between authenticators and RP)."
  },
  
  {
    "title": "acapy/issue/3321: Question API: Send Presentation without pres_ex_id or with connection_id",
    "url": "/github-discussions/acapy/issue/3321/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-10-29 15:17:14 -0700",
    





    
    "snippet": "Hi there,I am using aca-py for my master’s thesis and trying to achieve the trust between user and my system.What I am trying to achieve is to expose the system’s VC to the user’s wallet so they ca...",
    "content": "Hi there,I am using aca-py for my master’s thesis and trying to achieve the trust between user and my system.What I am trying to achieve is to expose the system’s VC to the user’s wallet so they can be sure that they have connected with the right entity.Is there a way to send VC presentation without needing a request first?Thanks in advance!"
  },
  
  {
    "title": "acapy-plugins/issue/1161: Multitenancy support for OID4VC plugin",
    "url": "/github-discussions/acapy-plugins/issue/1161/",
    "categories": "Hyperledger",
    "tags": "acapy-plugins",
    "date": "2024-10-28 07:14:18 -0700",
    





    
    "snippet": "Currently, the OID4VC plugin doesn’t support multitenancy, and all operations are saved in the base wallet. When we secure the admin API, the supported credentials data is not passed on to the .wel...",
    "content": "Currently, the OID4VC plugin doesn’t support multitenancy, and all operations are saved in the base wallet. When we secure the admin API, the supported credentials data is not passed on to the .well-known endpoint for the OID4VCI server.We have reviewed the initial design options and have started work on enabling multitenancy for the OID4VC plugin.The following changes are proposed:  Pass wallet information to the OID4VC server. This can be done by:          Creating a separate sub-path for each wallet and hosting all endpoints within that sub-path, e.g., &lt;OID4VCI-Endpoint&gt;/&lt;wallet-id&gt;, using it for identification; or      Passing the wallet ID as a request parameter, e.g., &lt;OID4VCI-Endpoint&gt;/.well-known/openid-credential-issuer?&lt;wallet-id&gt;.        Use the sub-path or request parameter to pass wallet information when issuing the credential offer.We’re opening this issue to gather feedback from maintainers and other OID4VC developers to finalize the design and continue the work. cc: @dbluhm, @jamshale"
  },
  
  {
    "title": "webauthn/issue/2187: Remove authenticatorDisplayName from L3",
    "url": "/github-discussions/webauthn/issue/2187/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-10-23 12:06:50 -0700",
    





    
    "snippet": "Discussed at TPAC as well as the 2024-10-23 call.  Remove authenticatorDisplayName from credProps for Level 3  Address the use case in Level 4 via https://github.com/w3c/webauthn/issues/2157Relevan...",
    "content": "Discussed at TPAC as well as the 2024-10-23 call.  Remove authenticatorDisplayName from credProps for Level 3  Address the use case in Level 4 via https://github.com/w3c/webauthn/issues/2157Relevant Issues and PRs:  https://github.com/w3c/webauthn/pull/2163  https://github.com/w3c/webauthn/pull/1880  https://github.com/w3c/webauthn/issues/2156  https://github.com/w3c/webauthn/pull/2005"
  },
  
  {
    "title": "identus/issue/76: Improve Infrastructure provisioning",
    "url": "/github-discussions/identus/issue/76/",
    "categories": "DIF",
    "tags": "identus",
    "date": "2024-10-21 07:31:35 -0700",
    





    
    "snippet": "Short DescriptionImprove the infrastructure provisioning by reducing the amount of services that are bundled by default + making those easier to configure and not require any specific SH configurat...",
    "content": "Short DescriptionImprove the infrastructure provisioning by reducing the amount of services that are bundled by default + making those easier to configure and not require any specific SH configuration script. On top of that we also aim to make everything deployable from a single docker image and not require too many images.Value statementMain goal behind this EPIC is to make our services easier to configure and maintain over time. For existing users, this will improve code maintenance and reduce the time spent on configuring the services and for our new users this will make it extremely easier to kick-off your project in Identus ecosystem. We mainly aim to reduce friction when it comes to configuring the services and get everything configured to start developing code.ComponentsCloud AgentTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "identus/issue/75: DID management component discussion",
    "url": "/github-discussions/identus/issue/75/",
    "categories": "DIF",
    "tags": "identus",
    "date": "2024-10-21 07:18:04 -0700",
    





    
    "snippet": "The reason for this discussion is there is a need for a better did management component.As part of this discussion the following is purposed:  Separate Plutos DID Management side into a more flexib...",
    "content": "The reason for this discussion is there is a need for a better did management component.As part of this discussion the following is purposed:  Separate Plutos DID Management side into a more flexible protocol.  Make the DID management data more common, aka: instead of having a different storage for PrismDID and PeerDID have a storage for DIDs.  Make a DID Management default component that is capable of manage (search, create, update, delete) DIDs and is components in the database.Then make this component available within PrismAgent."
  },
  
  {
    "title": "identus/issue/73: VCDM Improvements Phase 1: Standardize our implementation of 1.1 ",
    "url": "/github-discussions/identus/issue/73/",
    "categories": "DIF",
    "tags": "identus",
    "date": "2024-10-21 07:15:57 -0700",
    





    
    "snippet": "Short DescriptionWe need to change the schemaId from being an  strings vs array of object, and the field should also be replaced by another fieldName, from “schemaId” to “credentialSchema”Value sta...",
    "content": "Short DescriptionWe need to change the schemaId from being an  strings vs array of object, and the field should also be replaced by another fieldName, from “schemaId” to “credentialSchema”Value statementTBDComponents  OAS  SDKsTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "json-ld-syntax/issue/443: `@protected` creates unresolvable conflicts when the same term is defined in two contexts top-level",
    "url": "/github-discussions/json-ld-syntax/issue/443/",
    "categories": "DIF",
    "tags": "json-ld-syntax",
    "date": "2024-10-19 02:53:21 -0700",
    





    
    "snippet": "I’ve just encountered issue #424 (and the related #361 as well) and in a similar situation with https://www.w3.org/ns/controller/v1 defining alsoKnownAs top-level alongside @protected: true, while ...",
    "content": "I’ve just encountered issue #424 (and the related #361 as well) and in a similar situation with https://www.w3.org/ns/controller/v1 defining alsoKnownAs top-level alongside @protected: true, while https://www.w3.org/ns/activitystreams defines alsoKnownAs in a different namespace (as: vs sec:, loosely)From controller/v1:{  \"@context\": {    \"@protected\": true,    \"id\": \"@id\",    \"type\": \"@type\",    \"alsoKnownAs\": {      \"@id\": \"https://w3id.org/security#alsoKnownAs\",      \"@type\": \"@id\",      \"@container\": \"@set\"    },//...From activitystreams:{  \"@context\": {    \"@vocab\": \"_:\",    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",    \"as\": \"https://www.w3.org/ns/activitystreams#\",// ...\"alsoKnownAs\": {      \"@id\": \"as:alsoKnownAs\",      \"@type\": \"@id\"    }// ...Putting activitystreams before controller/v1 causes the later definition to override the older one, as expected (but not as desired):{  \"@context\": [\"https://www.w3.org/ns/activitystreams\", \"https://www.w3.org/ns/controller/v1\"],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // sec:alsoKnownAs}[  {    \"https://w3id.org/security#alsoKnownAs\": [  // should be https://www.w3.org/ns/activitystreams#alsoKnownAs      {        \"@id\": \"https://person.example\"      }    ],    \"@id\": \"http://person.example\",    \"@type\": [      \"https://www.w3.org/ns/activitystreams#Person\"    ]  }]But putting activitystreams after controller/v1 triggers the error due to @protected: true:{  \"@context\": [\"https://www.w3.org/ns/controller/v1\",  // uses @protected\"https://www.w3.org/ns/activitystreams\"  // will trigger the redefinition error],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"}jsonld.SyntaxError: Invalid JSON-LD syntax; tried to redefine a protected term.JSON-LD 1.1 4.1.11 Protected term definitions https://www.w3.org/TR/json-ld11/#protected-term-definitions describes two exceptions. The first exception is when the definition is the same, which is not applicable here. The second exception is for property-scoped context definitions, which is unworkable because in this case the singular top-level object is intended to be both an Actor as well as a Controller Document.To veryify, here’s a type-scoped context definition that errors out:{  \"@context\": [    \"https://www.w3.org/ns/controller/v1\",     {       \"Person\": {         \"@id\": \"https://www.w3.org/ns/activitystreams#Person\",         \"@context\": {           \"alsoKnownAs\": {  // triggers the redefinition error             \"@id\": \"https://www.w3.org/ns/activitystreams#alsoKnownAs\"           }         }       }     }],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"}And to reiterate, a property-scoped context definition can’t be used because the alsoKnownAs property is top-level. So the way I see it, there’s nothing that can be done to resolve this in a “plain JSON” compatible way except:  a) convince whoever is responsible for controller/v1 to remove @protected: true  b) convince whoever is responsible for controller/v1 to redefine alsoKnownAs with the activitystreams-namespaced @id instead of the security-namespaced one  c) write my own context documentThis leads me to think that @protected is a generally poorly-thought-out mechanism that highly increases the likelihood of such conflicts. Without it, as a producer I could just redefine the term later, for example by putting the activitystreams context last, or by using a local context object that comes after both remote contexts:{  \"@context\": [  \"https://www.w3.org/ns/controller/v1\",  // needs to remove @protected  \"https://www.w3.org/ns/activitystreams\"  // as:alsoKnownAs will override controller/v1's sec:alsoKnownAs],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // as:alsoKnownAs}or{  \"@context\": [\"https://www.w3.org/ns/activitystreams\",  // defines as:alsoKnownAs\"https://www.w3.org/ns/controller/v1\",  // redefines sec:alsoKnownAs as @protected {\"alsoKnownAs\": {  \"@id\": \"https://www.w3.org/ns/activitystreams#alsoKnownAs\",  // won't work unless controller/v1 removes @protected  \"@type\": \"@id\"}}],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // as:alsoKnownAs}I’m not sure the existence of @protected accomplishes its stated goal of “prevent[ing] this divergence of interpretation”, nor that the rationale “that “plain JSON” implementations, relying on a given specification, will only traverse properties defined by that specification” is sufficiently addressing the issue of conflicts (or that it is a valid assumption in the first place). The issue arises when two specifications define the same term, and both specifications apply to the current object or document. It effectively leads to a hard incompatibility where it is impossible to implement both specs fully; you have to pick between them.If there’s an option I’m not aware of I’d like to hear it."
  },
  
  {
    "title": "identus-apollo/pr/196: chore(deps-dev): Bump pytest from 7.4.4 to 8.1.0 in /basicmessage_storage",
    "url": "/github-discussions/identus-apollo/pr/196/",
    "categories": "Hyperledger",
    "tags": "identus-apollo",
    "date": "2024-10-16 05:48:45 -0700",
    





    
    "snippet": "Bumps pytest from 7.4.4 to 8.1.0.Release notesSourced from pytest's releases.8.1.0pytest 8.1.0 (2024-03-03)Features#11475: Added the new consider_namespace_packages{.interpreted-text role=&quot;con...",
    "content": "Bumps pytest from 7.4.4 to 8.1.0.Release notesSourced from pytest's releases.8.1.0pytest 8.1.0 (2024-03-03)Features#11475: Added the new consider_namespace_packages{.interpreted-text role=&quot;confval&quot;} configuration option, defaulting to False.If set to True, pytest will attempt to identify modules that are part of namespace packages when importing modules.#11653: Added the new verbosity_test_cases{.interpreted-text role=&quot;confval&quot;} configuration option for fine-grained control of test execution verbosity.See Fine-grained verbosity &lt;pytest.fine_grained_verbosity&gt;{.interpreted-text role=&quot;ref&quot;} for more details.Improvements#10865: pytest.warns{.interpreted-text role=&quot;func&quot;} now validates that warnings.warn{.interpreted-text role=&quot;func&quot;} was called with a [str]{.title-ref} or a [Warning]{.title-ref}.Currently in Python it is possible to use other types, however this causes an exception when warnings.filterwarnings{.interpreted-text role=&quot;func&quot;} is used to filter those warnings (see [CPython #103577](python/cpython#103577) for a discussion).While this can be considered a bug in CPython, we decided to put guards in pytest as the error message produced without this check in place is confusing.#11311: When using --override-ini for paths in invocations without a configuration file defined, the current working directory is usedas the relative directory.Previoulsy this would raise an AssertionError{.interpreted-text role=&quot;class&quot;}.#11475: --import-mode=importlib &lt;import-mode-importlib&gt;{.interpreted-text role=&quot;ref&quot;} now tries to import modules using the standard import mechanism (but still without changing :pysys.path{.interpreted-text role=&quot;data&quot;}), falling back to importing modules directly only if that fails.This means that installed packages will be imported under their canonical name if possible first, for example app.core.models, instead of having the module name always be derived from their path (for example .env310.lib.site_packages.app.core.models).#11801: Added the iter_parents() &lt;_pytest.nodes.Node.iter_parents&gt;{.interpreted-text role=&quot;func&quot;} helper method on nodes.It is similar to listchain &lt;_pytest.nodes.Node.listchain&gt;{.interpreted-text role=&quot;func&quot;}, but goes from bottom to top, and returns an iterator, not a list.#11850: Added support for sys.last_exc{.interpreted-text role=&quot;data&quot;} for post-mortem debugging on Python&gt;=3.12.#11962: In case no other suitable candidates for configuration file are found, a pyproject.toml (even without a [tool.pytest.ini_options] table) will be considered as the configuration file and define the rootdir.#11978: Add --log-file-mode option to the logging plugin, enabling appending to log-files. This option accepts either &quot;w&quot; or &quot;a&quot; and defaults to &quot;w&quot;.Previously, the mode was hard-coded to be &quot;w&quot; which truncates the file before logging.#12047: When multiple finalizers of a fixture raise an exception, now all exceptions are reported as an exception group.Previously, only the first exception was reported.Bug Fixes#11904: Fixed a regression in pytest 8.0.0 that would cause test collection to fail due to permission errors when using --pyargs.This change improves the collection tree for tests specified using --pyargs, see 12043{.interpreted-text role=&quot;pull&quot;} for a comparison with pytest 8.0 and &lt;8.... (truncated)Commitsb9a167f Prepare release version 8.1.000043f7 Merge pull request #12038 from bluetech/fixtures-rm-arg2indexf4e1025 Merge pull request #12048 from bluetech/fixture-teardown-excgroup43492f5 Merge pull request #12051 from jakkdl/test_debugging_pythonbreakpoint82fe28d [automated] Update plugin list (#12049)5e2ee71 monkeypatch.delenv PYTHONBREAKPOINT in two tests that previously failed/skipped89ee449 Merge pull request #11997 from nicoddemus/11475-importlib8248946 Do not collect symlinked tests under Windows (#12050)434282e fixtures: use exception group when multiple finalizers raise in fixture teardownd6134bc doc: document consider_namespace_packages optionAdditional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "acapy/issue/3283: `--base-wallet-routes` flag no longer works",
    "url": "/github-discussions/acapy/issue/3283/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-10-11 10:16:41 -0700",
    





    
    "snippet": "After the swap to using decorators to delineate routes accessible by tenants and routes accessible by admins, the ability to grant access to the base wallet to additional routes was lost.This optio...",
    "content": "After the swap to using decorators to delineate routes accessible by tenants and routes accessible by admins, the ability to grant access to the base wallet to additional routes was lost.This option made it possible for a base wallet to form a didcomm connection with a mediator and then use that as a base mediator for all tenants, among other things.cc @esune @jamshale"
  },
  
  {
    "title": "webauthn/issue/2169: [[Get]] method doesn't exist in CredMan",
    "url": "/github-discussions/webauthn/issue/2169/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-10-01 07:40:46 -0700",
    





    
    "snippet": "§5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method appears to reference a [[Get]] internal method on the Credential interface from CredMan, but ...",
    "content": "§5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method appears to reference a [[Get]] internal method on the Credential interface from CredMan, but no such internal method exists (unlike [[Create]], which does exist). Rather, [[DiscoverFromExternalSource]] is the actual internal method we override.Proposed Change  Delete the heading §5.1.4.1. PublicKeyCredential’s [[DiscoverFromExternalSource]](origin, options, sameOriginWithAncestors) Method (without changing any of the text around it).  Rename the heading §5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method to 5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [DiscoverFromExternalSource] Internal Method.  For consistency, change “Method” to “Internal Method” in the heading §5.1.3. Create a New Credential - PublicKeyCredential’s [[Create]](origin, options, sameOriginWithAncestors) Method.  Similarly, change “Method” to “Internal Method” in the heading §5.1.5. Store an Existing Credential - PublicKeyCredential’s [[Store]](credential, sameOriginWithAncestors) Method."
  },
  
  {
    "title": "did-core/issue/865: Question about query parameter ordering",
    "url": "/github-discussions/did-core/issue/865/",
    "categories": "W3C",
    "tags": "did-core",
    "date": "2024-09-25 05:50:27 -0700",
    





    
    "snippet": "I am looking for guidance on query parameter ordering, specifically where a DID URL with a query parameter might be used as an IDIn many systems such as ActivityPub, an ID is basically an opaque st...",
    "content": "I am looking for guidance on query parameter ordering, specifically where a DID URL with a query parameter might be used as an IDIn many systems such as ActivityPub, an ID is basically an opaque string but in practice it is a URL whose structure gives a hint on how to resolve it, like using an HTTPS URL that resolves to the object.I am in the process of trying to implement did:web for activitystreams object IDs inside of an ActivityPub project, but this would I think equally apply to service IDs in the DID document: How do I deal with query parameters being seemingly unordered if some things rely on IDs equally matching? Is anyone dealing with this in their projects?"
  },
  
  {
    "title": "webauthn/issue/2153: Bit set by the SPC extension should backed up as part of the Public Key Credential Source",
    "url": "/github-discussions/webauthn/issue/2153/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-09-24 18:04:28 -0700",
    





    
    "snippet": "PLACEHOLDERProposed ChangeBit set by the SPC extension should backed up as part of the Public Key Credential Source.",
    "content": "PLACEHOLDERProposed ChangeBit set by the SPC extension should backed up as part of the Public Key Credential Source."
  },
  
  {
    "title": "webauthn/issue/2152: Add `challengeUrl`",
    "url": "/github-discussions/webauthn/issue/2152/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-09-24 15:26:51 -0700",
    





    
    "snippet": "WebAuthn challenges usually need to be fetched from the server. This introduces extra latency, especially in cases where the page is loaded from offline storage and apps. This extra latency delays ...",
    "content": "WebAuthn challenges usually need to be fetched from the server. This introduces extra latency, especially in cases where the page is loaded from offline storage and apps. This extra latency delays when WebAuthn credentials can be shown to the user in an empty allow-list request.Proposed ChangeAdd a challengeUrl parameter that lets authenticators (or user agents) asynchronously fetch the challenge. This would let browsers render the list of credentials before the challenge comes back, improving the user experience. Add feature detection for it.This obsoletes issue #1856."
  },
  
  {
    "title": "webauthn/issue/2151: authenticatorDisplayName should use a localizable language map",
    "url": "/github-discussions/webauthn/issue/2151/",
    "categories": "W3C",
    "tags": "webauthn",
    "date": "2024-09-24 14:39:54 -0700",
    





    
    "snippet": "Related to #1644Proposed ChangeauthenticatorDisplayName is currently a DOMString and does not support localization, specifically language codes and direction.Change to a map following the String Me...",
    "content": "Related to #1644Proposed ChangeauthenticatorDisplayName is currently a DOMString and does not support localization, specifically language codes and direction.Change to a map following the String Meta spec: https://www.w3.org/TR/string-meta/#language-maps\"authenticatorDisplayName\": {    \"en\":    {\"value\": \"This is English\"},    \"en-GB\": {\"value\": \"This is UK English\", \"dir\": \"ltr\"},    \"fr\":    {\"value\": \"C'est français\", \"lang\": \"fr-CA\", \"dir\": \"ltr\"},    \"ar\":    {\"value\": \"هذه عربية\", \"dir\": \"rtl\"}}"
  },
  
  {
    "title": "identus/issue/61: Test roadmap item",
    "url": "/github-discussions/identus/issue/61/",
    "categories": "DIF",
    "tags": "identus",
    "date": "2024-09-19 06:27:35 -0700",
    





    
    "snippet": "Short DescriptionNew cool featureValue statementEnable new awesome solutionsArchitectPersonQA MemberPersonComponentsSDKs, Cloud AgentTeam membersx, y, z @essbante-io  task 1  task 2",
    "content": "Short DescriptionNew cool featureValue statementEnable new awesome solutionsArchitectPersonQA MemberPersonComponentsSDKs, Cloud AgentTeam membersx, y, z @essbante-io  task 1  task 2"
  },
  
  {
    "title": "acapy/pr/3237: did:tdw resolver",
    "url": "/github-discussions/acapy/pr/3237/",
    "categories": "OWF",
    "tags": "acapy",
    "date": "2024-09-16 15:01:14 -0700",
    





    
    "snippet": "  Uses the trustdidweb-py library to implement the resolver.  Plugs the resolve endpoint and library into the base_resolver class for caching and future other resolution.",
    "content": "  Uses the trustdidweb-py library to implement the resolver.  Plugs the resolve endpoint and library into the base_resolver class for caching and future other resolution."
  },
  
  {
    "title": "vc-data-model/pr/1560: Making Abstract abstract, instead of introduction",
    "url": "/github-discussions/vc-data-model/pr/1560/",
    "categories": "W3C",
    "tags": "vc-data-model",
    "date": "2024-09-11 08:34:20 -0700",
    





    
    "snippet": "pulled from #1554Preview | Diff",
    "content": "pulled from #1554Preview | Diff"
  },
  
  {
    "title": "indy-vdr/issue/324: [Expo SDK 52][Android] failing with CMake Error at CMakeLists.txt:30 (add_library):",
    "url": "/github-discussions/indy-vdr/issue/324/",
    "categories": "DIF",
    "tags": "indy-vdr",
    "date": "2024-08-29 09:38:05 -0700",
    





    
    "snippet": "After adding the @hyperledger/aries-askar-react-native facing issue in building the package in expo version 52 in androidCMake Error at CMakeLists.txt:30 (add_library):    Target \"ariesaskarreactna...",
    "content": "After adding the @hyperledger/aries-askar-react-native facing issue in building the package in expo version 52 in androidCMake Error at CMakeLists.txt:30 (add_library):    Target \"ariesaskarreactnative\" links to target    \"ReactAndroid::reactnativejni\" but the target was not found.  Perhaps a    find_package() call is missing for an IMPORTED target, or an ALIAS target    is missing?"
  },
  
  {
    "title": "identus-edge-agent-sdk-ts/issue/273: npm install fails",
    "url": "/github-discussions/identus-edge-agent-sdk-ts/issue/273/",
    "categories": "Hyperledger",
    "tags": "identus-edge-agent-sdk-ts",
    "date": "2024-08-25 16:32:42 -0700",
    





    
    "snippet": "Is this a regression?YesDescriptionDoesn’t install happily on a fresh install with npm. Seems to be some typedoc version problems in your repoPlease provide the exception or error you saw➜  ATALA c...",
    "content": "Is this a regression?YesDescriptionDoesn’t install happily on a fresh install with npm. Seems to be some typedoc version problems in your repoPlease provide the exception or error you saw➜  ATALA cd test➜  test npm init -yWrote to /home/fakename/projects/ATALA/test/package.json:{  \"name\": \"test\",  \"version\": \"1.0.0\",  \"description\": \"\",  \"main\": \"index.js\",  \"scripts\": {    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"  },  \"keywords\": [],  \"author\": \"\",  \"license\": \"ISC\"}➜  test npm i @hyperledger/identus-edge-agent-sdknpm WARN deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.npm WARN deprecated rimraf@2.7.1: Rimraf versions prior to v4 are no longer supportednpm WARN deprecated glob@7.2.3: Glob versions prior to v9 are no longer supportednpm WARN deprecated text-encoding@0.7.0: no longer maintainednpm ERR! code 1npm ERR! path /home/fakename/projects/ATALA/test/node_modules/@hyperledger/identus-edge-agent-sdknpm ERR! command failednpm ERR! command sh -c sh preinstall.shnpm ERR! running preinstall in /home/fakename/projects/ATALA/test/node_modules/@hyperledger/identus-edge-agent-sdknpm ERR! npm ERR! code ERESOLVEnpm ERR! npm ERR! ERESOLVE unable to resolve dependency treenpm ERR! npm ERR!npm ERR! npm ERR! While resolving: @hyperledger/identus-edge-agent-sdk@6.0.0npm ERR! npm ERR! Found: typedoc@0.25.13npm ERR! npm ERR! node_modules/typedocnpm ERR! npm ERR!   dev typedoc@\"^0.25.6\" from the root projectnpm ERR! npm ERR!npm ERR! npm ERR! Could not resolve dependency:npm ERR! npm ERR! peer typedoc@\"&gt;=0.26 &lt;2.0\" from typedoc-plugin-external-module-map@2.1.0npm ERR! npm ERR! node_modules/typedoc-plugin-external-module-mapnpm ERR! npm ERR!   dev typedoc-plugin-external-module-map@\"^2.0.1\" from the root projectnpm ERR! npm ERR!npm ERR! npm ERR! Fix the upstream dependency conflict, or retrynpm ERR! npm ERR! this command with --force or --legacy-peer-depsnpm ERR! npm ERR! to accept an incorrect (and potentially broken) dependency resolution.Please provide the environment you discovered this bug in➜  node -vv20.10.0➜  npm -v10.2.3Anything else?:cry:"
  },
  
  {
    "title": "dpv/issue/184: Typos in docs",
    "url": "/github-discussions/dpv/issue/184/",
    "categories": "Hyperledger",
    "tags": "dpv",
    "date": "2024-08-24 10:03:12 -0700",
    





    
    "snippet": "The quick start docs are showing typos.https://github.com/hyperledger/identus-docs/blame/ad4c0a07d4cdb2ca8c369e6dd40e4bd2db2084fc/documentation/docs/quick-start.md#L655",
    "content": "The quick start docs are showing typos.https://github.com/hyperledger/identus-docs/blame/ad4c0a07d4cdb2ca8c369e6dd40e4bd2db2084fc/documentation/docs/quick-start.md#L655"
  },
  
  {
    "title": "dpv/issue/183: Add capability to choose either polling or websocket",
    "url": "/github-discussions/dpv/issue/183/",
    "categories": "DIF",
    "tags": "dpv",
    "date": "2024-08-24 09:58:44 -0700",
    





    
    "snippet": "Proposed featureAdd possibility to choose the mediator connection either from pulling or websocket. Default (if no argument is passed) when starting the connection to the mediator, should be WS if ...",
    "content": "Proposed featureAdd possibility to choose the mediator connection either from pulling or websocket. Default (if no argument is passed) when starting the connection to the mediator, should be WS if availableFeature descriptionEnable user to choose the message receival mechanismAnything else?No response"
  },
  
  {
    "title": "dpv/issue/182: Link in the CONTRIBUTING.md is broken",
    "url": "/github-discussions/dpv/issue/182/",
    "categories": "Hyperledger",
    "tags": "dpv",
    "date": "2024-08-15 01:22:02 -0700",
    





    
    "snippet": "Is this a regression?NoDescriptionSteps:  Got to https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/master/CONTRIBUTING.md  Click on the link on the line 53 “1. Follow all instructio...",
    "content": "Is this a regression?NoDescriptionSteps:  Got to https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/master/CONTRIBUTING.md  Click on the link on the line 53 “1. Follow all instructions in the template”  It will open this browser window: https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/main/.github/PULL_REQUEST_TEMPLATE.mdPlease provide the exception or error you sawThe error is that the file does not exist: 404 - page not foundThe master branch of atala-prism-wallet-sdk-ts does not contain the path CONTRIBUTING.md.Please provide the environment you discovered this bug inOn the GitHub remote site (corresponding to latest version v5.0.0), master branch.Anything else?No"
  },
  
  {
    "title": "dpv/issue/180: I am not able to add v7.0.0 as a working dependency, 6.1.1 works",
    "url": "/github-discussions/dpv/issue/180/",
    "categories": "Hyperledger",
    "tags": "dpv",
    "date": "2024-08-08 07:38:47 -0700",
    





    
    "snippet": "Is this a regression?YesDescriptionIf I add v7.0.0 as a Package Dependency, it never fully resolves, leaving me in a state where I can’t link it to my target, or import it into Swift files.This wor...",
    "content": "Is this a regression?YesDescriptionIf I add v7.0.0 as a Package Dependency, it never fully resolves, leaving me in a state where I can’t link it to my target, or import it into Swift files.This works fine with v6.1.1Please provide the exception or error you sawWhen adding the Swift SDK as a Package Dependency, it should resolve all the packages and it should show the display name of the package.  The package list should allow me to open each package and see its contents. This does not happen with v7.0.0 for me.v6.1.1 works fine.Please provide the environment you discovered this bug inUsing from the 7.0.0 Tag in Xcode Package Dependency screenAnything else?Here is how my Package Dependency screen looks when I tag it to 7.0.0:You can see that the packages aren’t fully resolved:v6.1.1 works fine, shows up as it’s name “EdgeAgentSDK” (not the slug name) :And 6.1.1 can be found when I add it to my Target, 7.0.0 does not load fully so it’s not available to this menu."
  },
  
  {
    "title": "bbs-signature/issue/322: Wallet recovery with a password-protected backup file (from a single point of failure to 2FA) in addition to Seed Phrase Recovery",
    "url": "/github-discussions/bbs-signature/issue/322/",
    "categories": "DIF",
    "tags": "bbs-signature",
    "date": "2024-08-05 15:36:40 -0700",
    





    
    "snippet": "Proposed featureWe propose to contribute to this repository to add a functionality to recover a wallet through a password-protected backup file.We’ve already implemented this on the Socious Wallet....",
    "content": "Proposed featureWe propose to contribute to this repository to add a functionality to recover a wallet through a password-protected backup file.We’ve already implemented this on the Socious Wallet.Demos:Backup wallet flow:https://drive.google.com/file/d/1ae7t0MfNhgFz4FKy3LfLVfibYimfUgR8/view?usp=drivesdkRestore wallet with a password-protected backup file flow:https://drive.google.com/file/d/1qXmEhtN3Z4IEPWdSzdVmRTUZgeOI-mwj/view?usp=drivesdkProblem: The reliance on seed phrase-based wallet recovery is hindering mass adoption.The widespread adoption of blockchain wallets is significantly hindered by the use of seed phrases for wallet recovery. Seed phrases, also known as recovery or mnemonic phrases, are a list of words required to recover a blockchain wallet. This applies to both crypto wallets for token transactions and identity wallets for managing Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). For security reasons, this phrase must be kept confidential[^1^].Backgrounds on seed phrasesSince a private key consists of random binaries, it’s not human-readable, so it must be stored digitally. However, due to hacking risks, BIP39 was created to allow these keys to be written down on paper[^2^].However, the seed phrase being a single point of failure poses several challenges. Firstly, users may forget their seed phrases or misplace the physical copy containing it[^3^]. Secondly, if another person acquires the seed phrase, they can access the wallet and its funds[^4^]. Lastly, non-technical users may find the concept of a seed phrase difficult to comprehend and manage[^5^].These challenges are discussed in several sources. For instance, [this Cointelegraph article](https://cointelegraph.com/learn/how-to-recover-a-crypto-wallet) states that seed phrase recovery is a hindrance to mass adoption: “As the Web3 space looks to onboard its first billion users, intuitive wallet experiences are critical. Seed phrases are a hindrance to that experience.” In addition, [this Blockworks article](https://blockworks.co/news/what-are-seed-phrases) states that seed phrases have become a “major pain point for users”.Currently, the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) only supports wallet recovery based on seed phrases. This limitation hinders mass adoption.Alternatives to seed phrase-based recovery:Two primary alternatives to seed phrase-based recovery exist: social recovery and multifactor recovery involving backup files. Social recovery, which has been endorsed by Ethereum co-founder Vitalik Buterin[^1^], utilizes trusted contacts to help users regain access to their accounts. A prominent example of a wallet employing this method is the Argent wallet[^2^].On the other hand, multifactor recovery involves the use of backup files in addition to other authentication measures. Wallets using this method are rare, especially within the Cardano ecosystem. However, some examples do exist outside of it. For instance, the [Dock.io](http://dock.io/) identity wallet uses a recovery system involving a password-protected backup file[^3^]. Our plan includes implementing a similar solution to enhance the security and user experience of our wallet.See also:https://wirexapp.com/https://www.cypherock.com/features/no-backuphttps://medium.com/@bitizenwallet/private-keys-single-point-of-failure-a20b5f00a67dSolution: We improve the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase.The solution aims to address the vulnerability of seed phrases by enhancing the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase. Essentially, this wallet eliminates a single point of failure through the use of two-factor authentication, i.e., a password and a backup file. Consequently, even if someone acquires your backup file, they can’t decrypt it without your password. Similarly, a password alone is useless without access to your backup file. Moreover, you can always change your password. Implementing two-factor authentication for recovery significantly improves both security and user experience.Wallets with multi-factor authentication are rare, but they do exist outside the Cardano ecosystem. For example, the [Dock.io](http://dock.io/) identity wallet uses a recovery system with a [password-protected backup file](https://drive.google.com/file/d/1qatflQ6aDrQOqx8QlBtda5GlnILuckyV/view?usp=drive_link). We plan to implement a similar solution.Specifically, we will contribute to the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) repository. We aim to add new features without affecting the existing wallet recovery feature which uses seed phrases. The new features include the following:  Users do not see seed phrases when creating a wallet.  Users see an alert: “Please secure your wallet by backing up the wallet”.  Users select a secure password to encrypt the backup file.  Users have the freedom to save the backup file wherever they prefer, including on an external hard drive or cloud.  Users can restore a wallet by decrypting the backup file with the password.This plan has been discussed with IOG’s Atala PRISM team. They have confirmed that this improvement is not part of their roadmap and would welcome this additional feature to the SDK.This solution allows projects in the Cardano ecosystem to create their own wallets using this SDK. They can use a password-protected backup file for wallet recovery. This method is not only user-friendly but also secure. It will contribute to the widespread adoption of identity wallets and Self-Sovereign Identity.With this enhanced SDK, we’ll boost Socious Wallet’s security by shifting from seed phrase recovery to multifactor file backup recovery. This will let end-users enjoy the advantages of SSI, DID, and VC without the complexity of managing seed phrases or the risk of a single point of failure. Upon completion of this project, users will have a secure identity wallet on their iOS and Android mobile devices without the need to manage seed phrases.Feature descriptionWe propose to contribute to this repository to add a functionality to recover a wallet through a password-protected backup file.We’ve already implemented this on the Socious Wallet.Demos:Backup wallet flow:https://drive.google.com/file/d/1ae7t0MfNhgFz4FKy3LfLVfibYimfUgR8/view?usp=drivesdkRestore wallet with a password-protected backup file flow:https://drive.google.com/file/d/1qXmEhtN3Z4IEPWdSzdVmRTUZgeOI-mwj/view?usp=drivesdkProblem: The reliance on seed phrase-based wallet recovery is hindering mass adoption.The widespread adoption of blockchain wallets is significantly hindered by the use of seed phrases for wallet recovery. Seed phrases, also known as recovery or mnemonic phrases, are a list of words required to recover a blockchain wallet. This applies to both crypto wallets for token transactions and identity wallets for managing Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). For security reasons, this phrase must be kept confidential[^1^].Backgrounds on seed phrasesSince a private key consists of random binaries, it’s not human-readable, so it must be stored digitally. However, due to hacking risks, BIP39 was created to allow these keys to be written down on paper[^2^].However, the seed phrase being a single point of failure poses several challenges. Firstly, users may forget their seed phrases or misplace the physical copy containing it[^3^]. Secondly, if another person acquires the seed phrase, they can access the wallet and its funds[^4^]. Lastly, non-technical users may find the concept of a seed phrase difficult to comprehend and manage[^5^].These challenges are discussed in several sources. For instance, [this Cointelegraph article](https://cointelegraph.com/learn/how-to-recover-a-crypto-wallet) states that seed phrase recovery is a hindrance to mass adoption: “As the Web3 space looks to onboard its first billion users, intuitive wallet experiences are critical. Seed phrases are a hindrance to that experience.” In addition, [this Blockworks article](https://blockworks.co/news/what-are-seed-phrases) states that seed phrases have become a “major pain point for users”.Currently, the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) only supports wallet recovery based on seed phrases. This limitation hinders mass adoption.Alternatives to seed phrase-based recovery:Two primary alternatives to seed phrase-based recovery exist: social recovery and multifactor recovery involving backup files. Social recovery, which has been endorsed by Ethereum co-founder Vitalik Buterin[^1^], utilizes trusted contacts to help users regain access to their accounts. A prominent example of a wallet employing this method is the Argent wallet[^2^].On the other hand, multifactor recovery involves the use of backup files in addition to other authentication measures. Wallets using this method are rare, especially within the Cardano ecosystem. However, some examples do exist outside of it. For instance, the [Dock.io](http://dock.io/) identity wallet uses a recovery system involving a password-protected backup file[^3^]. Our plan includes implementing a similar solution to enhance the security and user experience of our wallet.See also:https://wirexapp.com/https://www.cypherock.com/features/no-backuphttps://medium.com/@bitizenwallet/private-keys-single-point-of-failure-a20b5f00a67dSolution: We improve the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase.The solution aims to address the vulnerability of seed phrases by enhancing the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase. Essentially, this wallet eliminates a single point of failure through the use of two-factor authentication, i.e., a password and a backup file. Consequently, even if someone acquires your backup file, they can’t decrypt it without your password. Similarly, a password alone is useless without access to your backup file. Moreover, you can always change your password. Implementing two-factor authentication for recovery significantly improves both security and user experience.Wallets with multi-factor authentication are rare, but they do exist outside the Cardano ecosystem. For example, the [Dock.io](http://dock.io/) identity wallet uses a recovery system with a [password-protected backup file](https://drive.google.com/file/d/1qatflQ6aDrQOqx8QlBtda5GlnILuckyV/view?usp=drive_link). We plan to implement a similar solution.Specifically, we will contribute to the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) repository. We aim to add new features without affecting the existing wallet recovery feature which uses seed phrases. The new features include the following:  Users do not see seed phrases when creating a wallet.  Users see an alert: “Please secure your wallet by backing up the wallet”.  Users select a secure password to encrypt the backup file.  Users have the freedom to save the backup file wherever they prefer, including on an external hard drive or cloud.  Users can restore a wallet by decrypting the backup file with the password.This plan has been discussed with IOG’s Atala PRISM team. They have confirmed that this improvement is not part of their roadmap and would welcome this additional feature to the SDK.This solution allows projects in the Cardano ecosystem to create their own wallets using this SDK. They can use a password-protected backup file for wallet recovery. This method is not only user-friendly but also secure. It will contribute to the widespread adoption of identity wallets and Self-Sovereign Identity.With this enhanced SDK, we’ll boost Socious Wallet’s security by shifting from seed phrase recovery to multifactor file backup recovery. This will let end-users enjoy the advantages of SSI, DID, and VC without the complexity of managing seed phrases or the risk of a single point of failure. Upon completion of this project, users will have a secure identity wallet on their iOS and Android mobile devices without the need to manage seed phrases.Anything else?No response"
  },
  
  {
    "title": "did-resolution/issue/80: Failed deployment is shown as successful",
    "url": "/github-discussions/did-resolution/issue/80/",
    "categories": "DIF",
    "tags": "did-resolution",
    "date": "2024-07-29 09:04:08 -0700",
    





    
    "snippet": "In order to deploy the docs corresponding to prism v2.9, https://github.com/input-output-hk/atala-releases/blob/master/Atala%20PRISM/2.9.md, I have chosen the wrong version (OEA version instead of ...",
    "content": "In order to deploy the docs corresponding to prism v2.9, https://github.com/input-output-hk/atala-releases/blob/master/Atala%20PRISM/2.9.md, I have chosen the wrong version (OEA version instead of the documentation version).In https://github.com/input-output-hk/atala-prism-docs/actions, click on Deployment and then Run workflowI chose: main branch, v1.25.0 and production and click Run workflow.It gave a successful deployment when looking after but the docs.atalaprism.io was still not updated as it showed in API –&gt; Agent API the same old version v1.22.0. See attached screenshot.The expectation is that as the workflow failed, the status should show as failed. If you look at the workflow file, there is no information that would give any indication of what was run.If you look at the https://github.com/input-output-hk/atala-prism-docs/actions/runs/7959863521/job/21727672596 , there is no information on the parsing of the version for example."
  },
  
  {
    "title": "identus-apollo/pr/185: chore(deps-dev): Bump indy-vdr from 0.3.4 to 0.4.1 in /rpc",
    "url": "/github-discussions/identus-apollo/pr/185/",
    "categories": "Hyperledger",
    "tags": "identus-apollo",
    "date": "2024-07-18 10:25:42 -0700",
    





    
    "snippet": "Bumps indy-vdr from 0.3.4 to 0.4.1.Release notesSourced from indy-vdr's releases.v0.4.1What's Changedfix(js): add missing parameters to rn wrapper by @​genaris in hyperledger/indy-vdr#218Update to ...",
    "content": "Bumps indy-vdr from 0.3.4 to 0.4.1.Release notesSourced from indy-vdr's releases.v0.4.1What's Changedfix(js): add missing parameters to rn wrapper by @​genaris in hyperledger/indy-vdr#218Update to indy-data-types 0.7; remove indy-utils by @​andrewwhitehead in hyperledger/indy-vdr#224fix a typo in logs by @​xiaolou86 in hyperledger/indy-vdr#231fix(js): use quotes instead of brackets for local dependencies by @​berendsliedrecht in hyperledger/indy-vdr#232fix(js): use universal architecture for darwin by @​berendsliedrecht in hyperledger/indy-vdr#233fix(rn): do not try to deserialize again if it is a stream by @​berendsliedrecht in hyperledger/indy-vdr#234Faster pool refresh by @​andrewwhitehead in hyperledger/indy-vdr#242Add genesis transactions caching by @​andrewwhitehead in hyperledger/indy-vdr#243genesis cache js by @​berendsliedrecht in hyperledger/indy-vdr#244Update setup.py by @​tnkhanh in hyperledger/indy-vdr#245New Contributors@​xiaolou86 made their first contribution in hyperledger/indy-vdr#231@​tnkhanh made their first contribution in hyperledger/indy-vdr#245Full Changelog: https://github.com/hyperledger/indy-vdr/compare/v0.4.0...v0.4.1v0.4.0Added support for did:indy in hyperledger/indy-vdr#166, thanks to @​domwoe, @​c2boAdded new nodejs and react-native wrappers, thanks to @​berendsliedrecht, @​TimoGlastra, @​karimStekelenburg, @​genaris, @​mrluninSwitched from Ursa (now archived) to indy-blssignaturesAdded builder for POOL_UPGRADE request into FFI and Python by @​Artemkaaas in hyperledger/indy-vdr#148Proxy client by @​mirgee in hyperledger/indy-vdr#184Support HTTPS by @​mirgee in hyperledger/indy-vdr#187Issue #210 InvalidClientTaaAcceptanceError time too precise error if container timezone is not UTC by @​Ennovate-com in hyperledger/indy-vdr#211Fix minor typos by @​omahs in hyperledger/indy-vdr#213Now publishing arm64 packagesFull Changelog: https://github.com/hyperledger/indy-vdr/compare/v0.3.4...v0.4.0v0.4.0-dev.16What's Changedfix(rn): android works with JSC and Hermes by @​blu3beri in hyperledger/indy-vdr#194chore: update version by @​blu3beri in hyperledger/indy-vdr#195Full Changelog: https://github.com/hyperledger/indy-vdr/compare/v0.4.0-dev.15...v0.4.0-dev.16v0.4.0-dev.15What's Changedfix(nodejs): compatible with Windows builds by @​blu3beri in hyperledger/indy-vdr#183feat: react native 0.71.x and Expo support by @​blu3beri in hyperledger/indy-vdr#186build(android): use custom cross images by @​blu3beri in hyperledger/indy-vdr#189chore: update version by @​blu3beri in hyperledger/indy-vdr#190build(js): use local network by @​blu3beri in hyperledger/indy-vdr#192Full Changelog: https://github.com/hyperledger/indy-vdr/compare/v0.4.0-dev.14...v0.4.0-dev.15... (truncated)Commitsc4b558c Merge pull request #247 from andrewwhitehead/upd/ver-0410d97507 use lockfile when installing cross162a1f3 update proxy version to 0.1.5a198344 update python wrapper version to 0.4.183f3507 Merge pull request #245 from tnkhanh/patch-1fb2bbbe Merge branch 'main' into patch-1f70a6d8 Merge pull request #244 from berendsliedrecht/genesis-cache-js9695a17 Merge branch 'main' into genesis-cache-jsa914ef4 Merge pull request #243 from andrewwhitehead/feat/genesis-cachecc7e2bb Update setup.pyAdditional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "tswg-keri-specification/issue/199: Adding concepts from the EU General-Purpose AI Code of Practice",
    "url": "/github-discussions/tswg-keri-specification/issue/199/",
    "categories": "DIF",
    "tags": "tswg-keri-specification",
    "date": "2024-07-13 22:41:43 -0700",
    





    
    "snippet": "Adding concepts from the EU General-Purpose AI Code of Practice upon its publication (expected to be published  in April 2025).",
    "content": "Adding concepts from the EU General-Purpose AI Code of Practice upon its publication (expected to be published  in April 2025)."
  },
  
  {
    "title": "dwn-user-guide/issue/3: Adding labels and triage process",
    "url": "/github-discussions/dwn-user-guide/issue/3/",
    "categories": "DIF",
    "tags": "dwn-user-guide",
    "date": "2024-07-10 10:51:17 -0700",
    





    
    "snippet": "Is your feature request related to a problem? Please describe.As the number of contributors is growing, the number of issues is growing. We need a triage process with a labelling system in place.De...",
    "content": "Is your feature request related to a problem? Please describe.As the number of contributors is growing, the number of issues is growing. We need a triage process with a labelling system in place.Describe the solution you’d likeLabels to be added in contributing.md (or another file that will be referred in contributing triage part) in Identus repo.Each label should have a prefix: for example:  Type: bug, docs, enhancement, support, research, maintenance, chore, ci, refactor, perf, test  Priority: critical, major, normal, minor  Component: cloud-agent, infrastructure, mediator, edge-agent-SDK-swift, edge-agent-SDK-KMP, edge-agent-SDK-TS, node, VDR, …  Team: marketing, product, engineering, management, dev-ops, security  Triage: needs-repro, needs-fix, stale, good-first-issue/up-for-graps, help-wanted, question/query, tech-debt  Closed: out-of-scope, can’t-repro, duplicate, won’t-fix, design-limitation  Status: new, ready, in-review, in-progress, fixed, qa-ready, qa-progress, qa-support (to indicate QA team needs support), stale, done/closed/terminatedColors for labels should follow a rule to be described.Each label should have a description associated to it.All Identus repos will use the same labels.Triage process needs to be written down: Have a look at Identus Technical Charter as reference first.Describe alternatives you’ve consideredWe need to check if the status are labels or customised fields.Best practices to be looked at as well so the solution is practical.Additional contextThe triage should be efficient and regularly done (recommendation is every 2 days) and it should be linked closely to the release process and cadence.Follow: https://docs.github.com/en/issues/using-labels-and-milestones-to-track-work/managing-labelsUse Conventional commit to match some labels"
  },
  
  {
    "title": "dwn-user-guide/issue/2: Threat model / Trust over IP introduction",
    "url": "/github-discussions/dwn-user-guide/issue/2/",
    "categories": "DIF",
    "tags": "dwn-user-guide",
    "date": "2024-07-10 10:48:23 -0700",
    





    
    "snippet": "(With caveat that I’m writing this after having read only from start to the end of section 2.2.4, and read the last use-case, and that perhaps somewhere in between lies the key to this issue. If th...",
    "content": "(With caveat that I’m writing this after having read only from start to the end of section 2.2.4, and read the last use-case, and that perhaps somewhere in between lies the key to this issue. If that is the case, it means that the key needs to be brought earlier. If not, disregard the caveat and proceed to reading the below as though I had finished proof-reading the entire doc.)If the Threat Model summarized in the last use-case is of importance, I suggest it be more clearly stated.It is introduced at the very end of section 2.2.4 by a Note that says “W3C is handling this issue with a Threat Model.” (which is problematic as it implies endorsement; see #1 )But then the use case merely summarizes a 35-page document that lacks a clear standing and is hosted elsewhere.There is a discrepancy between the implied endorsement of a threat model and a use-case which summarizes what appears to be introductory slides from 2021.If the threat model that is summarized is what the W3C Team recommends “W3C as an org” considers to handle the issue, then it needs to be framed in such a way. Furthermore, for the recommendation to have teeth, the reader has to understand the path W3C would take to handle the issue and to trust the threat model’s standing.Also “the issue” is unclear. Re-reading again section 2.2.4, it appears that “the issue” is [from the first “note” in this section] “enabling this technological innovation by being aware of the threats to Privacy, security, and Human Rights”, where “this technological innovation” refers to “digital identities and credentials”."
  },
  
  {
    "title": "identus-apollo/pr/179: chore(deps-dev): Update ruff requirement from ^0.1.2 to ^0.3.0 in /plugin_globals",
    "url": "/github-discussions/identus-apollo/pr/179/",
    "categories": "Hyperledger",
    "tags": "identus-apollo",
    "date": "2024-07-09 02:58:01 -0700",
    





    
    "snippet": "Updates the requirements on ruff to permit the latest version.Release notesSourced from ruff's releases.v0.3.0This release introduces the new Ruff formatter 2024.2 style and adds a new lint rule to...",
    "content": "Updates the requirements on ruff to permit the latest version.Release notesSourced from ruff's releases.v0.3.0This release introduces the new Ruff formatter 2024.2 style and adds a new lint rule todetect invalid formatter suppression comments.ChangesPreview features[flake8-bandit] Remove suspicious-lxml-import (S410) (#10154)[pycodestyle] Allow os.environ modifications between imports (E402) (#10066)[pycodestyle] Don't warn about a single whitespace character before a comma in a tuple (E203) (#10094)Rule changes[eradicate] Detect commented out case statements (ERA001) (#10055)[eradicate] Detect single-line code for try:, except:, etc. (ERA001) (#10057)[flake8-boolean-trap] Allow boolean positionals in __post_init__ (#10027)[flake8-copyright] Allow © in copyright notices (#10065)[isort]: Use one blank line after imports in typing stub files (#9971)[pylint] New Rule dict-iter-missing-items (PLE1141) (#9845)[pylint] Ignore sys.version and sys.platform (PLR1714) (#10054)[pyupgrade] Detect literals with unary operators (UP018) (#10060)[ruff] Expand rule for list(iterable).pop(0) idiom (RUF015) (#10148)FormatterThis release introduces the Ruff 2024.2 style, stabilizing the following changes:Prefer splitting the assignment's value over the target or type annotation (#8943)Remove blank lines before class docstrings (#9154)Wrap multiple context managers in with parentheses when targeting Python 3.9 or newer (#9222)Add a blank line after nested classes with a dummy body (...) in typing stub files (#9155)Reduce vertical spacing for classes and functions with a dummy (...) body (#7440, #9240)Add a blank line after the module docstring (#8283)Parenthesize long type hints in assignments (#9210)Preserve indent for single multiline-string call-expressions (#9673)Normalize hex escape and unicode escape sequences (#9280)Format module docstrings (#9725)CLIExplicitly disallow extend as part of a --config flag (#10135)Remove build from the default exclusion list (#10093)Deprecate ruff &lt;path&gt;, ruff --explain, ruff --clean, and ruff --generate-shell-completion in favor of ruff check &lt;path&gt;, ruff rule, ruff clean, and ruff generate-shell-completion (#10169)Remove the deprecated CLI option --format from ruff rule and ruff linter (#10170)Bug fixes[flake8-bugbear] Avoid adding default initializers to stubs (B006) (#10152)[flake8-type-checking] Respect runtime-required decorators for function signatures (#10091)... (truncated)ChangelogSourced from ruff's changelog.0.3.0This release introduces the new Ruff formatter 2024.2 style and adds a new lint rule todetect invalid formatter suppression comments.Preview features[flake8-bandit] Remove suspicious-lxml-import (S410) (#10154)[pycodestyle] Allow os.environ modifications between imports (E402) (#10066)[pycodestyle] Don't warn about a single whitespace character before a comma in a tuple (E203) (#10094)Rule changes[eradicate] Detect commented out case statements (ERA001) (#10055)[eradicate] Detect single-line code for try:, except:, etc. (ERA001) (#10057)[flake8-boolean-trap] Allow boolean positionals in __post_init__ (#10027)[flake8-copyright] Allow © in copyright notices (#10065)[isort]: Use one blank line after imports in typing stub files (#9971)[pylint] New Rule dict-iter-missing-items (PLE1141) (#9845)[pylint] Ignore sys.version and sys.platform (PLR1714) (#10054)[pyupgrade] Detect literals with unary operators (UP018) (#10060)[ruff] Expand rule for list(iterable).pop(0) idiom (RUF015) (#10148)FormatterThis release introduces the Ruff 2024.2 style, stabilizing the following changes:Prefer splitting the assignment's value over the target or type annotation (#8943)Remove blank lines before class docstrings (#9154)Wrap multiple context managers in with parentheses when targeting Python 3.9 or newer (#9222)Add a blank line after nested classes with a dummy body (...) in typing stub files (#9155)Reduce vertical spacing for classes and functions with a dummy (...) body (#7440, #9240)Add a blank line after the module docstring (#8283)Parenthesize long type hints in assignments (#9210)Preserve indent for single multiline-string call-expressions (#9673)Normalize hex escape and unicode escape sequences (#9280)Format module docstrings (#9725)CLIExplicitly disallow extend as part of a --config flag (#10135)Remove build from the default exclusion list (#10093)Deprecate ruff &lt;path&gt;, ruff --explain, ruff --clean, and ruff --generate-shell-completion in favor of ruff check &lt;path&gt;, ruff rule, ruff clean, and ruff generate-shell-completion (#10169)Remove the deprecated CLI option --format from ruff rule and ruff linter (#10170)Bug fixes[flake8-bugbear] Avoid adding default initializers to stubs (B006) (#10152)[flake8-type-checking] Respect runtime-required decorators for function signatures (#10091)[pycodestyle] Mark fixes overlapping with a multiline string as unsafe (W293) (#10049)... (truncated)Commitsb53118e Bump version to v0.3.0 (#10151)52f4c1e Remove deprecated CLI option --format (#10170)eceffe7 Deprecate ruff \\&lt;path&gt; ruff --explain, ruff --clean and `ruff --generate...c73c497 [pydocstyle] Trim whitespace when removing blank lines after section (`D413...c9c98c4 Fix mkdocs local link (#10167)72ccb34 Fix ecosystem check for indico (#10164)dcc92f5 Update black tests (#10166)a6f32dd Ruff 2024.2 style (#9639)0293908 Implement RUF028 to detect useless formatter suppression comments (#9899)36bc725 [flake8-bugbear] Avoid adding default initializers to stubs (B006) (#10152)Additional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "credential-schemas/issue/4: Add the identus release process",
    "url": "/github-discussions/credential-schemas/issue/4/",
    "categories": "DIF",
    "tags": "credential-schemas",
    "date": "2024-07-03 16:27:23 -0700",
    





    
    "snippet": "Is your feature request related to a problem? Please describe.Identus is an eco-system and the release process should be described in this repository. Explaining who and what steps are being follow...",
    "content": "Is your feature request related to a problem? Please describe.Identus is an eco-system and the release process should be described in this repository. Explaining who and what steps are being followed.See ATL-7060 as well.Describe the solution you’d likeMake a release vx.y:  Go to Identus repo hyperledger/identus  Check the latest release version; it should be Identus va.b format. E.g Identus v2.12.  Click on Release and Draft a new release button          In Choose a tag button, create the tag vx.y      Target = main      Previous tag Auto        Click on Generate change log: this will generate the log for this repository only, which should be reviewed.  Fill the release note in this change log,          Copy the template (from the previous release if a template file is not existing yet)      For each component, add the change log according to each component (it should be already available from the component release).      Select Set as a pre-release and click on Save Draft        Ask component owner to review: this is the critical step. The release owner should get an approval from each of the component: Cloud Agent, Edge Agent SDK Swift, KMP, TS, Mediator, Node, Docs.Note: This is not that convenient as having a PR where all can contribute: see alternatives considered  Ask QA team to validate the release by confirming there is no regression and critical bugs have been fixed.  Once all component owners have accepted (with a check in the release note? TBC)), publish the release by editing it and unselect Set as a pre-release and click on Publish release button: the release Identus vx.y should be seen as the latest; if not, fix it.Describe alternatives you’ve considered  Previously, we have a file and a PR was submitted for review. See atala-releases.  We should have a nice way to get the feedback from the component owners, maybe with a checkbox in the release.Or a PR can be actually raise, with the checkbox that all the component owners have reviewed. Only then, the release is accepted. We shall have also the QA team to validate the eco-system.  Using automated release would be a nice follow-up iteration.Additional contextUntil Identus v2.12, the release was done as a PR in another repository: https://github.com/input-output-hk/atala-releases"
  },
  
  {
    "title": "identus/issue/22: Implement user level events in SDKs",
    "url": "/github-discussions/identus/issue/22/",
    "categories": "DIF",
    "tags": "identus",
    "date": "2024-07-03 06:27:43 -0700",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "did-core/issue/855: Simplify abstract data model to be more concrete",
    "url": "/github-discussions/did-core/issue/855/",
    "categories": "Hyperledger",
    "tags": "did-core",
    "date": "2024-07-01 06:07:19 -0700",
    





    
    "snippet": "It has been suggested that the abstract data model in DID Core creates unnecessary complexity and that a more concrete data model should be selected, based on implementation experience over the pas...",
    "content": "It has been suggested that the abstract data model in DID Core creates unnecessary complexity and that a more concrete data model should be selected, based on implementation experience over the past two years. This issue is to track the discussion of how that simplification might occur."
  },
  
  {
    "title": "linked-vp/issue/53: DWN (Decentralized Web Node)",
    "url": "/github-discussions/linked-vp/issue/53/",
    "categories": "DIF",
    "tags": "linked-vp",
    "date": "2024-06-30 05:28:40 -0700",
    





    
    "snippet": "Is your feature request related to a problem? Please describe.Expanding Identus capabilities through seamless connectivity with decentralized web nodes, enabling a versatile and distributed self-so...",
    "content": "Is your feature request related to a problem? Please describe.Expanding Identus capabilities through seamless connectivity with decentralized web nodes, enabling a versatile and distributed self-sovereign identity ecosystem.Describe the solution you’d likeIntegrating Identus agents with decentralized web nodes enhances the self-sovereign identity ecosystem by offering diverse features and functionality across multiple DID methods and verifiable credential formats. Our Users benefit from an enriched experience with expanded capabilities such as integrated payments, autonomous credential exchange based on defined ACLs and rules, and customizable interfaces and hooks. For example, machine learning and artificial intelligence are moving towards intelligent Identus agents. This versatile solution fosters a more resilient, distributed, and innovative identity management platform that caters to the evolving needs of the decentralized web.  #54  #55  #56  #57  #58  #59"
  },
  
  {
    "title": "did-extensions/issue/565: Should there be a registry? Process to migrate to a W3C Registry?",
    "url": "/github-discussions/did-extensions/issue/565/",
    "categories": "W3C",
    "tags": "did-extensions",
    "date": "2024-06-27 08:52:48 -0700",
    





    
    "snippet": "Please share your ideas.",
    "content": "Please share your ideas."
  },
  
  {
    "title": "anoncreds-rs/pr/342: chore(deps): Bump idna from 3.6 to 3.7 in /basicmessage_storage",
    "url": "/github-discussions/anoncreds-rs/pr/342/",
    "categories": "Hyperledger",
    "tags": "anoncreds-rs",
    "date": "2024-06-26 08:45:48 -0700",
    





    
    "snippet": "Bumps idna from 3.6 to 3.7.Release notesSourced from idna's releases.v3.7What's ChangedFix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. ...",
    "content": "Bumps idna from 3.6 to 3.7.Release notesSourced from idna's releases.v3.7What's ChangedFix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. [CVE-2024-3651]Thanks to Guido Vranken for reporting the issue.Full Changelog: https://github.com/kjd/idna/compare/v3.6...v3.7ChangelogSourced from idna's changelog.3.7 (2024-04-11)++++++++++++++++Fix issue where specially crafted inputs to encode() couldtake exceptionally long amount of time to process. [CVE-2024-3651]Thanks to Guido Vranken for reporting the issue.Commits1d365e1 Release v3.7c1b3154 Merge pull request #172 from kjd/optimize-contextj0394ec7 Merge branch 'master' into optimize-contextjcd58a23 Merge pull request #152 from elliotwutingfeng/dev5beb28b More efficient resolution of joiner contexts1b12148 Update ossf/scorecard-action to v2.3.1d516b87 Update Github actions/checkout to v4c095c75 Merge branch 'master' into dev60a0a4c Fix typo in GitHub Actions workflow key5918a0e Merge branch 'master' into devAdditional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hyperledger/aries-acapy-plugins/network/alerts).&lt;/details&gt;"
  },
  
  {
    "title": "bbs-signature/pr/320: chore(deps-dev): Bump ruff from 0.1.15 to 0.3.5 in /rpc",
    "url": "/github-discussions/bbs-signature/pr/320/",
    "categories": "DIF",
    "tags": "bbs-signature",
    "date": "2024-06-25 08:38:48 -0700",
    





    
    "snippet": "Bumps ruff from 0.1.15 to 0.3.5.Release notesSourced from ruff's releases.v0.3.5ChangesPreview features[pylint] Implement modified-iterating-set (E4703) (#10473)[refurb] Implement for-loop-set-muta...",
    "content": "Bumps ruff from 0.1.15 to 0.3.5.Release notesSourced from ruff's releases.v0.3.5ChangesPreview features[pylint] Implement modified-iterating-set (E4703) (#10473)[refurb] Implement for-loop-set-mutations (FURB142) (#10583)[refurb] Implement unnecessary-from-float (FURB164) (#10647)[refurb] Implement verbose-decimal-constructor (FURB157) (#10533)Rule changes[flake8-comprehensions] Handled special case for C401 which also matches C416 (#10596)[flake8-pyi] Mark unaliased-collections-abc-set-import fix as &quot;safe&quot; for more cases in stub files (PYI025) (#10547)[numpy] Add row_stack to NumPy 2.0 migration rule (#10646)[pycodestyle] Allow cell magics before an import (E402) (#10545)[pycodestyle] Avoid blank line rules for the first logical line in cell (#10291)ConfigurationRespected nested namespace packages (#10541)[flake8-boolean-trap] Add setting for user defined allowed boolean trap (#10531)Bug fixesCorrectly handle references in __all__ definitions when renaming symbols in autofixes (#10527)Track ranges of names inside __all__ definitions (#10525)[flake8-bugbear] Avoid false positive for usage after continue (B031) (#10539)[flake8-copyright] Accept commas in default copyright pattern (#9498)[flake8-datetimez] Allow f-strings with %z for DTZ007 (#10651)[flake8-pytest-style] Fix PT014 autofix for last item in list (#10532)[flake8-quotes] Ignore Q000, Q001 when string is inside forward ref (#10585)[isort] Always place non-relative imports after relative imports (#10669)[isort] Respect Unicode characters in import sorting (#10529)[pyflakes] Fix F821 false negatives when from __future__ import annotations is active (attempt 2) (#10524)[pyflakes] Make unnecessary-lambda an always-unsafe fix (#10668)[pylint] Fixed false-positive on the rule PLW1641 (eq-without-hash) (#10566)[ruff] Fix panic in unused # noqa removal with multi-byte space (RUF100) (#10682)DocumentationAdd PR title format to CONTRIBUTING.md (#10665)Fix list markup to include blank lines required (#10591)Put flake8-logging next to the other flake8 plugins in registry (#10587)[flake8-bandit] Update warning message for rule S305 to address insecure block cipher mode use (#10602)[flake8-bugbear] Document use of anonymous assignment in useless-expression (#10551)[flake8-datetimez] Clarify error messages and docs for DTZ rules (#10621)[pycodestyle] Use same before vs. after numbers for space-around-operator (#10640)[ruff] Change quadratic-list-summation docs to use iadd consistently (#10666)... (truncated)ChangelogSourced from ruff's changelog.0.3.5Preview features[pylint] Implement modified-iterating-set (E4703) (#10473)[refurb] Implement for-loop-set-mutations (FURB142) (#10583)[refurb] Implement unnecessary-from-float (FURB164) (#10647)[refurb] Implement verbose-decimal-constructor (FURB157) (#10533)Rule changes[flake8-comprehensions] Handled special case for C401 which also matches C416 (#10596)[flake8-pyi] Mark unaliased-collections-abc-set-import fix as &quot;safe&quot; for more cases in stub files (PYI025) (#10547)[numpy] Add row_stack to NumPy 2.0 migration rule (#10646)[pycodestyle] Allow cell magics before an import (E402) (#10545)[pycodestyle] Avoid blank line rules for the first logical line in cell (#10291)ConfigurationRespected nested namespace packages (#10541)[flake8-boolean-trap] Add setting for user defined allowed boolean trap (#10531)Bug fixesCorrectly handle references in __all__ definitions when renaming symbols in autofixes (#10527)Track ranges of names inside __all__ definitions (#10525)[flake8-bugbear] Avoid false positive for usage after continue (B031) (#10539)[flake8-copyright] Accept commas in default copyright pattern (#9498)[flake8-datetimez] Allow f-strings with %z for DTZ007 (#10651)[flake8-pytest-style] Fix PT014 autofix for last item in list (#10532)[flake8-quotes] Ignore Q000, Q001 when string is inside forward ref (#10585)[isort] Always place non-relative imports after relative imports (#10669)[isort] Respect Unicode characters in import sorting (#10529)[pyflakes] Fix F821 false negatives when from __future__ import annotations is active (attempt 2) (#10524)[pyflakes] Make unnecessary-lambda an always-unsafe fix (#10668)[pylint] Fixed false-positive on the rule PLW1641 (eq-without-hash) (#10566)[ruff] Fix panic in unused # noqa removal with multi-byte space (RUF100) (#10682)DocumentationAdd PR title format to CONTRIBUTING.md (#10665)Fix list markup to include blank lines required (#10591)Put flake8-logging next to the other flake8 plugins in registry (#10587)[flake8-bandit] Update warning message for rule S305 to address insecure block cipher mode use (#10602)[flake8-bugbear] Document use of anonymous assignment in useless-expression (#10551)[flake8-datetimez] Clarify error messages and docs for DTZ rules (#10621)[pycodestyle] Use same before vs. after numbers for space-around-operator (#10640)[ruff] Change quadratic-list-summation docs to use iadd consistently (#10666)0.3.4... (truncated)Commits200ebee Bump version to v0.3.5 (#10717)23e8279 chore(deps): update npm development dependencies (#10716)221b323 chore(deps): update strum to 0.26.0 (#10715)a0e1544 chore(deps): update rust crate pep440_rs to 0.5.0 (#10703)2740fab Renovate: group all strum dependencies together (#10714)7042b9b fix(deps): update rust crate similar to v2.5.0 (#10711)4047d45 chore(deps): update rust crate insta to v1.38.0 (#10701)20d69ea chore(deps): update npm development dependencies (#10697)d021cac chore(deps): update rust crate tracing-tree to 0.3.0 (#10709)46369d4 chore(deps): update rust crate uuid to v1.8.0 (#10710)Additional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "json-ld-syntax/issue/436: URI in Profile triggers CORS Unsafe Request Header Byte rule",
    "url": "/github-discussions/json-ld-syntax/issue/436/",
    "categories": "DIF",
    "tags": "json-ld-syntax",
    "date": "2024-06-24 14:08:08 -0700",
    





    
    "snippet": "In the IANA registration [1], we define a media type parameter called ‘profile’. Its value is a space separated list of URIs, for which we registered six initial values. These can be composed toget...",
    "content": "In the IANA registration [1], we define a media type parameter called ‘profile’. Its value is a space separated list of URIs, for which we registered six initial values. These can be composed together, and new values can be added for other “constraints or conventions”.The IIIF specifications use this functionality, for example to define the specific structure of the response in an API [2] as part of the media type. Similarly in Linked Art, we do the same [3].However, in the WHATWG specification for fetch [4], it says that the value for the Accept header is NOT CORS safe, if it has more than 128 bytes (which multiple URIs might easily cause) or (more importantly) if the value contains an unsafe header byte. The unsafe header bytes include the character “:” … which prevents any URI or CURIE with a namespace prefix separate by : from being CORS safe.This means that we cannot use the JSON-LD media type as registered for content negotiation via the accept header according to the fetch specification, which was much of the rationale for the profile parameter.To resolve this, either WHATWG would need to change fetch, or W3C/IANA would need to change the definition of the media type and give some registration function for possible profile values, then all downstream specifications would need to register a safe profile value to use.I’ve added the tag-needs-resolution label, as I think that’s the level this would need to run up to :([1] https://www.w3.org/TR/json-ld11/#iana-considerations[2] https://iiif.io/api/presentation/3.0/#63-responses [3] https://linked.art/api/1.0/json-ld/#introduction[4] https://fetch.spec.whatwg.org/#ref-for-cors-unsafe-request-header-byte"
  },
  
  {
    "title": "credential-schemas/issue/1: List of Adopters",
    "url": "/github-discussions/credential-schemas/issue/1/",
    "categories": "DIF",
    "tags": "credential-schemas",
    "date": "2024-06-18 19:36:22 -0700",
    





    
    "snippet": "Is your feature request related to a problem? Please describe.For newcomers would be nice to know what else is out there that is already using Identus.Describe the solution you’d likeWould be nice ...",
    "content": "Is your feature request related to a problem? Please describe.For newcomers would be nice to know what else is out there that is already using Identus.Describe the solution you’d likeWould be nice to have a list of specific applications that adopted and using this technology/libraries.Can be real applications are just demos.Additional contextThis question was mention on the end of the Identus Community outreach call meeting (2024/04/23)"
  },
  
  {
    "title": "decentralized-web-node/pr/305: chore(deps-dev): Bump ruff from 0.1.15 to 0.3.4 in /oid4vci",
    "url": "/github-discussions/decentralized-web-node/pr/305/",
    "categories": "DIF",
    "tags": "decentralized-web-node",
    "date": "2024-06-12 08:21:27 -0700",
    





    
    "snippet": "Bumps ruff from 0.1.15 to 0.3.4.Release notesSourced from ruff's releases.v0.3.3ChangesPreview features[flake8-bandit]: Implement S610 rule (#10316)[pycodestyle] Implement blank-line-at-end-of-file...",
    "content": "Bumps ruff from 0.1.15 to 0.3.4.Release notesSourced from ruff's releases.v0.3.3ChangesPreview features[flake8-bandit]: Implement S610 rule (#10316)[pycodestyle] Implement blank-line-at-end-of-file (W391) (#10243)[pycodestyle] Implement redundant-backslash (E502) (#10292)[pylint] - implement redeclared-assigned-name (W0128) (#9268)Rule changes[flake8_comprehensions] Handled special case for C400 which also matches C416 (#10419)[flake8-bandit] Implement upstream updates for S311, S324 and S605 (#10313)[pyflakes] Remove F401 fix for __init__ imports by default and allow opt-in to unsafe fix (#10365)[pylint] Implement invalid-bool-return-type (E304) (#10377)[pylint] Include builtin warnings in useless-exception-statement (PLW0133) (#10394)CLIAdd message on success to ruff check (#8631)Bug fixes[PIE970] Allow trailing ellipsis in typing.TYPE_CHECKING (#10413)Avoid TRIO115 if the argument is a variable (#10376)[F811] Avoid removing shadowed imports that point to different symbols (#10387)Fix F821 and F822 false positives in .pyi files (#10341)Fix F821 false negatives in .py files when from __future__ import annotations is active (#10362)Fix case where Indexer fails to identify continuation preceded by newline #10351 (#10354)Sort hash maps in Settings display (#10370)Track conditional deletions in the semantic model (#10415)[C413] Wrap expressions in parentheses when negating (#10346)[pycodestyle] Do not ignore lines before the first logical line in blank lines rules. (#10382)[pycodestyle] Do not trigger E225 and E275 when the next token is a ')' (#10315)[pylint] Avoid false-positive slot non-assignment for __dict__ (PLE0237) (#10348)Gate f-string struct size test for Rustc &lt; 1.76 (#10371)DocumentationUse ruff.toml format in README (#10393)[RUF008] Make it clearer that a mutable default in a dataclass is only valid if it is typed as a ClassVar (#10395)[pylint] Extend docs and test in invalid-str-return-type (E307) (#10400)Remove . from check and format commands (#10217)Contributors@​AlexWaygood@​Guilherme-Vasconcelos@​KotlinIsland@​anuraaga... (truncated)ChangelogSourced from ruff's changelog.0.3.4Preview features[flake8-simplify] Detect implicit else cases in needless-bool (SIM103) (#10414)[pylint] Implement nan-comparison (PLW0117) (#10401)[pylint] Implement nonlocal-and-global (E115) (#10407)[pylint] Implement singledispatchmethod-function (PLE5120) (#10428)[refurb] Implement list-reverse-copy (FURB187) (#10212)Rule changes[flake8-pytest-style] Add automatic fix for pytest-parametrize-values-wrong-type (PT007) (#10461)[pycodestyle] Allow SPDX license headers to exceed the line length (E501) (#10481)FormatterFix unstable formatting for trailing subscript end-of-line comment (#10492)Bug fixesAvoid code comment detection in PEP 723 script tags (#10464)Avoid incorrect tuple transformation in single-element case (C409) (#10491)Bug fix: Prevent fully defined links name from being reformatted (#10442)Consider raw source code for W605 (#10480)Docs: Link inline settings when not part of options section (#10499)Don't treat annotations as redefinitions in .pyi files (#10512)Fix E231 bug: Inconsistent catch compared to pycodestyle, such as when dict nested in list (#10469)Fix pylint upstream categories not showing in docs (#10441)Add missing Options references to blank line docs (#10498)'Revert &quot;F821: Fix false negatives in .py files when from __future__ import annotations is active (#10362)&quot;' (#10513)Apply NFKC normalization to unicode identifiers in the lexer (#10412)Avoid failures due to non-deterministic binding ordering (#10478)[flake8-bugbear] Allow tuples of exceptions (B030) (#10437)[flake8-quotes] Avoid syntax errors due to invalid quotes (Q000, Q002) (#10199)0.3.3Preview features[flake8-bandit]: Implement S610 rule (#10316)[pycodestyle] Implement blank-line-at-end-of-file (W391) (#10243)[pycodestyle] Implement redundant-backslash (E502) (#10292)[pylint] - implement redeclared-assigned-name (W0128) (#9268)Rule changes[flake8_comprehensions] Handled special case for C400 which also matches C416 (#10419)[flake8-bandit] Implement upstream updates for S311, S324 and S605 (#10313)[pyflakes] Remove F401 fix for __init__ imports by default and allow opt-in to unsafe fix (#10365)... (truncated)Commits5062572 Bump version to v0.3.4 (#10515)dc6f639 Rename list-reassign-reversed to list-reverse-copy (#10514)01fe268 [refurb] Implement list_assign_reversed lint (FURB187) (#10212)c62184d 'Revert &quot;F821: Fix false negatives in .py files when `from future import ...9b3c732 Docs: Link inline settings when not part of options section (#10499)caa1450 Don't treat annotations as redefinitions in .pyi files (#10512)60fd98e Update Rust to v1.77 (#10510)ac150b9 Spruce up docs for flake8-pyi rules (part 2) (#10494)d9ac170 Fix E231 bug: Inconsistent catch compared to pycodestyle, such as when dict...c5ea420 chore: remove repetitive words (#10502)Additional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "spec-up/issue/65: Test",
    "url": "/github-discussions/spec-up/issue/65/",
    "categories": "DIF",
    "tags": "spec-up",
    "date": "2024-06-11 09:45:29 -0700",
    





    
    "snippet": "Short DescriptiontestValue statementtestComponentstestTeam memberstestArchitectNo responseQA MemberNo responseOwnertest  #66  task 2  task 3",
    "content": "Short DescriptiontestValue statementtestComponentstestTeam memberstestArchitectNo responseQA MemberNo responseOwnertest  #66  task 2  task 3"
  },
  
  {
    "title": "universal-resolver/pr/428: chore(deps): Bump the pip group in /oid4vci with 3 updates",
    "url": "/github-discussions/universal-resolver/pr/428/",
    "categories": "DIF",
    "tags": "universal-resolver",
    "date": "2024-06-03 05:16:56 -0700",
    





    
    "snippet": "Bumps the pip group in /oid4vci with 3 updates: idna, jwcrypto and pillow.Updates idna from 3.6 to 3.7Release notesSourced from idna's releases.v3.7What's ChangedFix issue where specially crafted i...",
    "content": "Bumps the pip group in /oid4vci with 3 updates: idna, jwcrypto and pillow.Updates idna from 3.6 to 3.7Release notesSourced from idna's releases.v3.7What's ChangedFix issue where specially crafted inputs to encode() could take exceptionally long amount of time to process. [CVE-2024-3651]Thanks to Guido Vranken for reporting the issue.Full Changelog: https://github.com/kjd/idna/compare/v3.6...v3.7ChangelogSourced from idna's changelog.3.7 (2024-04-11)++++++++++++++++Fix issue where specially crafted inputs to encode() couldtake exceptionally long amount of time to process. [CVE-2024-3651]Thanks to Guido Vranken for reporting the issue.Commits1d365e1 Release v3.7c1b3154 Merge pull request #172 from kjd/optimize-contextj0394ec7 Merge branch 'master' into optimize-contextjcd58a23 Merge pull request #152 from elliotwutingfeng/dev5beb28b More efficient resolution of joiner contexts1b12148 Update ossf/scorecard-action to v2.3.1d516b87 Update Github actions/checkout to v4c095c75 Merge branch 'master' into dev60a0a4c Fix typo in GitHub Actions workflow key5918a0e Merge branch 'master' into devAdditional commits viewable in compare viewUpdates jwcrypto from 1.5.1 to 1.5.6Release notesSourced from jwcrypto's releases.Version 1.5.6 - Moderate Security releaseWhat's ChangedAddress potential DoS with high compression ratio by @​simo5 in latchset/jwcrypto#349Full Changelog: https://github.com/latchset/jwcrypto/compare/v1.5.5...v1.5.6Version 1.5.5This version fixes a pypi distribution problem introduced in 1.0 when pushing was automated.With 1.5.5 a binary wheel is now also made available on pypi.What's ChangedFix doc generation by @​simo5 in latchset/jwcrypto#345Update publish action to upload also binary dist by @​simo5 in latchset/jwcrypto#347Fix pypi publishing by @​simo5 in latchset/jwcrypto#348Full Changelog: https://github.com/latchset/jwcrypto/compare/v1.5.4...v1.5.5v1.5.4One more release bump to address issues with typing_extensions minimum required versionFull Changelog: https://github.com/latchset/jwcrypto/compare/v1.5.3...v1.5.4v1.5.3Bumping release due to inconsistency in python 3.6 support that affected pypijwcrypto-1.5.3.tar.gz.sha512sum.txtjwcrypto-1.5.3.tar.gzWhat's ChangedDrop python 3.6 and 3.7 and add 3.11 support by @​simo5 in latchset/jwcrypto#340Full Changelog: https://github.com/latchset/jwcrypto/compare/v1.5.2...v1.5.3Version 1.5.2 -  maintenance releaseThis is a minor maintenance release to improve interoperability with debuggersNote: yanked from pypi due to 3.6 incompatibility, use 1.5.3What's Changedreplace deprecated package with typing_extensions by @​david-homelend in latchset/jwcrypto#337New Contributors@​david-homelend made their first contribution in latchset/jwcrypto#337Full Changelog: https://github.com/latchset/jwcrypto/compare/v1.5.1...v1.5.2Commitsecde4ef Version 1.5.690477a3 Address potential DoS with high compression ratio240cc60 Modernize pypi action491f448 Version 1.5.57f51d28 Update publish action to upload also binary dist5dc2ea2 Fix doc generationb9432ef Version 1.5.4e7ef80f Set a minimum version for typing_extensionsa06b84a Version 1.5.3c659e38 Drop python 3.6 and 3.7 and add 3.11 supportAdditional commits viewable in compare viewUpdates pillow from 10.2.0 to 10.3.0Release notesSourced from pillow's releases.10.3.0https://pillow.readthedocs.io/en/stable/releasenotes/10.3.0.htmlChangesCVE-2024-28219: Use strncpy to avoid buffer overflow #7928 [@​hugovk]Use functools.lru_cache for hopper() #7912 [@​hugovk]Raise ValueError if seeking to greater than offset-sized integer in TIFF #7883 [@​radarhere]Improve speed of loading QOI images #7925 [@​radarhere]Added RGB to I;16N conversion #7920 [@​radarhere]Add --report argument to main.py to omit supported formats #7818 [@​nulano]Added RGB to I;16, I;16L and I;16B conversion #7918 [@​radarhere]Fix editable installation with custom build backend and configuration options #7658 [@​nulano]Fix putdata() for I;16N on big-endian #7209 [@​Yay295]Determine MPO size from markers, not EXIF data #7884 [@​radarhere]Improved conversion from RGB to RGBa, LA and La #7888 [@​radarhere]Support FITS images with GZIP_1 compression #7894 [@​radarhere]Use I;16 mode for 9-bit JPEG 2000 images #7900 [@​scaramallion]Raise ValueError if kmeans is negative #7891 [@​radarhere]Remove TIFF tag OSUBFILETYPE when saving using libtiff #7893 [@​radarhere]Raise ValueError for negative values when loading P1-P3 PPM images #7882 [@​radarhere]Added reading of JPEG2000 palettes #7870 [@​radarhere]Added alpha_quality argument when saving WebP images #7872 [@​radarhere]Fixed joined corners for ImageDraw rounded_rectangle() non-integer dimensions #7881 [@​radarhere]Removed Python and NumPy pinning on Cygwin #7880 [@​radarhere]Update UnidentifiedImageError and version imports #7644 [@​radarhere]Stop reading EPS image at EOF marker #7753 [@​radarhere]PSD layer co-ordinates may be negative #7706 [@​radarhere]Use subprocess with CREATE_NO_WINDOW flag in ImageShow WindowsViewer #7791 [@​radarhere]When saving GIF frame that restores to background color, do not fill identical pixels #7788 [@​radarhere]Fixed reading PNG iCCP compression method #7823 [@​radarhere]Allow writing IFDRational to UNDEFINED tag #7840 [@​radarhere]Fix logged tag name when loading Exif data #7842 [@​radarhere]Use maximum frame size in IHDR chunk when saving APNG images #7821 [@​radarhere]Prevent opening P TGA images without a palette #7797 [@​radarhere]Use palette when loading ICO images #7798 [@​radarhere]Use consistent arguments for load_read and load_seek #7713 [@​radarhere]Turn off nullability warnings for macOS SDK #7827 [@​radarhere]Fix shift-sign issue in Convert.c #7838 [@​r-barnes]winbuild: Refactor dependency versions into constants #7843 [@​hugovk]Build macOS arm64 wheels natively #7852 [@​radarhere]Fixed typo #7855 [@​radarhere]Open 16-bit grayscale PNGs as I;16 #7849 [@​radarhere]Handle truncated chunks at the end of PNG images #7709 [@​lajiyuan]Match mask size to pasted image size in GifImagePlugin #7779 [@​radarhere]Changed SupportsGetMesh protocol to be public #7841 [@​radarhere]Release GIL while calling WebPAnimDecoderGetNext #7782 [@​evanmiller]Fixed reading FLI/FLC images with a prefix chunk #7804 [@​twolife]Updated package name for Tidelift #7810 [@​radarhere]Removed unused code #7744 [@​radarhere]... (truncated)ChangelogSourced from pillow's changelog.10.3.0 (2024-04-01)CVE-2024-28219: Use strncpy to avoid buffer overflow #7928[radarhere, hugovk]Deprecate eval(), replacing it with lambda_eval() and unsafe_eval() #7927[radarhere, hugovk]Raise ValueError if seeking to greater than offset-sized integer in TIFF #7883[radarhere]Add --report argument to __main__.py to omit supported formats #7818[nulano, radarhere, hugovk]Added RGB to I;16, I;16L, I;16B and I;16N conversion #7918, #7920[radarhere]Fix editable installation with custom build backend and configuration options #7658[nulano, radarhere]Fix putdata() for I;16N on big-endian #7209[Yay295, hugovk, radarhere]Determine MPO size from markers, not EXIF data #7884[radarhere]Improved conversion from RGB to RGBa, LA and La #7888[radarhere]Support FITS images with GZIP_1 compression #7894[radarhere]Use I;16 mode for 9-bit JPEG 2000 images #7900[scaramallion, radarhere]Raise ValueError if kmeans is negative #7891[radarhere]Remove TIFF tag OSUBFILETYPE when saving using libtiff #7893[radarhere]Raise ValueError for negative values when loading P1-P3 PPM images #7882[radarhere]Added reading of JPEG2000 palettes #7870[radarhere]Added alpha_quality argument when saving WebP images #7872[radarhere]... (truncated)Commits5c89d88 10.3.0 version bump63cbfcf Update CHANGES.rst [ci skip]2776126 Merge pull request #7928 from python-pillow/lcmsaeb51cb Merge branch 'main' into lcms5beb0b6 Update CHANGES.rst [ci skip]cac6ffa Merge pull request #7927 from python-pillow/imagemathf5eeeac Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated evalfacf3af Added release notes2a93aba Use strncpy to avoid buffer overflowa670597 Update CHANGES.rst [ci skip]Additional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore  major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)- `@dependabot ignore  minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)- `@dependabot ignore ` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)- `@dependabot unignore ` will remove all of the ignore conditions of the specified dependency- `@dependabot unignore  ` will remove the ignore condition of the specified dependency and ignore conditionsYou can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hyperledger/aries-acapy-plugins/network/alerts).&lt;/details&gt;"
  },
  
  {
    "title": "tswg-keri-specification/issue/178: Pollux as a plugin interface and new credentials type plugins can be inserted into the Agent",
    "url": "/github-discussions/tswg-keri-specification/issue/178/",
    "categories": "Hyperledger",
    "tags": "tswg-keri-specification",
    "date": "2024-05-21 07:59:32 -0700",
    





    
    "snippet": "Proposed featurePollux will become a plugin interface, this will enable more control over the available credentials type that can be used by the agent. It will as well enable developers to provide ...",
    "content": "Proposed featurePollux will become a plugin interface, this will enable more control over the available credentials type that can be used by the agent. It will as well enable developers to provide their own Plugins for credential types that are not by default supported by the Agent.Feature descriptionPollux will become more inline with a plugin interface. It will be adapted so each plugin as versioning and version support.Each plugin can identify itself and identify the application/types it supports.The agent will receive an array of Pollux plugins and pick the plugin that supports a type of credential to run the flow.Anything else?No response"
  },
  
  {
    "title": "json-ld-syntax/issue/432: An asynchronous issuance",
    "url": "/github-discussions/json-ld-syntax/issue/432/",
    "categories": "DIF",
    "tags": "json-ld-syntax",
    "date": "2024-05-15 03:12:27 -0700",
    





    
    "snippet": "Hi,it might be out of the scope of this spec, it’s not a microservice, but asynchronous issuing is crucial in order to enable:  an approval process - a process that might involve collecting additio...",
    "content": "Hi,it might be out of the scope of this spec, it’s not a microservice, but asynchronous issuing is crucial in order to enable:  an approval process - a process that might involve collecting additional information, checks, and even human involvement  optimal infrastructure utilization - e.g. a queue of requests scheduled to be processed on an issuer’s termsTo keep this spec simple, perhaps, simply allowing to return 202 Accepted code without specifying any further details, leaving the further interaction details on an implementer for now, could be enough to keep the issuance interface being used for advanced use-cases without a need to introduce a proprietary endpoint on issuer’s side."
  },
  
  {
    "title": "vc-api/issue/383: Timeout on OPTIONS (cors preflight)",
    "url": "/github-discussions/vc-api/issue/383/",
    "categories": "DIF",
    "tags": "vc-api",
    "date": "2024-05-14 09:12:53 -0700",
    





    
    "snippet": "Seems like the mediator is responding like this:atala-prism-mediator-identus-mediator-1  | 2024-11-24_00:56:53.696 WARN  f.d.f.TransportDispatcher@L167:[ZScheduler-Worker-1] {version=1.0.0, msg_sha...",
    "content": "Seems like the mediator is responding like this:atala-prism-mediator-identus-mediator-1  | 2024-11-24_00:56:53.696 WARN  f.d.f.TransportDispatcher@L167:[ZScheduler-Worker-1] {version=1.0.0, msg_sha256=c4946137e7ddb36a3261fd6dfb6b0b4265280b0a3dfc91c3e449513dd2c7ed10} - zio-fiber-1940542155 No url to send messageo.h.i.m.DIDCommRoutes@L167:[ZScheduler-Worker-2] {version=1.0.0} - zio-fiber-1688384339 Request TimeoutFor a CORS check from the browser, this is causing Safari 18 to stop polling the endpoint since it triggers a CORS failureOther browsers seems to just ignore this timeout and work fine.In order for this bug to reproduce you need to run Safari 18 (Sequoia) on mediator v1.0.0."
  },
  
  {
    "title": "didcomm-demo/pr/76: chore: upgrade package from AFJ to credo-ts",
    "url": "/github-discussions/didcomm-demo/pr/76/",
    "categories": "DIF",
    "tags": "didcomm-demo",
    "date": "2024-05-07 06:43:52 -0700",
    





    
    "snippet": "  Replaced AFJ package with credo-ts across the codebase  Updated relevant imports and dependencies to ensure compatibility with credo-ts  Refactored code to align with any breaking changes or diff...",
    "content": "  Replaced AFJ package with credo-ts across the codebase  Updated relevant imports and dependencies to ensure compatibility with credo-ts  Refactored code to align with any breaking changes or differences between AFJ and credo-ts Tested the changes to confirm that the upgrade works as expected without any issues."
  },
  
  {
    "title": "didcomm-demo/issue/74: VCDM Improvements Phase 2: Add versioning to the API to support multiple versions at the same time",
    "url": "/github-discussions/didcomm-demo/issue/74/",
    "categories": "DIF",
    "tags": "didcomm-demo",
    "date": "2024-05-06 04:09:29 -0700",
    





    
    "snippet": "Short DescriptionThis phase we integrate versioning support while we will still be using 1.1, we change the source to be able to plug more modern versions of the spec soon.Value statementTBDCompone...",
    "content": "Short DescriptionThis phase we integrate versioning support while we will still be using 1.1, we change the source to be able to plug more modern versions of the spec soon.Value statementTBDComponents  OASTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "org/issue/37: Tagging this repo",
    "url": "/github-discussions/org/issue/37/",
    "categories": "DIF",
    "tags": "org",
    "date": "2024-04-20 18:16:24 -0700",
    





    
    "snippet": "The concept of tagging this repo came up on the Aries WG call on Nov. 15, 2023. I wanted to continue that discussion here:As prior art, consider this text from: https://github.com/hyperledger/aries...",
    "content": "The concept of tagging this repo came up on the Aries WG call on Nov. 15, 2023. I wanted to continue that discussion here:As prior art, consider this text from: https://github.com/hyperledger/aries-acapy-plugin-toolbox#aca-py-version-compatibility  ACA-Py Version Compatibility  To avoid a confusing pseudo-lock-step release, this plugin is versioned independent of ACA-Py. Plugin releases will follow standard semver but each release will also be tagged with a mapping to an ACA-Py version with the format acapy-X.Y.Z-J where X.Y.Z corresponds to the ACA-Py version supported and J is an incrementing number for each new plugin release that targets the same version of ACA-Py.  You should look for the most recent release tagged with the version of ACA-Py you are using (with the highest value for J).This was a convention that the toolbox plugin adopted (back when we were actively working on it). I think tagging the whole repo will be challenging to do meaningfully; for the toolbox plugin, we needed to keep track changes of the plugin itself as well as the versions of ACA-Py it was compatible with. The plugins should be able to evolve and gain features and be able to version themselves to communicate when new features are added."
  },
  
  {
    "title": "aries-vcx/pr/1182: Minor Bug Fixes",
    "url": "/github-discussions/aries-vcx/pr/1182/",
    "categories": "Hyperledger",
    "tags": "aries-vcx",
    "date": "2024-04-18 22:37:21 -0700",
    





    
    "snippet": "In our testing, we’ve come across a few minor bugs that this PR intends to sort out",
    "content": "In our testing, we’ve come across a few minor bugs that this PR intends to sort out"
  },
  
  {
    "title": "tswg-cesr-specification/issue/91: Separate \"Security and Privacy Considerations\"",
    "url": "/github-discussions/tswg-cesr-specification/issue/91/",
    "categories": "Hyperledger",
    "tags": "tswg-cesr-specification",
    "date": "2024-04-11 07:19:46 -0700",
    





    
    "snippet": "At the moment, the specification has a “Security and Privacy Considerations” section.In a W3C specification, these should be separated into a “Security Considerations” section and a “Privacy Consid...",
    "content": "At the moment, the specification has a “Security and Privacy Considerations” section.In a W3C specification, these should be separated into a “Security Considerations” section and a “Privacy Considerations” section."
  },
  
  {
    "title": "tswg-cesr-specification/issue/90: Typo in appendix A: `eddsa-rdfc-2022` is wrongly named `edssa-2022`",
    "url": "/github-discussions/tswg-cesr-specification/issue/90/",
    "categories": "Hyperledger",
    "tags": "tswg-cesr-specification",
    "date": "2024-04-11 07:10:47 -0700",
    





    
    "snippet": "Hi, I think to have spotted a typo in the first paragraph of appendix A, where eddsa-rdfc-2022 is wrongly named edssa-2022. The link correctly points to eddsa-rdfc-2022.",
    "content": "Hi, I think to have spotted a typo in the first paragraph of appendix A, where eddsa-rdfc-2022 is wrongly named edssa-2022. The link correctly points to eddsa-rdfc-2022."
  },
  
  {
    "title": "aries-acapy-docs/pr/101: build(deps-dev): bump @babel/traverse from 7.14.0 to 7.23.2 in /acapy/controller",
    "url": "/github-discussions/aries-acapy-docs/pr/101/",
    "categories": "Hyperledger",
    "tags": "aries-acapy-docs",
    "date": "2024-04-09 13:10:16 -0700",
    





    
    "snippet": "Bumps @babel/traverse from 7.14.0 to 7.23.2.Release notesSourced from @​babel/traverse's releases.v7.23.2 (2023-10-11)NOTE: This release also re-publishes @babel/core, even if it does not appear in...",
    "content": "Bumps @babel/traverse from 7.14.0 to 7.23.2.Release notesSourced from @​babel/traverse's releases.v7.23.2 (2023-10-11)NOTE: This release also re-publishes @babel/core, even if it does not appear in the linked release commit.Thanks @​jimmydief for your first PR!:bug: Bug Fixbabel-traverse#16033 Only evaluate own String/Number/Math methods (@​nicolo-ribaudo)babel-preset-typescript#16022 Rewrite .tsx extension when using rewriteImportExtensions (@​jimmydief)babel-helpers#16017 Fix: fallback to typeof when toString is applied to incompatible object (@​JLHwung)babel-helpers, babel-plugin-transform-modules-commonjs, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime#16025 Avoid override mistake in namespace imports (@​nicolo-ribaudo)Committers: 5Babel Bot (@​babel-bot)Huáng Jùnliàng (@​JLHwung)James Diefenderfer (@​jimmydief)Nicolò Ribaudo (@​nicolo-ribaudo)@​liuxingbaoyuv7.23.1 (2023-09-25)Re-publishing @babel/helpers due to a publishing error in 7.23.0.v7.23.0 (2023-09-25)Thanks @​lorenzoferre and @​RajShukla1 for your first PRs!:rocket: New Featurebabel-plugin-proposal-import-wasm-source, babel-plugin-syntax-import-source, babel-plugin-transform-dynamic-import#15870 Support transforming import source for wasm (@​nicolo-ribaudo)babel-helper-module-transforms, babel-helpers, babel-plugin-proposal-import-defer, babel-plugin-syntax-import-defer, babel-plugin-transform-modules-commonjs, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime, babel-standalone#15878 Implement import defer proposal transform support (@​nicolo-ribaudo)babel-generator, babel-parser, babel-types#15845 Implement import defer parsing support (@​nicolo-ribaudo)#15829 Add parsing support for the &quot;source phase imports&quot; proposal (@​nicolo-ribaudo)babel-generator, babel-helper-module-transforms, babel-parser, babel-plugin-transform-dynamic-import, babel-plugin-transform-modules-amd, babel-plugin-transform-modules-commonjs, babel-plugin-transform-modules-systemjs, babel-traverse, babel-types#15682 Add createImportExpressions parser option (@​JLHwung)babel-standalone#15671 Pass through nonce to the transformed script element (@​JLHwung)babel-helper-function-name, babel-helper-member-expression-to-functions, babel-helpers, babel-parser, babel-plugin-proposal-destructuring-private, babel-plugin-proposal-optional-chaining-assign, babel-plugin-syntax-optional-chaining-assign, babel-plugin-transform-destructuring, babel-plugin-transform-optional-chaining, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime, babel-standalone, babel-types#15751 Add support for optional chain in assignments (@​nicolo-ribaudo)babel-helpers, babel-plugin-proposal-decorators#15895 Implement the &quot;decorator metadata&quot; proposal (@​nicolo-ribaudo)babel-traverse, babel-types#15893 Add t.buildUndefinedNode (@​liuxingbaoyu)babel-preset-typescript... (truncated)ChangelogSourced from @​babel/traverse's changelog.v7.23.2 (2023-10-11):bug: Bug Fixbabel-traverse#16033 Only evaluate own String/Number/Math methods (@​nicolo-ribaudo)babel-preset-typescript#16022 Rewrite .tsx extension when using rewriteImportExtensions (@​jimmydief)babel-helpers#16017 Fix: fallback to typeof when toString is applied to incompatible object (@​JLHwung)babel-helpers, babel-plugin-transform-modules-commonjs, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime#16025 Avoid override mistake in namespace imports (@​nicolo-ribaudo)v7.23.0 (2023-09-25):rocket: New Featurebabel-plugin-proposal-import-wasm-source, babel-plugin-syntax-import-source, babel-plugin-transform-dynamic-import#15870 Support transforming import source for wasm (@​nicolo-ribaudo)babel-helper-module-transforms, babel-helpers, babel-plugin-proposal-import-defer, babel-plugin-syntax-import-defer, babel-plugin-transform-modules-commonjs, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime, babel-standalone#15878 Implement import defer proposal transform support (@​nicolo-ribaudo)babel-generator, babel-parser, babel-types#15845 Implement import defer parsing support (@​nicolo-ribaudo)#15829 Add parsing support for the &quot;source phase imports&quot; proposal (@​nicolo-ribaudo)babel-generator, babel-helper-module-transforms, babel-parser, babel-plugin-transform-dynamic-import, babel-plugin-transform-modules-amd, babel-plugin-transform-modules-commonjs, babel-plugin-transform-modules-systemjs, babel-traverse, babel-types#15682 Add createImportExpressions parser option (@​JLHwung)babel-standalone#15671 Pass through nonce to the transformed script element (@​JLHwung)babel-helper-function-name, babel-helper-member-expression-to-functions, babel-helpers, babel-parser, babel-plugin-proposal-destructuring-private, babel-plugin-proposal-optional-chaining-assign, babel-plugin-syntax-optional-chaining-assign, babel-plugin-transform-destructuring, babel-plugin-transform-optional-chaining, babel-runtime-corejs2, babel-runtime-corejs3, babel-runtime, babel-standalone, babel-types#15751 Add support for optional chain in assignments (@​nicolo-ribaudo)babel-helpers, babel-plugin-proposal-decorators#15895 Implement the &quot;decorator metadata&quot; proposal (@​nicolo-ribaudo)babel-traverse, babel-types#15893 Add t.buildUndefinedNode (@​liuxingbaoyu)babel-preset-typescript#15913 Add rewriteImportExtensions option to TS preset (@​nicolo-ribaudo)babel-parser#15896 Allow TS tuples to have both labeled and unlabeled elements (@​yukukotani):bug: Bug Fixbabel-plugin-transform-block-scoping#15962 fix: transform-block-scoping captures the variables of the method in the loop (@​liuxingbaoyu):nail_care: Polishbabel-traverse#15797 Expand evaluation of global built-ins in @babel/traverse (@​lorenzoferre)babel-plugin-proposal-explicit-resource-management#15985 Improve source maps for blocks with using declarations (@​nicolo-ribaudo):microscope: Output optimizationbabel-core, babel-helper-module-transforms, babel-plugin-transform-async-to-generator, babel-plugin-transform-classes, babel-plugin-transform-dynamic-import, babel-plugin-transform-function-name, babel-plugin-transform-modules-amd, babel-plugin-transform-modules-commonjs, babel-plugin-transform-modules-umd, babel-plugin-transform-parameters, babel-plugin-transform-react-constant-elements, babel-plugin-transform-react-inline-elements, babel-plugin-transform-runtime, babel-plugin-transform-typescript, babel-preset-env#15984 Inline exports.XXX = update in simple variable declarations (@​nicolo-ribaudo)v7.22.20 (2023-09-16)... (truncated)Commitsb4b9942 v7.23.2b13376b Only evaluate own String/Number/Math methods (#16033)ca58ec1 v7.23.00f333da Add createImportExpressions parser option (#15682)3744545 Fix lintingc7e6806 Add t.buildUndefinedNode (#15893)38ee8b4 Expand evaluation of global built-ins in @babel/traverse (#15797)9f3dfd9 v7.22.203ed28b2 Fully support || and &amp;&amp; in pluginToggleBooleanFlag (#15961)77b0d73 v7.22.19Additional commits viewable in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hyperledger/aries-mediator-service/network/alerts).&lt;/details&gt;"
  },
  
  {
    "title": "spec-up/issue/64: task 1",
    "url": "/github-discussions/spec-up/issue/64/",
    "categories": "DIF",
    "tags": "spec-up",
    "date": "2024-04-08 22:47:46 -0700",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "didcomm-book/issue/20: Problem reporting for the Agent and Mediator",
    "url": "/github-discussions/didcomm-book/issue/20/",
    "categories": "DIF",
    "tags": "didcomm-book",
    "date": "2024-04-03 08:06:47 -0700",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "org/issue/33: Cloud Agent to publish PrismDID on behalf of external wallet into VDR",
    "url": "/github-discussions/org/issue/33/",
    "categories": "DIF",
    "tags": "org",
    "date": "2024-03-23 12:27:01 -0700",
    





    
    "snippet": "Is your feature request related to a problem? Please describe.Currently, Cloud Agent can only publish PrismDIDs that are created by the same Cloud Agent into the VDR. Most Edge Clients will never b...",
    "content": "Is your feature request related to a problem? Please describe.Currently, Cloud Agent can only publish PrismDIDs that are created by the same Cloud Agent into the VDR. Most Edge Clients will never be connected to a full node in order to publish their PrismDIDs to the VDR and it could be useful for certain use cases.Describe the solution you’d likeIt would be great to ask the Cloud Agent to publish a PrismDID created from my Edge Client Wallet through the REST API.Describe alternatives you’ve consideredAllowing the Edge SDK to connect directly to icarus (like the cloud agent does) and prepare the right payload which I would need to reverse engineer anyways from the cloud agent code :)"
  },
  
  {
    "title": "aries-acapy-docs/pr/99: Bugfix: vc.credentialSubject.id, vc.issuer, iss, and sub should be DID itself",
    "url": "/github-discussions/aries-acapy-docs/pr/99/",
    "categories": "Hyperledger",
    "tags": "aries-acapy-docs",
    "date": "2024-03-22 07:55:16 -0700",
    





    
    "snippet": "[OID4VCI]credentialSubject.id, iss, and sub should be DID, not DID URLs pointing to verification methods.",
    "content": "[OID4VCI]credentialSubject.id, iss, and sub should be DID, not DID URLs pointing to verification methods."
  },
  
  {
    "title": "aries-acapy-docs/pr/97: Bump hyperledger/aries-cloudagent-python from py3.9-0.10.3 to py3.9-0.12.1 in /docker/acapy",
    "url": "/github-discussions/aries-acapy-docs/pr/97/",
    "categories": "DIF",
    "tags": "aries-acapy-docs",
    "date": "2024-03-22 07:37:54 -0700",
    





    
    "snippet": "Bumps hyperledger/aries-cloudagent-python from py3.9-0.10.3 to py3.9-0.12.1.CommitsSee full diff in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it your...",
    "content": "Bumps hyperledger/aries-cloudagent-python from py3.9-0.10.3 to py3.9-0.12.1.CommitsSee full diff in compare viewDependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "aries-vcx/issue/1163: OpenID4VP SD-JWT is not verifying the holder signature (KB-JWT)",
    "url": "/github-discussions/aries-vcx/issue/1163/",
    "categories": "Hyperledger",
    "tags": "aries-vcx",
    "date": "2024-03-22 04:12:01 -0700",
    





    
    "snippet": "I believe the SD-JWT cred processor verify_presentation is not actually checking the holder’s signature (KB-JWT) on the presented SD-JWT. Meaning the SD-JWT holder does not have to prove they are b...",
    "content": "I believe the SD-JWT cred processor verify_presentation is not actually checking the holder’s signature (KB-JWT) on the presented SD-JWT. Meaning the SD-JWT holder does not have to prove they are bound to the SD-JWT.I tested this locally by using a malicious client that intentionally malforms the signature bytes of the KB-JWT it produces. The acapy plugin still reported verified=true (credo reported verified=false with logs that indicate the signature was invalid).I believe this happens because:  verify_presentation calls sd_jwt_verify with only 2 params; profile, presentation: https://github.com/openwallet-foundation/acapy-plugins/blob/main/oid4vc/sd_jwt_vc/cred_processor.py#L205  sd_jwt_verify has 2 additional optional params, expected_aud &amp; expected_nonce. so verify_presentation sets those as None  sd_jwt_verify initializes SDJWTVerifierACAPy with those null values for self.expected_aud &amp; self.expected_nonce  sd_jwt_verify then calls SDJWTVerifierACAPy.verify(), which checks the SD-JWT VC signature, and then only IF if self.expected_aud or self.expected_nonce: does it check the KB JWT:     if self.expected_aud or self.expected_nonce:          if not (self.expected_aud and self.expected_nonce):              raise ValueError(                  \"Either both expected_aud and expected_nonce must be provided \"                  \"or both must be None\"              )          await self._verify_key_binding_jwt(              self.expected_aud,              self.expected_nonce,          )        meaning the KB-JWT signature (holder binding/proof) is not checked"
  },
  
  {
    "title": "bbs-signature/issue/318: Able to create an in-memory sqlite database?",
    "url": "/github-discussions/bbs-signature/issue/318/",
    "categories": "DIF",
    "tags": "bbs-signature",
    "date": "2024-03-19 02:13:15 -0700",
    





    
    "snippet": "From the python library is there a way to create an in-memory sqlite database?I see this https://github.com/hyperledger/aries-askar/blob/main/askar-storage/src/backend/sqlite/provision.rs#L50 and w...",
    "content": "From the python library is there a way to create an in-memory sqlite database?I see this https://github.com/hyperledger/aries-askar/blob/main/askar-storage/src/backend/sqlite/provision.rs#L50 and will try and figure it out myself. Just posting this here is anyone knows off the to of their head.context: We’re trying to rely on askar fully in aca-py and remove the existing in-memory wallet that was created for testing. Having the option to create an in-memory wallet that is askar based would really help speed up the tests and prevent file IO errors."
  },
  
  {
    "title": "universal-registrar/pr/81: fix: indyNamespace",
    "url": "/github-discussions/universal-registrar/pr/81/",
    "categories": "DIF",
    "tags": "universal-registrar",
    "date": "2024-03-18 09:21:41 -0700",
    





    
    "snippet": "Fixes indy name spaces to get the issue credential flows working for the Indicio Testnet and Candy",
    "content": "Fixes indy name spaces to get the issue credential flows working for the Indicio Testnet and Candy"
  },
  
  {
    "title": "labs/issue/7: Running cargo test shows failure status for most of the test cases",
    "url": "/github-discussions/labs/issue/7/",
    "categories": "DIF",
    "tags": "labs",
    "date": "2024-03-18 09:16:27 -0700",
    





    
    "snippet": "Fork repository using main branch and clone it on my system. Then execute following:-cargo build =&gt; successfulcargo test =&gt; many test cases reported failedBuild system : Fedora 38rustc versio...",
    "content": "Fork repository using main branch and clone it on my system. Then execute following:-cargo build =&gt; successfulcargo test =&gt; many test cases reported failedBuild system : Fedora 38rustc version: rustc 1.72.0 (5680fa18f 2023-08-23)cargo version: cargo 1.72.0 (103a7ff2e 2023-08-15)"
  },
  
  {
    "title": "labs/issue/6: Link to identus-cloud-agent example / documentation",
    "url": "/github-discussions/labs/issue/6/",
    "categories": "DIF",
    "tags": "labs",
    "date": "2024-03-18 09:16:02 -0700",
    





    
    "snippet": "The “README - getting started” with plugin is not too actionable given it can’t do meaningful thing by itself alone. There should be a pointer to identus-cloud-agent documentation / example where t...",
    "content": "The “README - getting started” with plugin is not too actionable given it can’t do meaningful thing by itself alone. There should be a pointer to identus-cloud-agent documentation / example where the plugin is actually used."
  },
  
  {
    "title": "linked-vp/issue/51: NGrok setup for local use with indy tails server",
    "url": "/github-discussions/linked-vp/issue/51/",
    "categories": "DIF",
    "tags": "linked-vp",
    "date": "2024-02-29 00:54:34 -0800",
    





    
    "snippet": "Using the startup instructions in:https://github.com/hyperledger/aries-endorser-service?tab=readme-ov-file#running-locallywon’t really work as-is any more as Indy Tails Server needs the ngrok auth ...",
    "content": "Using the startup instructions in:https://github.com/hyperledger/aries-endorser-service?tab=readme-ov-file#running-locallywon’t really work as-is any more as Indy Tails Server needs the ngrok auth token as well. And if you use the same auth token in the 2 contexts  Indy Tails Server  Endorser ServiceYou will get the issue about simultaneous ngrok agent sessionsfrom docker-ngrok-endorser-agent container:2024-02-16 16:16:45 ERROR:  authentication failed: Your account is limited to 1 simultaneous ngrok agent session.2024-02-16 16:16:45 ERROR:  You can run multiple tunnels on a single agent session using a configuration file.2024-02-16 16:16:45 ERROR:  To learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/2024-02-16 16:16:45 ERROR:  2024-02-16 16:16:45 ERROR:  Active ngrok agent sessions in region 'us-cal-1':2024-02-16 16:16:45 ERROR:    - ts_2cTI2njhg4tmt7Qe1cltNsx3kxT (23.16.82.223)2024-02-16 16:16:45 ERROR:  2024-02-16 16:16:45 ERROR:  ERR_NGROK_1082024-02-16 16:16:45 ERROR:Not sure if we could adjust to have one environment that shares it, or at least need to adjust documentation."
  },
  
  {
    "title": "linked-vp/issue/50: Consider if things should be switched over to Credo",
    "url": "/github-discussions/linked-vp/issue/50/",
    "categories": "DIF",
    "tags": "linked-vp",
    "date": "2024-02-29 00:53:59 -0800",
    





    
    "snippet": "Instructions, git command to pull the repo, documentation, comments etc all refer to Aries-Framework-Javascript. This has been replaced by the move to Credo-TS so Akrida should(?) reference that in...",
    "content": "Instructions, git command to pull the repo, documentation, comments etc all refer to Aries-Framework-Javascript. This has been replaced by the move to Credo-TS so Akrida should(?) reference that instead.As well imports in the package.json like @aries-framework/core, @aries-framework/node on 0.4.0 versions do not continue to be updated and the 0.5.x updates look to be released and updated under @credo-ts/node etc on npm."
  },
  
  {
    "title": "did-jwt/issue/308: Issues handling didcomm message errors",
    "url": "/github-discussions/did-jwt/issue/308/",
    "categories": "DIF",
    "tags": "did-jwt",
    "date": "2024-02-28 04:47:17 -0800",
    





    
    "snippet": "Is this a regression?YesDescriptionBriefWhen didcomm message returns a http status code other than ok the message becomes undefined due a try-catch block. This issue’s goal is to enable an error ma...",
    "content": "Is this a regression?YesDescriptionBriefWhen didcomm message returns a http status code other than ok the message becomes undefined due a try-catch block. This issue’s goal is to enable an error management for didcomm errors.Spec: https://identity.foundation/didcomm-messaging/spec/#problem-reportsFetchApi.ts  async request&lt;T&gt;(    method: HttpMethod,    urlStr: string,    urlParameters: Map&lt;string, string&gt; = new Map(),    httpHeaders: Map&lt;string, string&gt; = new Map(),    body?: string | Record&lt;string, any&gt;  ): Promise&lt;ApiResponse&lt;T&gt;&gt; {    // ...    if (response.ok) {      return new ApiResponse(        data,        response.status,        response.statusText,        response.headers      );    }    throw new ApiError(response.status, response.statusText, data);}Mercury.ts  async sendMessageParseMessage(    message: Domain.Message  ): Promise&lt;Domain.Message | undefined&gt; {    const responseBody = await this.sendMessage&lt;any&gt;(message);    try {      const responseJSON = JSON.stringify(responseBody);      return await this.unpackMessage(responseJSON);    } catch (err) {      return undefined    }  }Any ApiError thrown will cause message to return undefined as per described in the Mercury.ts#sendMessageParseMessage methodPlease provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "vc-data-model/pr/1448: docs: connectionless proof",
    "url": "/github-discussions/vc-data-model/pr/1448/",
    "categories": "W3C",
    "tags": "vc-data-model",
    "date": "2024-02-27 11:04:35 -0800",
    





    
    "snippet": "Base branch: https://github.com/hyperledger/identus-cloud-agent/pull/1447(merge first)See diff : https://github.com/hyperledger/identus-cloud-agent/commit/b5efc5f62c12dc712458a58c38e0b43f26ae1251Ad...",
    "content": "Base branch: https://github.com/hyperledger/identus-cloud-agent/pull/1447(merge first)See diff : https://github.com/hyperledger/identus-cloud-agent/commit/b5efc5f62c12dc712458a58c38e0b43f26ae1251Adds  a page for connectionless proof  link in sidebar"
  },
  
  {
    "title": "bbs-signature/issue/315: SDJWT SDK to SDK Verification",
    "url": "/github-discussions/bbs-signature/issue/315/",
    "categories": "DIF",
    "tags": "bbs-signature",
    "date": "2024-02-16 15:54:22 -0800",
    





    
    "snippet": "Proposed featureOur aim is to bring verification capabilities across the different SDK platforms. We will do so by allowing Edge Wallets to initiate a ProofRequest to a known Identifier (DID), also...",
    "content": "Proposed featureOur aim is to bring verification capabilities across the different SDK platforms. We will do so by allowing Edge Wallets to initiate a ProofRequest to a known Identifier (DID), also this same Edge wallet need to be capable of Generating the Proof and send it back. This would basically allow any Edge wallet to initiate and complete verification requests by itself with Credential Type SD JWT. As this is a Selective Disclosure JWT, during the verification process the Verifier will receive both the shared disclosures and the SD JWT Credential.User CasesHigh level description SD-JWT-Based Verifiable Credentials: An Introduction (criipto.com)Current Draft Spec https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/EBSI Spec https://hub.ebsi.eu/vc-framework/did/selective-disclosure-sd-jwtAge Verification: For services that require age verification, such as venues where entrants need to be over 18. Entrants can share their driving licence as verifiable presentation and security can receive on a mobile device and automatically confirm that they are over the age of 18 without actually disclosing their age.Voting Systems: In digital voting systems, edge wallets can store digital identities, allowing citizens to vote securely and anonymously, ensuring the integrity of the electoral process.Feature descriptionUsing Presentation exchange protocol we add the ability for any SDK Verifier to now request SDJWT Presentation with all the disclosure capabilities bundled in.The verification will only pass if the claims we asked have been provided by the user, and disclosed correctlyAnything else?No response"
  },
  
  {
    "title": "identus-edge-agent-sdk-ts/issue/174: MySQL Support",
    "url": "/github-discussions/identus-edge-agent-sdk-ts/issue/174/",
    "categories": "Hyperledger",
    "tags": "identus-edge-agent-sdk-ts",
    "date": "2024-02-15 07:55:21 -0800",
    





    
    "snippet": "Our team currently uses vdr-tools as the underlying framework to support AFJ on our mediator. The reasoning is better support for concurrency, as well as MySQL support.We are now looking to upgrade...",
    "content": "Our team currently uses vdr-tools as the underlying framework to support AFJ on our mediator. The reasoning is better support for concurrency, as well as MySQL support.We are now looking to upgrade AFJ to 0.4.x, and in by doing so upgrade to use Aries Askar etc.Askar only supports SqlLite and Postgres - is there a workaround so that we can continue using MySQL?"
  },
  
  {
    "title": "tswg-cesr-specification/issue/60: About resolving protocol question",
    "url": "/github-discussions/tswg-cesr-specification/issue/60/",
    "categories": "DIF",
    "tags": "tswg-cesr-specification",
    "date": "2024-02-15 07:49:35 -0800",
    





    
    "snippet": "Hi, I’ve been following did for a long time, I want to know besides HTTP (s) + JSON, is there any plan to support COAP + CBOR for did resolution ?",
    "content": "Hi, I’ve been following did for a long time, I want to know besides HTTP (s) + JSON, is there any plan to support COAP + CBOR for did resolution ?"
  },
  
  {
    "title": "vc-data-model/pr/1441: fix: Kafka consumer not picking messages",
    "url": "/github-discussions/vc-data-model/pr/1441/",
    "categories": "W3C",
    "tags": "vc-data-model",
    "date": "2024-02-15 05:31:14 -0800",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "credential-trust-establishment/issue/35: Migration to new AnonCreds object format",
    "url": "/github-discussions/credential-trust-establishment/issue/35/",
    "categories": "DIF",
    "tags": "credential-trust-establishment",
    "date": "2024-02-12 10:05:40 -0800",
    





    
    "snippet": "ACA-Py will eventually move a feature that is currently experimental to ready-for-use status: AnonCreds RS support. With this change, the migration strategy used in the wallet upgrade tool will req...",
    "content": "ACA-Py will eventually move a feature that is currently experimental to ready-for-use status: AnonCreds RS support. With this change, the migration strategy used in the wallet upgrade tool will require tweaks to migrate an Indy wallet to the new AnonCreds format.Is this something we should worry about? It should be technically possible to upgrade using this tool as is and then use the upgrade endpoint @jamshale is working on in https://github.com/hyperledger/aries-cloudagent-python/pull/2922.cc: @swcurran"
  },
  
  {
    "title": "uni-resolver-driver-did-key/issue/9: Many errors in rocksdb/_rocksdb.pyx cause build failure",
    "url": "/github-discussions/uni-resolver-driver-did-key/issue/9/",
    "categories": "DIF",
    "tags": "uni-resolver-driver-did-key",
    "date": "2024-02-06 23:19:56 -0800",
    





    
    "snippet": "The first error is:/tmp/pip-build-clvy4twe/python-rocksdb/.eggs/Cython-3.0.8-py3.5.egg/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (P...",
    "content": "The first error is:/tmp/pip-build-clvy4twe/python-rocksdb/.eggs/Cython-3.0.8-py3.5.egg/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /tmp/pip-build-clvy4twe/python-rocksdb/rocksdb/_rocksdb.pyxAfter that, there are hundreds of errors in the module — many referencing a missing “gil”."
  },
  
  {
    "title": "vc-data-model/issue/1432: DIDComm Message Decryption + Disruption by `eth_getLogs`/`eth_getChainId` calls",
    "url": "/github-discussions/vc-data-model/issue/1432/",
    "categories": "Hyperledger",
    "tags": "vc-data-model",
    "date": "2024-02-03 10:43:05 -0800",
    





    
    "snippet": "ProblemIn our use case we are decrypting didcomm messages within the context of our custom MetaMask Snap. This process is quite time consuming (up to approx. 100 seconds). Our specific use case doe...",
    "content": "ProblemIn our use case we are decrypting didcomm messages within the context of our custom MetaMask Snap. This process is quite time consuming (up to approx. 100 seconds). Our specific use case does not invoke calls to the network, however, Veramo (via the provider) does invoke the eth_getLogs and eth_getChainId calls using ethers. In the case of their failure (i.e. in the case the RPC provider comes back with an error, for example, a rate limit), the long running decryption process (i.e. the decryption) is interrupted. Therefore, there are two components to this issue we are facing:  Decryption Time: Why would the decryption take so long? In our case decrypting the DIDComm message (jwe encoded) takes around or over 100 seconds;  Error Handling/Unnecessary Calls: Where calls to the network are not required, such as the case described above, what is the case for these calls?SolutionAs it relates to the decryption time any feedback or insight you can provide on the matter is greatly appreciated. As it pertains to the provider calls on eth_getChainId and eth_getLogs errors bubbling up and cancelling the other processes - even when the aforementioned calls do not appear to be required - it would appear that these could be deactivated.Other QuestionsAny information you can provide on this is greatly appreciated. If we can align on the solution, we would be happy to present a PR, but wanted to sync up here first.ScreenshotExample of offending calls within the background.html in the MetaMask Snap. "
  },
  
  {
    "title": "identus-cloud-agent/issue/864: Missing MAINTAINERS.md",
    "url": "/github-discussions/identus-cloud-agent/issue/864/",
    "categories": "Hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-01-25 01:23:55 -0800",
    





    
    "snippet": "Is this a regression?NoDescriptionAs part of Hyperledger - we MUST have a MAINTAINERS.md file (as per https://toc.hyperledger.org/guidelines/MAINTAINERS-guidelines.html)The repository is currently ...",
    "content": "Is this a regression?NoDescriptionAs part of Hyperledger - we MUST have a MAINTAINERS.md file (as per https://toc.hyperledger.org/guidelines/MAINTAINERS-guidelines.html)The repository is currently missing this file, we must create this file and populate according to the expecations defined in the guidelinesSome content may already be defined in other files in the repositor (from CONTRIBUTING.md)Please provide the exception or error you sawN/APlease provide the environment you discovered this bug inN/AAnything else?No response"
  },
  
  {
    "title": "aries-acapy-docs/issue/93: Support DID Exchange Protocol",
    "url": "/github-discussions/aries-acapy-docs/issue/93/",
    "categories": "Hyperledger",
    "tags": "aries-acapy-docs",
    "date": "2024-01-09 10:41:08 -0800",
    





    
    "snippet": "  Support only did:peer  Swift did:peer library: https://github.com/beatt83/peerdid-swift  Will not support public DID",
    "content": "  Support only did:peer  Swift did:peer library: https://github.com/beatt83/peerdid-swift  Will not support public DID"
  },
  
  {
    "title": "anoncreds-spec/issue/192: Compiled with problems when access react Wallet SDK TS",
    "url": "/github-discussions/anoncreds-spec/issue/192/",
    "categories": "Hyperledger",
    "tags": "anoncreds-spec",
    "date": "2023-12-13 11:16:33 -0800",
    





    
    "snippet": "Is this a regression?YesDescriptionI follow “Running a demo project” guide at https://github.com/input-output-hk/atala-prism-wallet-sdk-tsthen got “Compiled with problems” when access react Wallet ...",
    "content": "Is this a regression?YesDescriptionI follow “Running a demo project” guide at https://github.com/input-output-hk/atala-prism-wallet-sdk-tsthen got “Compiled with problems” when access react Wallet SDK TypeScript DemonstrationPlease provide the exception or error you saw```Compiled with problems:×ERROR in ../../build/browser/anoncreds-3aba21a7.js 3120:12-57Module not found: Error: Can't resolve 'anoncreds_bg.wasm' in '/home/cardano/did/atala-prism-wallet-sdk-ts/build/browser'ERROR in ../../build/browser/didcomm_js-c556b936.js 770:12-58Module not found: Error: Can't resolve 'didcomm_js_bg.wasm' in '/home/cardano/did/atala-prism-wallet-sdk-ts/build/browser'`/from console I saw these logFailed to compile.Module not found: Error: Can't resolve 'anoncreds_bg.wasm' in '/home/cardano/did/atala-prism-wallet-sdk-ts/build/browser'WARNING in ../../node_modules/@atala/apollo/Apollo.js 1766:11-24Critical dependency: the request of a dependency is an expressionWARNING in ../../node_modules/@atala/apollo/Apollo.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/common/src/generated/_Arrays.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/common/src/generated/_Arrays.kt'WARNING in ../../node_modules/@atala/apollo/Apollo.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/src/commonMain/kotlin/io/iohk/atala/prism/apollo/derivation/HDKeyOptions.kt' file: Error: ENOENT: no such file or directory, open '/home/src/commonMain/kotlin/io/iohk/atala/prism/apollo/derivation/HDKeyOptions.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/ranges/ProgressionIterators.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/ranges/ProgressionIterators.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/ranges/Progressions.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/ranges/Progressions.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Appendable.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Appendable.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Char.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Char.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/StringNumberConversions.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/StringNumberConversions.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Strings.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/text/Strings.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/HashCode.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/HashCode.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Lazy.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Lazy.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Preconditions.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Preconditions.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Result.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Result.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Standard.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Standard.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Tuples.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/src/kotlin/util/Tuples.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UByte.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UByte.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UByteArray.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UByteArray.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UInt.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UInt.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UIntArray.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UIntArray.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/ULong.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/ULong.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/ULongArray.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/ULongArray.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UShort.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UShort.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UStrings.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UStrings.kt'WARNING in ../../node_modules/@atala/apollo/kotlin-kotlin-stdlib.jsModule Warning (from ./node_modules/source-map-loader/dist/cjs.js):Failed to parse source map from '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UnsignedUtils.kt' file: Error: ENOENT: no such file or directory, open '/home/cardano/did/atala-prism-wallet-sdk-ts/node_modules/@atala/apollo/unsigned/src/kotlin/UnsignedUtils.kt'ERROR in ../../build/browser/anoncreds-3aba21a7.js 3120:12-57Module not found: Error: Can't resolve 'anoncreds_bg.wasm' in '/home/cardano/did/atala-prism-wallet-sdk-ts/build/browser'ERROR in ../../build/browser/didcomm_js-c556b936.js 770:12-58Module not found: Error: Can't resolve 'didcomm_js_bg.wasm' in '/home/cardano/did/atala-prism-wallet-sdk-ts/build/browser'webpack compiled with 2 errors and 220 warningsNo issues found.Please provide the environment you discovered this bug inI am running in Ubuntu 20.4 and follow Running a demo project guide at https://github.com/input-output-hk/atala-prism-wallet-sdk-tsAnything else?Please not that service is still running"
  },
  
  {
    "title": "presentation-exchange/issue/457: Unclear use of `tag` in key derivation and wrapping algorithm",
    "url": "/github-discussions/presentation-exchange/issue/457/",
    "categories": "DIF",
    "tags": "presentation-exchange",
    "date": "2023-11-02 11:00:26 -0700",
    





    
    "snippet": "I don’t understand how to use a tag in key derivation/wrapping algorithm as described in sections:  5.1.9 ECDH-1PU key wrapping and common protected headers  5.1.10 ECDH-ES key wrapping and common ...",
    "content": "I don’t understand how to use a tag in key derivation/wrapping algorithm as described in sections:  5.1.9 ECDH-1PU key wrapping and common protected headers  5.1.10 ECDH-ES key wrapping and common protected headersThere is a mention“As per this requirement, the JWE building must first encrypt the payload, then use the resulting tag as part of the key derivation process when wrapping the cek.”But I don’t see any information on how that tag should be used in derivation of kek  or wrapping of cek with kek. Am I missing something?"
  },
  
  {
    "title": "veramo-plugin/issue/28: Rewrite PRISM node",
    "url": "/github-discussions/veramo-plugin/issue/28/",
    "categories": "DIF",
    "tags": "veramo-plugin",
    "date": "2023-10-29 10:01:48 -0700",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "didcomm-demo/issue/19: Error handling and Problem reporting for SDKs",
    "url": "/github-discussions/didcomm-demo/issue/19/",
    "categories": "DIF",
    "tags": "didcomm-demo",
    "date": "2023-10-03 10:34:16 -0700",
    





    
    "snippet": "No content available",
    "content": "No content available"
  },
  
  {
    "title": "traceability-interop/issue/589: Update maintainers `w3cid` value in documents",
    "url": "/github-discussions/traceability-interop/issue/589/",
    "categories": "W3C",
    "tags": "traceability-interop",
    "date": "2023-08-23 06:13:40 -0700",
    





    
    "snippet": "Hi @apuchitnis @stenreijers @gatemezing @adam-burns @Steffytan @MizukiSonoko @rajivrajani @genaris @ajile-in and @KDean-Dolphin,Publication of did-extensions is currently failing because some of yo...",
    "content": "Hi @apuchitnis @stenreijers @gatemezing @adam-burns @Steffytan @MizukiSonoko @rajivrajani @genaris @ajile-in and @KDean-Dolphin,Publication of did-extensions is currently failing because some of you don’t have w3cid values listed in your Editor’s entry in each specification. I need each of you to update your w3cid value in the “Editors” section of each document listed below:  https://github.com/w3c/did-extensions/blob/main/index.html#L54-L95  https://github.com/w3c/did-extensions/blob/main/methods/index.html#L95-L136  https://github.com/w3c/did-extensions/blob/main/properties/index.html#L54-L96  https://github.com/w3c/did-extensions/blob/main/resolution/index.html#L54-L96If you don’t have a free w3.org account, you can get one here:https://www.w3.org/account/request/You can then see your w3cid value by logging into w3.org and going to this link:https://www.w3.org/users/myprofile/The value will be in the URL in your web browser address bar. For example, when I go to the URL above, I get redirected to this URL (and my w3cid value is 41758):https://www.w3.org/users/41758/Just raise a PR on all four documents above and I’ll merge them as they come in."
  },
  
  {
    "title": "credential-trust-establishment/issue/18: Identus Cloud Agent Scalability - Background Jobs",
    "url": "/github-discussions/credential-trust-establishment/issue/18/",
    "categories": "DIF",
    "tags": "credential-trust-establishment",
    "date": "2023-08-21 10:44:33 -0700",
    





    
    "snippet": "This Epic aims to investigate ZIO Stream and ZIO Kafka as a replacement for the mechanism behind the execution of background jobs.Currently, each background job is a recurrent ZIO effect created us...",
    "content": "This Epic aims to investigate ZIO Stream and ZIO Kafka as a replacement for the mechanism behind the execution of background jobs.Currently, each background job is a recurrent ZIO effect created using ZIO#repeat that processes a configurable number of records in parallel during each iteration. This will inevitably lead to conflicts and race conditions as soon as we run two instances of the cloud agent in parallel, as the same record will be processed by those two agents sharing the same DB. The related flows will be executed multiple times, and the same DIDComm message will be sent several times to the DIDComm peer.This can be solved using a message queueing system like Kafka and leveraging Kafka’s consumer groups capability to concurrently distribute the load among multiple agent instances.At a later stage, using a queuing mechanism like Kafka would allow us to better control - and allocate resources to - the execution of the resource-intensive tasks that put pressure on the system (e.g., generation of AnonCreds credential definitions via the Rust library)."
  },
  
  {
    "title": "credential-trust-establishment/issue/8: User can backup and restore Wallet (KMM)",
    "url": "/github-discussions/credential-trust-establishment/issue/8/",
    "categories": "DIF",
    "tags": "credential-trust-establishment",
    "date": "2023-05-25 15:58:54 -0700",
    





    
    "snippet": "Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets in...",
    "content": "Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/ARelease notes -Prism documentation - Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/ARelease notes -Prism documentation - Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/A "
  },
  
  {
    "title": "SIG-IoT/issue/17: Error handling for the Agent",
    "url": "/github-discussions/SIG-IoT/issue/17/",
    "categories": "DIF",
    "tags": "SIG-IoT",
    "date": "2023-03-15 10:24:28 -0700",
    





    
    "snippet": "Although PRISM already has some errors defined and returned by our Cloud Agent RestAPI calls, we do not have any mechanism to handle and report errors when they are happening during record processi...",
    "content": "Although PRISM already has some errors defined and returned by our Cloud Agent RestAPI calls, we do not have any mechanism to handle and report errors when they are happening during record processing or sending/receiving DIDComm messages. It is required to implement a mechanism of error handling for Cloud Agent to log, update records in the database, and report errors in the right way.  hyperledger/identus-edge-agent-sdk-ts/issues/308"
  },
  
  {
    "title": "org/pr/22: Bump ubuntu from 16.04 to 24.04 in /ci",
    "url": "/github-discussions/org/pr/22/",
    "categories": "DIF",
    "tags": "org",
    "date": "2023-02-24 03:09:43 -0800",
    





    
    "snippet": "Bumps ubuntu from 16.04 to 24.04.Dependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.D...",
    "content": "Bumps ubuntu from 16.04 to 24.04.Dependabot will resolve any conflicts with this PR as long as you don’t alter it yourself. You can also trigger a rebase manually by commenting @dependabot rebase.Dependabot commands and optionsYou can trigger Dependabot actions by commenting on this PR:- `@dependabot rebase` will rebase this PR- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it- `@dependabot merge` will merge this PR after your CI passes on it- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it- `@dependabot cancel merge` will cancel a previously requested merge and block automerging- `@dependabot reopen` will reopen this PR if it is closed- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually- `@dependabot show  ignore conditions` will show all of the ignore conditions of the specified dependency- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)&lt;/details&gt;"
  },
  
  {
    "title": "did-resolver/issue/97: Infinite loop in Release process",
    "url": "/github-discussions/did-resolver/issue/97/",
    "categories": "DIF",
    "tags": "did-resolver",
    "date": "2021-08-30 02:14:56 -0700",
    





    
    "snippet": "Go to https://handbook.atalaprism.io/engineering/sdlc/release/release-process-overview.And go at the bottom of the page. The link on the right is Release process anew, so it is an infinite loop.",
    "content": "Go to https://handbook.atalaprism.io/engineering/sdlc/release/release-process-overview.And go at the bottom of the page. The link on the right is Release process anew, so it is an infinite loop."
  },
  
  {
    "title": "did-jwt/issue/194: Cleanup the GitHub workflows after moving to the GitHub pages",
    "url": "/github-discussions/did-jwt/issue/194/",
    "categories": "DIF",
    "tags": "did-jwt",
    "date": "2021-08-24 21:51:03 -0700",
    





    
    "snippet": "The workflow files should be cleaned up: the docker image with the documentation portal and the corresponding helm chart are not needed anymore.",
    "content": "The workflow files should be cleaned up: the docker image with the documentation portal and the corresponding helm chart are not needed anymore."
  }
  
]

