[
  
  {
    "title": "ACA-Py failing to start, gives KeyError: 'pattern'",
    "url": "/github-discussions/acapy/3353/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-11-25 07:25:18 -0800",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/issues/3353ACA-py started failing to start in the Interop Test Pipeline over the weekend. This is the error. The pipeline pull from main to build...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/issues/3353ACA-py started failing to start in the Interop Test Pipeline over the weekend. This is the error. The pipeline pull from main to build acapy.2024-11-25 15:13:18,787 acapy_agent.core.plugin_registry ERROR Module doesn't exist: redis_events.v1_0.redis_queue.events2024-11-25 15:13:19,438 acapy_agent.commands.start ERROR Exception during startup:Traceback (most recent call last):  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/commands/start.py\", line 72, in init    await startup  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/commands/start.py\", line 28, in start_app    await conductor.setup()  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/core/conductor.py\", line 128, in setup    context = await self.context_builder.build_context()              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/config/default_context.py\", line 78, in build_context    await self.load_plugins(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/config/default_context.py\", line 183, in load_plugins    await plugin_registry.init_context(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/core/plugin_registry.py\", line 207, in init_context    await plugin.setup(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/__init__.py\", line 62, in setup    await universal_resolver.setup(context)  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 66, in setup    supported_did_regex = await self._get_supported_did_regex()                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 115, in _get_supported_did_regex    return _compile_supported_did_regex(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 24, in _compile_supported_did_regex    for pattern in patterns                   ^^^^^^^^  File \"/usr/local/lib/python3.12/site-packages/acapy_agent/resolver/default/universal.py\", line 116, in &lt;genexpr&gt;    driver[\"http\"][\"pattern\"] for driver in props.values()    ~~~~~~~~~~~~~~^^^^^^^^^^^KeyError: 'pattern'Shutting down"
  },
  
  {
    "title": "Support for subdirectory in SERVICE_ENDPOINTS",
    "url": "/github-discussions/identus-mediator/382/",
    "categories": "hyperledger",
    "tags": "identus-mediator",
    "date": "2024-11-23 16:04:25 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-mediator/issues/382Sometimes is desirable to run the mediator endpoint in a subdirectory of a webapp to avoid CORS issues, for example, defining SERVICE_...",
    "content": "URL: https://github.com/hyperledger/identus-mediator/issues/382Sometimes is desirable to run the mediator endpoint in a subdirectory of a webapp to avoid CORS issues, for example, defining SERVICE_ENDPOINTS='https://www.myapp.com/mediator'. If you setup the ProxyPass on webserver correctly, when you try to load the endpoint it fails trying to load https://www.myapp.com/public/webapp-fastopt-bundle.js because the mediator server endpoint is assuming the SERVICE_ENDPOINT is not on a subdirectory and on a web root."
  },
  
  {
    "title": "SUPER/META PROPOSAL: Authentication of unique DID Method names: allowing for multiple approaches",
    "url": "/github-discussions/did-extensions/597/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-11-22 07:09:36 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/597@msporny proposed restricted approach here: https://github.com/w3c/did-extensions/issues/595In this Super/Meta Proposal, I want to suggest that ...",
    "content": "URL: https://github.com/w3c/did-extensions/issues/597@msporny proposed restricted approach here: https://github.com/w3c/did-extensions/issues/595In this Super/Meta Proposal, I want to suggest that the DID method registration section in the spec be modified to support more than one Authentication of unique DID Method names approach that covers the following objectives:  Removes the burden from the reviewers  Removes the W3C from having to arbitrate DID method uniqueness issues  Produces a tangible result in terms of authenticating the uniqueness of new DID Method registration applicationsThe idea is to support, in the specification, more than one trivially easy-to-access Authentication of unique DID Method names  approach - with the goal of giving registrants/controllers at least a couple choices that they can choose from based on time, effort, and cost.  For example, tradmarking is costly especially for registrants who do not have in-house legal council - more cost effective solution(s) are also needed.  The wording of the specification cannot be prejudiced for or against any registrant.  In addition, a DID Method name may not be trademarkable: https://github.com/w3c/did-extensions/issues/595#issuecomment-2494098759So what’s on the table in terms of approaches (in order of strength: effectiveness, cost, time, and effort):  DNS Registration: Leveraging what is already available using Internet Doman Name System (DNS) domain name registration. Examples of such an approach can be found in https://github.com/w3c/did-extensions/issues/590  Registered trademarks per the concepts outlined here: https://github.com/w3c/did-extensions/issues/595  Unregistered trademarks  No authentication of uniqueness supplied in the applicationNOTE: The implication of point 4 is that we add a field to the DID Method Name registration file to specify the registrant’s Authentication of unique DID Method names approach/evidence.  This can be a simple text field with a link to the domain registration, a trademark statement, etc.  An empty or missing field would default to class 4: No authentication of uniqueness provided.  This field can also be used to ajudicate new applications that have or claim to have a stronger authentication.Q: any additional Authentication of unique DID Method names approaches that would be simple in terms of effort, time and cost for the registrant and as well the reviewers and the W3C?Other thoughts?"
  },
  
  {
    "title": "Restore `--base-wallet-routes` flag functionality",
    "url": "/github-discussions/acapy/3344/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-11-21 10:21:14 -0800",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/pull/3344Resolves #3283The tenant_authentication has been updated to also allow access to the base wallet when the route matches a path defined u...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/pull/3344Resolves #3283The tenant_authentication has been updated to also allow access to the base wallet when the route matches a path defined using --base-wallet-routes.Please note that, when compared to the previous implementation, the matcher has been made more greedy to tighten security: if an extra route of /test is specified, the matcher will only match that and not /testA or /test-something-else as it appears it would have done before.One drawback of having to use this matcher inside the decorator is that I could not think of an elegant way of caching the compiled pattern for reuse - suggestions on how to achieve that, if desirable/required, will be welcome."
  },
  
  {
    "title": "CR: Need a way to detect \"cancel\"",
    "url": "/github-discussions/webauthn/2211/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-21 09:31:50 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2211Proposed ChangeNeed a way to programmatically detect when the user has cancelled the “Use passkey from another device” browser native prompt by click...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2211Proposed ChangeNeed a way to programmatically detect when the user has cancelled the “Use passkey from another device” browser native prompt by clicking the “Cancel” button. This could be achieved by adding a new property or event to the prompt that indicates whether the user has cancelled the prompt.^ the “cancel” button there."
  },
  
  {
    "title": "Clarify the registration process wrt. trademarks and copyrights",
    "url": "/github-discussions/did-extensions/595/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-11-21 08:51:14 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/595The current specification doesn’t say that in order to block or remove a registration that a /registered/ trademark is required. The language ar...",
    "content": "URL: https://github.com/w3c/did-extensions/issues/595The current specification doesn’t say that in order to block or remove a registration that a /registered/ trademark is required. The language around copyright is also problematic (granting a copyright holder the broad ability to block a registration). The text needs to be updated to remove much of the evaluation burden from the maintainers (by requiring that the trademark owner has the burden of proof). The purpose of this issue is to track this desired clarification."
  },
  
  {
    "title": "Add test vectors",
    "url": "/github-discussions/webauthn/2209/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-20 10:38:52 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/pull/2209Closes #1633. Sorry it took so long!The test vectors proposed in #1633 use RP IDs of real websites unaffiliated with W3C, which felt out of place to me...",
    "content": "URL: https://github.com/w3c/webauthn/pull/2209Closes #1633. Sorry it took so long!The test vectors proposed in #1633 use RP IDs of real websites unaffiliated with W3C, which felt out of place to me, so I chose to generate new ones instead. Also in order to pre-empt any worry that there could be something nefarious hidden in these values, they are all generated deterministically from disclosed PRNG seeds. Consequently the attestation statements are synthetic values rather than real attestations from the corresponding trusted source, which unfortunately means there’s more room for error, but I think it’s worth it to have the examples self-contained and transparent. I invite library authors to try running their registration and authentication procedures on these examples so that we may work out any inconsistencies.I plan to also share the code used to generate these, but I needed to patch some of the libraries I used, so I need to resolve that first.Preview | Diff"
  },
  
  {
    "title": " proof request there's no information on holder ",
    "url": "/github-discussions/identus-cloud-agent/1459/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-20 02:34:25 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1459Is this a regression?NODescriptionRight know when we have a proof request there’s no information on holder side of what’s being re...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1459Is this a regression?NODescriptionRight know when we have a proof request there’s no information on holder side of what’s being requested.Holder webhook data:PresentationStatusAdapter(presentationId=94acbe0f-ed87-4477-9757-4b4ba8c3461d, thid=d080d2b5-0498-42aa-a829-22cf021ff3cf, role=PROVER, status=REQUEST_RECEIVED, metaRetries=5, proofs=[], data=[], connectionId=null)GET /present-proof/presentations/$presentationId{    “presentationId”: “94acbe0f-ed87-4477-9757-4b4ba8c3461d”,    “thid”: “d080d2b5-0498-42aa-a829-22cf021ff3cf”,    “role”: “Prover”,    “status”: “RequestReceived”,    “proofs”: [],\"data\": [    ],\"requestData\": [    \"{\\n  \\\"options\\\" : {\\n    \\\"domain\\\" : \\\"https://example-verifier.com\\\",\\n    \\\"challenge\\\" : \\\"11c91493-01b3-4c4d-ac36-b336bab5bddf\\\"\\n  },\\n  \\\"presentation_definition\\\" : {\\n    \\\"format\\\" : null,\\n    \\\"name\\\" : null,\\n    \\\"purpose\\\" : null,\\n    \\\"id\\\" : \\\"345b056f-2889-458a-9f59-25d1ab249557\\\",\\n    \\\"input_descriptors\\\" : [\\n    ]\\n  }\\n}\"],\"metaRetries\": 5 }The data is available in the RequestPresentation Attachment but we don’t expose it on the endpoint This will be helpful fro cloud agnet  while testing testPlease provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "DID Management Proposed Update",
    "url": "/github-discussions/acapy/3343/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-11-19 08:58:08 -0800",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/issues/3343In light of our current push to add support for more DID Methods to ACA-Py, some primitives within ACA-Py need some updates. This issu...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/issues/3343In light of our current push to add support for more DID Methods to ACA-Py, some primitives within ACA-Py need some updates. This issue outlines the updates I propose. I plan to update this further as the topic is discussed or as implementations better inform decisions.Proposed UpdatesDID Storage (updating DIDInfo)Current StateAt present, the DIDInfo object looks like this:https://github.com/openwallet-foundation/acapy/blob/f5c49b0710dd180ea31c45f73bc82ef06f9523b4/acapy_agent/wallet/did_info.py#L20-L29This is stored in the wallet with a category of did, the primary identifier being the DID value, and the following tags:  method: the method name  verkey: the verkey element of the tuple where it is the base58 encoding of the public key  verkey_type: the key type of the verkey (e.g. ed25519)As currently used, metadata will include:  posted: a boolean value representing whether this did has been published to an indy network  endpoint: a string value representing associated with the endpoint attrib of this did on an indy network.EvaluationAs is plain to see, the structure, tags, and metadata of the DIDInfo object are very Indy-oriented. This structure has been in use for years.Currently, ACA-Py will retrieve a DIDInfo object in order to use the key associated with the “DID.” It will do this by taking a “DID” as input (usually, actually more like a “nym” value, i.e. 16 base58 encoded bytes without a did: prefix), then using the verkey value to retrieve a Key object that it can then use to perform a signature or pack a DIDComm message.SolutionDIDs should have multiple keys associated with them rather than a single key. To achieve this while also having an efficient lookup mechanism, we should reorient our storage as outlined below.Quick background on AskarAskar is a secure storage solution used by ACA-Py. Askar encrypts all data and provides a tagging mechanism to enable lookup of encrypted records. An entry in Askar is composed of the following elements:  Category: The major group or “bucket” that the entry belongs to.  Name: The primary identifier for the record; this is roughly equivalent to primary keys on a traditional DB table. The most efficient lookup possible is by name.  Value: The value stored in the entry. This is usually a serialized JSON object.  Tags: A mapping of strings to strings or lists of strings. These values can be used with the “Wallet Query Language (WQL)” to look up encrypted Askar entries efficiently.Askar has a dedicated API for storage and retrieval of keys. However, this API is conceptually just a shorthand for record storage and retrieval from a “private” key category with the key itself as the value of the entry. Key entries behave almost exactly the same as non-key entries, including names and tags.Key StorageBuilding off of Patrick’s contributions of managing keys by multikey instead of “verkey,” the multikey representation of a key should be the default identifier for keys in the wallet.  Name: multikey representation of the key  Tags:          Implicit tag for the KeyAlg (automatically included on every key)      did: the DID (or a list of DIDs) the key is associated with      vm_id: an absolute DID URL (or a list of DID URLs) representing the verification method ID(s) of the key      rel: A list of verification relationships as defined by the DID Core spec; e.g. [\"authentication\", \"assertionMethod\"]. This represents the intended use of this key.      alias: A human-friendly alias (or list of aliases) that can help identify a key to a user      These sets of tags enable us to look up keys with a combination of did and rel; when these tags are lists, Askar will return all keys that contain the tag filter value in their respective list. This permits the controller to continue to specify just a DID as the issuer/signer/sender of a value without having to know exactly which key ACA-Py should use to perform the operation. This also permits the controller to continue to use the verification method ID directly to specify a key that might not normally be selected first. Additionally, when a specific proof type is desired, Askar can also filter by KeyAlg so a simple mapping from proof type to appropriate KeyAlgs can efficiently accomplish this filtering.DID StorageDIDs should be altered to be stored in a way that simply acknowledges that we own the DID and not as the primary key retrieval mechanism.  Category: did  Name: the DID itself  Value:          …        Tags:          method: a string representing the DID Method      (Maybe?) features: the list of features the DID is capable of      Other things it would be valuable to use to look up the DID?      MigrationExisting ACA-Py wallets should have the following migration performed to accommodate this reorientation:  Migrate all existing records in the did category to the new structure and also duplicate the record to a legacy nym category          If the did value is unqualified, “move” to the new did category and map old values onto new, adding did:sov: to the front.      If the did value is unqualified, also create a record in the new nym category with a structure matching the original DIDInfo object, where a verkey is closely associated with the nym. This should enable us to continue using the builtin Indy support in a way that distinguishes the old from the new.      For did values that are qualified, move to the new did category and make sure the associated key entries are properly tagged. This will depend on the DID Method. Plugged in DID Methods may need to account for their own DID methods in a separate migration process.      "
  },
  
  {
    "title": "\"Verify\" is undefined",
    "url": "/github-discussions/webauthn/2208/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-18 07:50:14 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2208For example, https://w3c.github.io/webauthn/#sctn-registering-a-new-credential has a step that reads  Verify that the value of C.type is webauthn.cre...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2208For example, https://w3c.github.io/webauthn/#sctn-registering-a-new-credential has a step that reads  Verify that the value of C.type is webauthn.create.but it’s not at all clear what this means or what should happen when it cannot be true. If it’s always meant to be true unless something outside of the scope of the specification has happened, it would be more appropriate to use Infra’s Assert primitive.If it can actually have other values, you’ll need to define how to handle those."
  },
  
  {
    "title": "JSON parsing should be on top of Infra primitives",
    "url": "/github-discussions/webauthn/2207/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-18 05:58:14 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2207I suspect that most can be replaced by https://infra.spec.whatwg.org/#parse-json-bytes-to-an-infra-value. This will also require some changes to the ...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2207I suspect that most can be replaced by https://infra.spec.whatwg.org/#parse-json-bytes-to-an-infra-value. This will also require some changes to the following steps as they now have an Infra value. This should also allow for the removal of the notes as now this is all well-defined instead of somewhat hand-wavy."
  },
  
  {
    "title": "Use of \"valid domain\" seems wrong",
    "url": "/github-discussions/webauthn/2206/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-18 05:55:36 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2206No user agent implements “valid domain”. I suspect that instead you simply want to do a type check that the host of an origin is a domain.Also, what ...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2206No user agent implements “valid domain”. I suspect that instead you simply want to do a type check that the host of an origin is a domain.Also, what kind of schemes can this origin have and do those need to be checked?"
  },
  
  {
    "title": "Usage of \"effective domain\" seems wrong",
    "url": "/github-discussions/webauthn/2205/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-18 05:54:16 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2205No other specification really ought to use “effective domain”. That’s only for document.domain-related business. I suspect you just want to grab an o...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2205No other specification really ought to use “effective domain”. That’s only for document.domain-related business. I suspect you just want to grab an origin’s host and ignore this operation."
  },
  
  {
    "title": "Verifiable Credential Issued in JWT uses longform of prism DID in the iss field of JWT",
    "url": "/github-discussions/identus-cloud-agent/1451/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-18 05:19:24 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1451Is this a regression?NoDescriptionA Verifiable Credential issued in JWT format currently uses the long-form of a Prism DID in the ...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1451Is this a regression?NoDescriptionA Verifiable Credential issued in JWT format currently uses the long-form of a Prism DID in the iss field of the JWT. We should update this to use the short-form Prism DID instead. Below is an example of a VC issued in JWT format, and upon decoding, the iss field displays the long-form DIDeyJ0eXAiOiJKV1QiLCJhbGciOiJFZERTQSJ9.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.BlhAJdhgJO58y17Xe21iKnOkrj2JNcK_R2tfUAfCh_KO8jjOepCVLZWJWqcV–XkBMraUJCT8R4H1KhIlAIyBQ```{  “iss”: “did:prism:f2ebecf1b5e94edd6b0fc456ce2fba0cb78a17352e1af5cd86e2fa02ad7a8d77:CpsCCpgCEkYKFW15LWtleS1hdXRoZW50aWNhdGlvbhAESisKB0VkMjU1MTkSINnhhfj-t1wuAjKHT3mYMQ44QMqwJ4lo4HOdkNMcIAxnEkcKFm15LWtleS1hc3NlcnRpb25NZXRob2QQAkorCgdFZDI1NTE5EiCboM2DRna–XtFO_E34EWhTa34LjFD7FdE3qnyZMt5uBI7CgdtYXN0ZXIwEAFKLgoJc2VjcDI1NmsxEiEC1fopauP-Kz-7szZFWAnf_xEiF9YOScS6CfmvQm7PWRsaSAoOYWdlbnQtYmFzZS11cmwSEExpbmtlZFJlc291cmNlVjEaJGh0dHA6Ly8xOTIuMTY4LjEuODY6ODAwMC9jbG91ZC1hZ2VudA”,  “sub”: “did:prism:ce30775196fe449f6731dda2eafee1a620fee224a7e6f631ba748afca6155093:CpcCCpQCEj8KC215LWF1dGgta2V5EARKLgoJc2VjcDI1NmsxEiEC2qHVEawblVd8nnGN8HMhpHpfFd0TRLuRY9GU-w0ZPtcSSgoWbXkta2V5LWFzc2VydGlvbk1ldGhvZBACSi4KCXNlY3AyNTZrMRIhA5G9MWNRRr8SHxSHah1cvj7eXdsYzW-x-eqVAWsTxPcyEjsKB21hc3RlcjAQAUouCglzZWNwMjU2azESIQMmLm5mHjWMuF5RZn4Vb1j4hGtHIsQht1wHVCwv1Qv1ZRpICg5hZ2VudC1iYXNlLXVybBIQTGlua2VkUmVzb3VyY2VWMRokaHR0cDovLzE5Mi4xNjguMS44Njo5MDAwL2Nsb3VkLWFnZW50”,  “nbf”: 1731927195,  “exp”: 1731930795,  “vc”: {    “credentialSchema”: [      {        “id”: “http://192.168.1.86:8000/cloud-agent/schema-registry/schemas/7b4b0f23-d995-3e7a-bf9d-19bbe10e2d4b”,        “type”: “CredentialSchema2022”      }    ],    “credentialSubject”: {      “emailAddress”: “alice@wonderland.com”,      “drivingClass”: 3,      “familyName”: “Wonderland”,      “givenName”: “Alice”,      “drivingLicenseID”: “12345”,      “id”: “did:prism:ce30775196fe449f6731dda2eafee1a620fee224a7e6f631ba748afca6155093:CpcCCpQCEj8KC215LWF1dGgta2V5EARKLgoJc2VjcDI1NmsxEiEC2qHVEawblVd8nnGN8HMhpHpfFd0TRLuRY9GU-w0ZPtcSSgoWbXkta2V5LWFzc2VydGlvbk1ldGhvZBACSi4KCXNlY3AyNTZrMRIhA5G9MWNRRr8SHxSHah1cvj7eXdsYzW-x-eqVAWsTxPcyEjsKB21hc3RlcjAQAUouCglzZWNwMjU2azESIQMmLm5mHjWMuF5RZn4Vb1j4hGtHIsQht1wHVCwv1Qv1ZRpICg5hZ2VudC1iYXNlLXVybBIQTGlua2VkUmVzb3VyY2VWMRokaHR0cDovLzE5Mi4xNjguMS44Njo5MDAwL2Nsb3VkLWFnZW50”,      “dateOfIssuance”: “2020-11-13T20:20:39+00:00”    },    “type”: [      “VerifiableCredential”    ],    “@context”: [      “https://www.w3.org/2018/credentials/v1”    ],    “issuer”: {      “id”: “did:prism:f2ebecf1b5e94edd6b0fc456ce2fba0cb78a17352e1af5cd86e2fa02ad7a8d77:CpsCCpgCEkYKFW15LWtleS1hdXRoZW50aWNhdGlvbhAESisKB0VkMjU1MTkSINnhhfj-t1wuAjKHT3mYMQ44QMqwJ4lo4HOdkNMcIAxnEkcKFm15LWtleS1hc3NlcnRpb25NZXRob2QQAkorCgdFZDI1NTE5EiCboM2DRna–XtFO_E34EWhTa34LjFD7FdE3qnyZMt5uBI7CgdtYXN0ZXIwEAFKLgoJc2VjcDI1NmsxEiEC1fopauP-Kz-7szZFWAnf_xEiF9YOScS6CfmvQm7PWRsaSAoOYWdlbnQtYmFzZS11cmwSEExpbmtlZFJlc291cmNlVjEaJGh0dHA6Ly8xOTIuMTY4LjEuODY6ODAwMC9jbG91ZC1hZ2VudA”,      “type”: “Profile”    },    “credentialStatus”: {      “statusPurpose”: “Revocation”,      “statusListIndex”: 2,      “id”: “http://192.168.1.86:8000/cloud-agent/credential-status/a71b2646-af9d-4453-97bd-4825aec31d2c#2”,      “type”: “StatusList2021Entry”,      “statusListCredential”: “http://192.168.1.86:8000/cloud-agent/credential-status/a71b2646-af9d-4453-97bd-4825aec31d2c”    }  }}``Please provide the exception or error you sawNAPlease provide the environment you discovered this bug inNA"
  },
  
  {
    "title": "Add support for SDJWT  trustedIssuer and credential SchemaId Validation ",
    "url": "/github-discussions/identus-cloud-agent/1450/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-18 05:13:03 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1450Is this a regression?NoDescriptionSDJWT is similar flow as JWT so need to support  similar to JWT { “connectionId”: “{{VERIFIER_CO...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1450Is this a regression?NoDescriptionSDJWT is similar flow as JWT so need to support  similar to JWT { “connectionId”: “{{VERIFIER_CONNECTION_ID}}”, “proofs”: [            {                “schemaId”: “{{baseUrl}}/schema-registry/schemas/{{SCHEMA_ID}}”,                “trustIssuers”: [                    “did:prism:invalidddddđ”                ]            }], “options”: {    “challenge”: “11c91493-01b3-4c4d-ac36-b336bab5bddf”,    “domain”: “https://prism-verifier.com”  },  “credentialFormat”: “SDJWT”,  “claims”: {        “emailAddress”: {},        “givenName”: {},        “country” :{}     }}Please provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "test: add new tests and refactoring",
    "url": "/github-discussions/identus-cloud-agent/1442/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-15 15:02:41 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/pull/1442Description:Adds more tests and refactoringChecklist:  My PR follows the contribution guidelines of this project  My PR is free of t...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/pull/1442Description:Adds more tests and refactoringChecklist:  My PR follows the contribution guidelines of this project  My PR is free of third-party dependencies that don’t comply with the Allowlist  I have commented my code, particularly in hard-to-understand areas  I have made corresponding changes to the documentation  I have added tests that prove my fix is effective or that my feature works  I have checked the PR title to follow the conventional commit specification"
  },
  
  {
    "title": "docs/ Docker error",
    "url": "/github-discussions/identus-cloud-agent/1440/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-14 17:27:38 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1440Is this a regression?YesDescriptionReading docs/README.md there are instructions for seeing swagger docs. They didn’t work for meP...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1440Is this a regression?YesDescriptionReading docs/README.md there are instructions for seeing swagger docs. They didn’t work for mePlease provide the exception or error you sawdocker compose -f docs/docker-compose.yml upWARN[0000] /home/projects/IDENTUS/identus-cloud-agent/docs/docker-compose.yml: the attribute `version` is obsolete, it will be ignored, please remove it to avoid potential confusion[+] Running 1/2 ✘ atala-structurizr-lite Error pull access denied for atala-struc...                               4.0s ⠏ swagger-ui Pulling                                                                               4.0sError response from daemon: pull access denied for atala-structurizr-lite, repository does not exist or may require 'docker login': denied: requested access to the resource is deniedPlease provide the environment you discovered this bug inLinux: Debian/Ubuntu 22.04Docker: version 27.3.1, build ce12230Anything else?Note I had to run docker compose not docker-compose … i forget why docker split these out / when … generally it’s not a problem to swap those commands but it is a deviation from the documented command to run"
  },
  
  {
    "title": "Should steps 28 and 29 occur before Step 27 in the registration ceremony",
    "url": "/github-discussions/webauthn/2204/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-14 13:07:57 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2204Currently step 27 occurs before steps 28 and 29; however it seems weird to “create and store a new credential record in the user account” before succ...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2204Currently step 27 occurs before steps 28 and 29; however it seems weird to “create and store a new credential record in the user account” before successfully completing steps 28 and 29, right? This means one could save a credential even though the ceremony fails later.A similar issue exists for the authentication ceremony where step 23 occurs before steps 24 and 25.I think moving those steps last makes the most sense since this way any credential creation or update occurs iff the ceremony succeeds."
  },
  
  {
    "title": "Cardano Connector for SDK",
    "url": "/github-discussions/identus/86/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-11-14 08:12:54 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/86Short DescriptionA connector for the SDKs to submit the PRISM Block to the Cardano Blockchain.Value statementAs a community we already agreed th...",
    "content": "URL: https://github.com/hyperledger/identus/issues/86Short DescriptionA connector for the SDKs to submit the PRISM Block to the Cardano Blockchain.Value statementAs a community we already agreed this is value coming from the discussion in https://github.com/hyperledger/identus/discussions/80But just the summarize:The PRISM Node can be view as a Cardano Connector. But is a component that is able to do much more that simple submit transaction with metadata.But this is a very common use case in Cardano.The value of this come from bypassing this dedicated component of the did:prism method. With a generic component that uses infrastructure that already exists and that is largely available.Again, the ONLY concern that we care about in here is the Writing Path.We don’t care about the status of DID in here. But to create valid PRISM Block you need to know the status of the DID. For that you have the Reading Path. Both PRISM Node or the universal resolver cover that.For example when you create a new did:prism you already know the state of the DID, because it is no existed.So let’s split responsibility:  The SDKs needs to produce the bytes that constitute a valid PRISM Block.Note the PRISM Block is already sign with the private keys if the DID, so the Keys is never shared with the connector.  The Cardano Connector receive the bytes of the PRISM Block (which is a protobuf) and create a transactions with those bytes on the metadata and a metadata id 21325.See Appendix A &amp; B on the PRISM DID method specs for more for more information.  Private keys. There are you two pairs of Private keys, one is the Master key on the DID and another is the key of the wallet.          The Master private key of the DID is never shared with the Connector. This key is used to sign the PRISM Object in order to make the PRISM Block.      The private key of the wallet its also never shared to other components. This key is used to sign the Cardano transactions.      I propose we do a proof of concept of a connector that will be a Chrome extension and use the TS SDK to call the Lace wallet and make a transaction via the Lace wallet.The idea is to explore CIP30 API and try to build from there https://cips.cardano.org/cip/CIP-30ComponentsProof of concept for a new company ComponentWriting path of the did:prism method using the TS SDK"
  },
  
  {
    "title": "Replace `USVString` with `DOMString`",
    "url": "/github-discussions/webauthn/2203/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-14 07:08:41 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2203It would appear that the same justification that was used for #2115 applies to the remaining areas where USVString is used:  As recommended by the We...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2203It would appear that the same justification that was used for #2115 applies to the remaining areas where USVString is used:  As recommended by the Web IDL spec:      Specifications should only use USVString for APIs that perform text processing and need a string of scalar values to operate on. Most APIs that use strings should instead be using DOMString, which does not make any interpretations of the code units in the string. When in doubt, use DOMString.  Currently the only places where USVString is used are the following extensions:  appid  appidExclude  prfShould these all be changed to DOMString?"
  },
  
  {
    "title": "AttestationFormats may have duplicate entries",
    "url": "/github-discussions/webauthn/2202/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-13 18:19:50 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2202Proposed ChangeIn the spec, we introduce attestationFormats for RPs to indicate the attestation statement format preference for create options.The de...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2202Proposed ChangeIn the spec, we introduce attestationFormats for RPs to indicate the attestation statement format preference for create options.The definition in the spec is as follows.  attestationFormats, of type sequence&lt;DOMString&gt;, defaulting to []The Relying Party MAY use this OPTIONAL member to specify a preference regarding the attestation statement format used by the authenticator. Values SHOULD be taken from the IANA “WebAuthn Attestation Statement Format Identifiers” registry [IANA-WebAuthn-Registries] established by [RFC8809]. Values are ordered from most preferable to least preferable. This parameter is advisory and the authenticator MAY use an attestation statement not enumerated in this parameter.Since the value itself is the list of ordered preferences, it implies that the element of the fields would be unique.The sequence&lt;’T’&gt; does not have any such constraints for uniqueness.Thus, duplicated entries in the attestationFormats may be valid input as per the current spec. We may add some constraints around the field itself or we could describe the way for authenticator and client to handle such duplicated entries without throwing errors.This issue is related to the #2145 and maybe we could resolve this issue with similar manner."
  },
  
  {
    "title": "Proofs from presentation request not work",
    "url": "/github-discussions/identus-cloud-agent/1438/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-11-13 18:19:10 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1438Is this a regression?YesDescriptionHello, regarding the request body for the presentation request:I don’t understand the fields pr...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/1438Is this a regression?YesDescriptionHello, regarding the request body for the presentation request:I don’t understand the fields proofs.schemaId and proofs.trustIssuers. Although I sent a credential that does not match the schemaId and issuerDid, the status in the cloud agent still returns “PresentationVerified.”Is that a bug?{    \"connectionId\": \"bee34719-def5-4420-8d4f-35318e72e916\",    \"proofs\": [        {            \"schemaId\": \"ddec9bf9-b187-3862-897d-dd11d1c1eb53\",            \"trustIssuers\": [                \"did:prism:invalidddddđ\"            ]        }    ],    \"options\": {        \"challenge\": \"{{$randomUUID}}\",        \"domain\": \"https://prism-verifier.com\"    },    \"credentialFormat\": \"JWT\"}Please provide the exception or error you sawNo responsePlease provide the environment you discovered this bug in1.39.1-104-1c7c38eAnything else?No response"
  },
  
  {
    "title": "WebAuthn Clients should NOT zero out AAGUIDs from security keys when attestation is none",
    "url": "/github-discussions/webauthn/2198/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-11-13 12:51:20 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2198There has been some confusion across multiple issues, so creating another one 🫠.In #2058, spec text was added to only zero out AAGUIDs for none attes...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2198There has been some confusion across multiple issues, so creating another one 🫠.In #2058, spec text was added to only zero out AAGUIDs for none attestations when the authenticator was not a platform authenticator.Proposal is to remove this change altogether, which would allow AAGUIDs from security keys to not be zeroed out.Remove:If authenticator is not a [platform authenticator](https://w3c.github.io/webauthn/#platform-authenticators) then replace the [aaguid](https://w3c.github.io/webauthn/#authdata-attestedcredentialdata-aaguid) in the [attested credential data](https://w3c.github.io/webauthn/#attested-credential-data) with 16 zero bytes.This makes the behavior the same across all authenticator types from the client perspective."
  },
  
  {
    "title": "Scalability and Performance Optimization",
    "url": "/github-discussions/org/57/",
    "categories": "decentralized-identity",
    "tags": "org",
    "date": "2024-11-13 10:04:46 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/org/issues/57Optimize scalability and performance when interacting with decentralized web nodes, ensuring a reliable and efficient user experience.",
    "content": "URL: https://github.com/decentralized-identity/org/issues/57Optimize scalability and performance when interacting with decentralized web nodes, ensuring a reliable and efficient user experience."
  },
  
  {
    "title": "SPEC/PROCESS PROPOSAL: To secure a unique method name, require the registration of the corresponding Internet DNS name: did-<method>. directory ",
    "url": "/github-discussions/did-extensions/590/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-11-10 14:57:39 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/590For example,  did:ns -&gt; http://did-ns.directory  did: object -&gt; http://did-object.directoryThere would be no requirement to implement or u...",
    "content": "URL: https://github.com/w3c/did-extensions/issues/590For example,  did:ns -&gt; http://did-ns.directory  did: object -&gt; http://did-object.directoryThere would be no requirement to implement or use the registered domain. It would be like buying an automobile license plate and never placing it on a vehicle (which is OK).Second, this would remove the W3C from the conflicting method name problem.Third, existing W3C registrations would be “grandfathered in”; i.e. not required to have the DNS name registration but it would still be recommended.Other thoughts?"
  },
  
  {
    "title": "Objection: approval of did:tdw",
    "url": "/github-discussions/did-extensions/586/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-11-07 09:37:26 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/586I have a commercial objection to the approval of did:tdw.“tdw” overlaps significantly with the Trusted Digital Web, the parent project of the We...",
    "content": "URL: https://github.com/w3c/did-extensions/issues/586I have a commercial objection to the approval of did:tdw.“tdw” overlaps significantly with the Trusted Digital Web, the parent project of the Web 7.0 Ultraweb.Reference: https://github.com/mwherman2000/TrustedDigitalWebSee PR  https://github.com/w3c/did-extensions/pull/581#issuecomment-2462828639 for the details."
  },
  
  {
    "title": "https://www.w3.org/TR/did-extensions-methods/ is unresolvable ",
    "url": "/github-discussions/did-extensions/585/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-11-07 09:23:22 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/585In the Extensions document, the DID Methods document link doesn’t resolve.See https://w3c.github.io/did-extensions/#extensions@msporny",
    "content": "URL: https://github.com/w3c/did-extensions/issues/585In the Extensions document, the DID Methods document link doesn’t resolve.See https://w3c.github.io/did-extensions/#extensions@msporny"
  },
  
  {
    "title": "Support Verification in SDK - Anoncreds",
    "url": "/github-discussions/credential-schemas/23/",
    "categories": "decentralized-identity",
    "tags": "credential-schemas",
    "date": "2024-11-05 09:54:02 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-schemas/issues/23No content available",
    "content": "URL: https://github.com/decentralized-identity/credential-schemas/issues/23No content available"
  },
  
  {
    "title": "Fix mac-os build",
    "url": "/github-discussions/credential-schemas/21/",
    "categories": "decentralized-identity",
    "tags": "credential-schemas",
    "date": "2024-11-04 05:41:24 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-schemas/issues/21See https://github.com/hyperledger/indy-cli-rs/pull/20",
    "content": "URL: https://github.com/decentralized-identity/credential-schemas/issues/21See https://github.com/hyperledger/indy-cli-rs/pull/20"
  },
  
  {
    "title": "The authenticator may hide the credential even if the RP signals unknown credentials",
    "url": "/github-discussions/webauthn/2192/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-10-30 02:03:05 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2192Proposed ChangeIn the spec, there are some description and recommendation how the authenticator handles signal APIs.Currently, in many parts, there a...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2192Proposed ChangeIn the spec, there are some description and recommendation how the authenticator handles signal APIs.Currently, in many parts, there are description like this.  WebAuthn Relying Parties may use these signal methods to inform authenticators of the state of public key credentials, so that incorrect or revoked credentials may be updated, removed, or hidden.The authenticator may decide not to remove the credential at the time of receiving the signal and it may remove it after certain amount of time passes. It implies that the credential would not delete the credential and for some reasons the hidden credential would be changed to active credential.In the case of the user directly goes through the authenticator dedicated UI and then delete the credential, it would not be reported to the RP and which causes credential mismatch. So, for this case, the authenticator would hide the credential if the user deletes the credential through menu and it would be restored depending on some cases, and it would still work without any issue.For this scenario, the hidden feature might be a good choice as an authenticator to prevent the credential is accidentally removed so that the user avoid user lock out case.However, for the signal APIs, RP indicates that the acceptable credentials with an intention, so It would be better for authenticators to delete or update credentials if it is required to meet the original requirement (synchronization between authenticators and RP)."
  },
  
  {
    "title": "Question API: Send Presentation without pres_ex_id or with connection_id",
    "url": "/github-discussions/acapy/3321/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-10-29 15:17:14 -0700",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/issues/3321Hi there,I am using aca-py for my master’s thesis and trying to achieve the trust between user and my system.What I am trying to achie...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/issues/3321Hi there,I am using aca-py for my master’s thesis and trying to achieve the trust between user and my system.What I am trying to achieve is to expose the system’s VC to the user’s wallet so they can be sure that they have connected with the right entity.Is there a way to send VC presentation without needing a request first?Thanks in advance!"
  },
  
  {
    "title": "Multitenancy support for OID4VC plugin",
    "url": "/github-discussions/acapy-plugins/1161/",
    "categories": "openwallet-foundation",
    "tags": "acapy-plugins",
    "date": "2024-10-28 07:14:18 -0700",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy-plugins/issues/1161Currently, the OID4VC plugin doesn’t support multitenancy, and all operations are saved in the base wallet. When we secure the...",
    "content": "URL: https://github.com/openwallet-foundation/acapy-plugins/issues/1161Currently, the OID4VC plugin doesn’t support multitenancy, and all operations are saved in the base wallet. When we secure the admin API, the supported credentials data is not passed on to the .well-known endpoint for the OID4VCI server.We have reviewed the initial design options and have started work on enabling multitenancy for the OID4VC plugin.The following changes are proposed:  Pass wallet information to the OID4VC server. This can be done by:          Creating a separate sub-path for each wallet and hosting all endpoints within that sub-path, e.g., &lt;OID4VCI-Endpoint&gt;/&lt;wallet-id&gt;, using it for identification; or      Passing the wallet ID as a request parameter, e.g., &lt;OID4VCI-Endpoint&gt;/.well-known/openid-credential-issuer?&lt;wallet-id&gt;.        Use the sub-path or request parameter to pass wallet information when issuing the credential offer.We’re opening this issue to gather feedback from maintainers and other OID4VC developers to finalize the design and continue the work. cc: @dbluhm, @jamshale"
  },
  
  {
    "title": "Remove authenticatorDisplayName from L3",
    "url": "/github-discussions/webauthn/2187/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-10-23 12:06:50 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2187Discussed at TPAC as well as the 2024-10-23 call.  Remove authenticatorDisplayName from credProps for Level 3  Address the use case in Level 4 via ht...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2187Discussed at TPAC as well as the 2024-10-23 call.  Remove authenticatorDisplayName from credProps for Level 3  Address the use case in Level 4 via https://github.com/w3c/webauthn/issues/2157Relevant Issues and PRs:  https://github.com/w3c/webauthn/pull/2163  https://github.com/w3c/webauthn/pull/1880  https://github.com/w3c/webauthn/issues/2156  https://github.com/w3c/webauthn/pull/2005"
  },
  
  {
    "title": "Improve Infrastructure provisioning",
    "url": "/github-discussions/identus/76/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-10-21 07:31:35 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/76Short DescriptionImprove the infrastructure provisioning by reducing the amount of services that are bundled by default + making those easier to...",
    "content": "URL: https://github.com/hyperledger/identus/issues/76Short DescriptionImprove the infrastructure provisioning by reducing the amount of services that are bundled by default + making those easier to configure and not require any specific SH configuration script. On top of that we also aim to make everything deployable from a single docker image and not require too many images.Value statementMain goal behind this EPIC is to make our services easier to configure and maintain over time. For existing users, this will improve code maintenance and reduce the time spent on configuring the services and for our new users this will make it extremely easier to kick-off your project in Identus ecosystem. We mainly aim to reduce friction when it comes to configuring the services and get everything configured to start developing code.ComponentsCloud AgentTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "DID management component discussion",
    "url": "/github-discussions/identus/75/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-10-21 07:18:04 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/75The reason for this discussion is there is a need for a better did management component.As part of this discussion the following is purposed:  S...",
    "content": "URL: https://github.com/hyperledger/identus/issues/75The reason for this discussion is there is a need for a better did management component.As part of this discussion the following is purposed:  Separate Plutos DID Management side into a more flexible protocol.  Make the DID management data more common, aka: instead of having a different storage for PrismDID and PeerDID have a storage for DIDs.  Make a DID Management default component that is capable of manage (search, create, update, delete) DIDs and is components in the database.Then make this component available within PrismAgent."
  },
  
  {
    "title": "VCDM Improvements Phase 1: Standardize our implementation of 1.1 ",
    "url": "/github-discussions/identus/73/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-10-21 07:15:57 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/73Short DescriptionWe need to change the schemaId from being an  strings vs array of object, and the field should also be replaced by another fiel...",
    "content": "URL: https://github.com/hyperledger/identus/issues/73Short DescriptionWe need to change the schemaId from being an  strings vs array of object, and the field should also be replaced by another fieldName, from “schemaId” to “credentialSchema”Value statementTBDComponents  OAS  SDKsTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "`@protected` creates unresolvable conflicts when the same term is defined in two contexts top-level",
    "url": "/github-discussions/json-ld-syntax/443/",
    "categories": "w3c",
    "tags": "json-ld-syntax",
    "date": "2024-10-19 02:53:21 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/json-ld-syntax/issues/443I’ve just encountered issue #424 (and the related #361 as well) and in a similar situation with https://www.w3.org/ns/controller/v1 defining als...",
    "content": "URL: https://github.com/w3c/json-ld-syntax/issues/443I’ve just encountered issue #424 (and the related #361 as well) and in a similar situation with https://www.w3.org/ns/controller/v1 defining alsoKnownAs top-level alongside @protected: true, while https://www.w3.org/ns/activitystreams defines alsoKnownAs in a different namespace (as: vs sec:, loosely)From controller/v1:{  \"@context\": {    \"@protected\": true,    \"id\": \"@id\",    \"type\": \"@type\",    \"alsoKnownAs\": {      \"@id\": \"https://w3id.org/security#alsoKnownAs\",      \"@type\": \"@id\",      \"@container\": \"@set\"    },//...From activitystreams:{  \"@context\": {    \"@vocab\": \"_:\",    \"xsd\": \"http://www.w3.org/2001/XMLSchema#\",    \"as\": \"https://www.w3.org/ns/activitystreams#\",// ...\"alsoKnownAs\": {      \"@id\": \"as:alsoKnownAs\",      \"@type\": \"@id\"    }// ...Putting activitystreams before controller/v1 causes the later definition to override the older one, as expected (but not as desired):{  \"@context\": [\"https://www.w3.org/ns/activitystreams\", \"https://www.w3.org/ns/controller/v1\"],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // sec:alsoKnownAs}[  {    \"https://w3id.org/security#alsoKnownAs\": [  // should be https://www.w3.org/ns/activitystreams#alsoKnownAs      {        \"@id\": \"https://person.example\"      }    ],    \"@id\": \"http://person.example\",    \"@type\": [      \"https://www.w3.org/ns/activitystreams#Person\"    ]  }]But putting activitystreams after controller/v1 triggers the error due to @protected: true:{  \"@context\": [\"https://www.w3.org/ns/controller/v1\",  // uses @protected\"https://www.w3.org/ns/activitystreams\"  // will trigger the redefinition error],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"}jsonld.SyntaxError: Invalid JSON-LD syntax; tried to redefine a protected term.JSON-LD 1.1 4.1.11 Protected term definitions https://www.w3.org/TR/json-ld11/#protected-term-definitions describes two exceptions. The first exception is when the definition is the same, which is not applicable here. The second exception is for property-scoped context definitions, which is unworkable because in this case the singular top-level object is intended to be both an Actor as well as a Controller Document.To veryify, here’s a type-scoped context definition that errors out:{  \"@context\": [    \"https://www.w3.org/ns/controller/v1\",     {       \"Person\": {         \"@id\": \"https://www.w3.org/ns/activitystreams#Person\",         \"@context\": {           \"alsoKnownAs\": {  // triggers the redefinition error             \"@id\": \"https://www.w3.org/ns/activitystreams#alsoKnownAs\"           }         }       }     }],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"}And to reiterate, a property-scoped context definition can’t be used because the alsoKnownAs property is top-level. So the way I see it, there’s nothing that can be done to resolve this in a “plain JSON” compatible way except:  a) convince whoever is responsible for controller/v1 to remove @protected: true  b) convince whoever is responsible for controller/v1 to redefine alsoKnownAs with the activitystreams-namespaced @id instead of the security-namespaced one  c) write my own context documentThis leads me to think that @protected is a generally poorly-thought-out mechanism that highly increases the likelihood of such conflicts. Without it, as a producer I could just redefine the term later, for example by putting the activitystreams context last, or by using a local context object that comes after both remote contexts:{  \"@context\": [  \"https://www.w3.org/ns/controller/v1\",  // needs to remove @protected  \"https://www.w3.org/ns/activitystreams\"  // as:alsoKnownAs will override controller/v1's sec:alsoKnownAs],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // as:alsoKnownAs}or{  \"@context\": [\"https://www.w3.org/ns/activitystreams\",  // defines as:alsoKnownAs\"https://www.w3.org/ns/controller/v1\",  // redefines sec:alsoKnownAs as @protected {\"alsoKnownAs\": {  \"@id\": \"https://www.w3.org/ns/activitystreams#alsoKnownAs\",  // won't work unless controller/v1 removes @protected  \"@type\": \"@id\"}}],  \"type\": \"Person\",  \"id\": \"http://person.example\",  \"alsoKnownAs\": \"https://person.example\"  // as:alsoKnownAs}I’m not sure the existence of @protected accomplishes its stated goal of “prevent[ing] this divergence of interpretation”, nor that the rationale “that “plain JSON” implementations, relying on a given specification, will only traverse properties defined by that specification” is sufficiently addressing the issue of conflicts (or that it is a valid assumption in the first place). The issue arises when two specifications define the same term, and both specifications apply to the current object or document. It effectively leads to a hard incompatibility where it is impossible to implement both specs fully; you have to pick between them.If there’s an option I’m not aware of I’d like to hear it."
  },
  
  {
    "title": "`--base-wallet-routes` flag no longer works",
    "url": "/github-discussions/acapy/3283/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-10-11 10:16:41 -0700",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/issues/3283After the swap to using decorators to delineate routes accessible by tenants and routes accessible by admins, the ability to grant acc...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/issues/3283After the swap to using decorators to delineate routes accessible by tenants and routes accessible by admins, the ability to grant access to the base wallet to additional routes was lost.This option made it possible for a base wallet to form a didcomm connection with a mediator and then use that as a base mediator for all tenants, among other things.cc @esune @jamshale"
  },
  
  {
    "title": "[[Get]] method doesn't exist in CredMan",
    "url": "/github-discussions/webauthn/2169/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-10-01 07:40:46 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2169§5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method appears to reference a [[Get]] internal metho...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2169§5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method appears to reference a [[Get]] internal method on the Credential interface from CredMan, but no such internal method exists (unlike [[Create]], which does exist). Rather, [[DiscoverFromExternalSource]] is the actual internal method we override.Proposed Change  Delete the heading §5.1.4.1. PublicKeyCredential’s [[DiscoverFromExternalSource]](origin, options, sameOriginWithAncestors) Method (without changing any of the text around it).  Rename the heading §5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [[Get]](options) Method to 5.1.4. Use an Existing Credential to Make an Assertion - PublicKeyCredential’s [DiscoverFromExternalSource] Internal Method.  For consistency, change “Method” to “Internal Method” in the heading §5.1.3. Create a New Credential - PublicKeyCredential’s [[Create]](origin, options, sameOriginWithAncestors) Method.  Similarly, change “Method” to “Internal Method” in the heading §5.1.5. Store an Existing Credential - PublicKeyCredential’s [[Store]](credential, sameOriginWithAncestors) Method."
  },
  
  {
    "title": "Question about query parameter ordering",
    "url": "/github-discussions/did-core/865/",
    "categories": "w3c",
    "tags": "did-core",
    "date": "2024-09-25 05:50:27 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/did-core/issues/865I am looking for guidance on query parameter ordering, specifically where a DID URL with a query parameter might be used as an IDIn many systems such ...",
    "content": "URL: https://github.com/w3c/did-core/issues/865I am looking for guidance on query parameter ordering, specifically where a DID URL with a query parameter might be used as an IDIn many systems such as ActivityPub, an ID is basically an opaque string but in practice it is a URL whose structure gives a hint on how to resolve it, like using an HTTPS URL that resolves to the object.I am in the process of trying to implement did:web for activitystreams object IDs inside of an ActivityPub project, but this would I think equally apply to service IDs in the DID document: How do I deal with query parameters being seemingly unordered if some things rely on IDs equally matching? Is anyone dealing with this in their projects?"
  },
  
  {
    "title": "Bit set by the SPC extension should backed up as part of the Public Key Credential Source",
    "url": "/github-discussions/webauthn/2153/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-09-24 18:04:28 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2153PLACEHOLDERProposed ChangeBit set by the SPC extension should backed up as part of the Public Key Credential Source.",
    "content": "URL: https://github.com/w3c/webauthn/issues/2153PLACEHOLDERProposed ChangeBit set by the SPC extension should backed up as part of the Public Key Credential Source."
  },
  
  {
    "title": "Add `challengeUrl`",
    "url": "/github-discussions/webauthn/2152/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-09-24 15:26:51 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2152WebAuthn challenges usually need to be fetched from the server. This introduces extra latency, especially in cases where the page is loaded from offl...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2152WebAuthn challenges usually need to be fetched from the server. This introduces extra latency, especially in cases where the page is loaded from offline storage and apps. This extra latency delays when WebAuthn credentials can be shown to the user in an empty allow-list request.Proposed ChangeAdd a challengeUrl parameter that lets authenticators (or user agents) asynchronously fetch the challenge. This would let browsers render the list of credentials before the challenge comes back, improving the user experience. Add feature detection for it.This obsoletes issue #1856."
  },
  
  {
    "title": "authenticatorDisplayName should use a localizable language map",
    "url": "/github-discussions/webauthn/2151/",
    "categories": "w3c",
    "tags": "webauthn",
    "date": "2024-09-24 14:39:54 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/webauthn/issues/2151Related to #1644Proposed ChangeauthenticatorDisplayName is currently a DOMString and does not support localization, specifically language codes and d...",
    "content": "URL: https://github.com/w3c/webauthn/issues/2151Related to #1644Proposed ChangeauthenticatorDisplayName is currently a DOMString and does not support localization, specifically language codes and direction.Change to a map following the String Meta spec: https://www.w3.org/TR/string-meta/#language-maps\"authenticatorDisplayName\": {    \"en\":    {\"value\": \"This is English\"},    \"en-GB\": {\"value\": \"This is UK English\", \"dir\": \"ltr\"},    \"fr\":    {\"value\": \"C'est français\", \"lang\": \"fr-CA\", \"dir\": \"ltr\"},    \"ar\":    {\"value\": \"هذه عربية\", \"dir\": \"rtl\"}}"
  },
  
  {
    "title": "Test roadmap item",
    "url": "/github-discussions/identus/61/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-09-19 06:27:35 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/61Short DescriptionNew cool featureValue statementEnable new awesome solutionsArchitectPersonQA MemberPersonComponentsSDKs, Cloud AgentTeam member...",
    "content": "URL: https://github.com/hyperledger/identus/issues/61Short DescriptionNew cool featureValue statementEnable new awesome solutionsArchitectPersonQA MemberPersonComponentsSDKs, Cloud AgentTeam membersx, y, z @essbante-io  task 1  task 2"
  },
  
  {
    "title": "did:tdw resolver",
    "url": "/github-discussions/acapy/3237/",
    "categories": "openwallet-foundation",
    "tags": "acapy",
    "date": "2024-09-16 15:01:14 -0700",
    





    
    "snippet": "URL: https://github.com/openwallet-foundation/acapy/pull/3237  Uses the trustdidweb-py library to implement the resolver.  Plugs the resolve endpoint and library into the base_resolver class for ca...",
    "content": "URL: https://github.com/openwallet-foundation/acapy/pull/3237  Uses the trustdidweb-py library to implement the resolver.  Plugs the resolve endpoint and library into the base_resolver class for caching and future other resolution."
  },
  
  {
    "title": "Making Abstract abstract, instead of introduction",
    "url": "/github-discussions/vc-data-model/1560/",
    "categories": "w3c",
    "tags": "vc-data-model",
    "date": "2024-09-11 08:34:20 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/vc-data-model/pull/1560pulled from #1554Preview | Diff",
    "content": "URL: https://github.com/w3c/vc-data-model/pull/1560pulled from #1554Preview | Diff"
  },
  
  {
    "title": "[Expo SDK 52][Android] failing with CMake Error at CMakeLists.txt:30 (add_library):",
    "url": "/github-discussions/indy-vdr/324/",
    "categories": "hyperledger",
    "tags": "indy-vdr",
    "date": "2024-08-29 09:38:05 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/indy-vdr/issues/324After adding the @hyperledger/aries-askar-react-native facing issue in building the package in expo version 52 in androidCMake Error at CMakeL...",
    "content": "URL: https://github.com/hyperledger/indy-vdr/issues/324After adding the @hyperledger/aries-askar-react-native facing issue in building the package in expo version 52 in androidCMake Error at CMakeLists.txt:30 (add_library):    Target \"ariesaskarreactnative\" links to target    \"ReactAndroid::reactnativejni\" but the target was not found.  Perhaps a    find_package() call is missing for an IMPORTED target, or an ALIAS target    is missing?"
  },
  
  {
    "title": "npm install fails",
    "url": "/github-discussions/identus-edge-agent-sdk-ts/273/",
    "categories": "hyperledger",
    "tags": "identus-edge-agent-sdk-ts",
    "date": "2024-08-25 16:32:42 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-edge-agent-sdk-ts/issues/273Is this a regression?YesDescriptionDoesn’t install happily on a fresh install with npm. Seems to be some typedoc version prob...",
    "content": "URL: https://github.com/hyperledger/identus-edge-agent-sdk-ts/issues/273Is this a regression?YesDescriptionDoesn’t install happily on a fresh install with npm. Seems to be some typedoc version problems in your repoPlease provide the exception or error you saw➜  ATALA cd test➜  test npm init -yWrote to /home/fakename/projects/ATALA/test/package.json:{  \"name\": \"test\",  \"version\": \"1.0.0\",  \"description\": \"\",  \"main\": \"index.js\",  \"scripts\": {    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"  },  \"keywords\": [],  \"author\": \"\",  \"license\": \"ISC\"}➜  test npm i @hyperledger/identus-edge-agent-sdknpm WARN deprecated inflight@1.0.6: This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.npm WARN deprecated rimraf@2.7.1: Rimraf versions prior to v4 are no longer supportednpm WARN deprecated glob@7.2.3: Glob versions prior to v9 are no longer supportednpm WARN deprecated text-encoding@0.7.0: no longer maintainednpm ERR! code 1npm ERR! path /home/fakename/projects/ATALA/test/node_modules/@hyperledger/identus-edge-agent-sdknpm ERR! command failednpm ERR! command sh -c sh preinstall.shnpm ERR! running preinstall in /home/fakename/projects/ATALA/test/node_modules/@hyperledger/identus-edge-agent-sdknpm ERR! npm ERR! code ERESOLVEnpm ERR! npm ERR! ERESOLVE unable to resolve dependency treenpm ERR! npm ERR!npm ERR! npm ERR! While resolving: @hyperledger/identus-edge-agent-sdk@6.0.0npm ERR! npm ERR! Found: typedoc@0.25.13npm ERR! npm ERR! node_modules/typedocnpm ERR! npm ERR!   dev typedoc@\"^0.25.6\" from the root projectnpm ERR! npm ERR!npm ERR! npm ERR! Could not resolve dependency:npm ERR! npm ERR! peer typedoc@\"&gt;=0.26 &lt;2.0\" from typedoc-plugin-external-module-map@2.1.0npm ERR! npm ERR! node_modules/typedoc-plugin-external-module-mapnpm ERR! npm ERR!   dev typedoc-plugin-external-module-map@\"^2.0.1\" from the root projectnpm ERR! npm ERR!npm ERR! npm ERR! Fix the upstream dependency conflict, or retrynpm ERR! npm ERR! this command with --force or --legacy-peer-depsnpm ERR! npm ERR! to accept an incorrect (and potentially broken) dependency resolution.Please provide the environment you discovered this bug in➜  node -vv20.10.0➜  npm -v10.2.3Anything else?:cry:"
  },
  
  {
    "title": "Typos in docs",
    "url": "/github-discussions/dpv/184/",
    "categories": "w3c",
    "tags": "dpv",
    "date": "2024-08-24 10:03:12 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/dpv/issues/184The quick start docs are showing typos.https://github.com/hyperledger/identus-docs/blame/ad4c0a07d4cdb2ca8c369e6dd40e4bd2db2084fc/documentation/docs/quick-...",
    "content": "URL: https://github.com/w3c/dpv/issues/184The quick start docs are showing typos.https://github.com/hyperledger/identus-docs/blame/ad4c0a07d4cdb2ca8c369e6dd40e4bd2db2084fc/documentation/docs/quick-start.md#L655"
  },
  
  {
    "title": "Add capability to choose either polling or websocket",
    "url": "/github-discussions/dpv/183/",
    "categories": "w3c",
    "tags": "dpv",
    "date": "2024-08-24 09:58:44 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/dpv/issues/183Proposed featureAdd possibility to choose the mediator connection either from pulling or websocket. Default (if no argument is passed) when starting the co...",
    "content": "URL: https://github.com/w3c/dpv/issues/183Proposed featureAdd possibility to choose the mediator connection either from pulling or websocket. Default (if no argument is passed) when starting the connection to the mediator, should be WS if availableFeature descriptionEnable user to choose the message receival mechanismAnything else?No response"
  },
  
  {
    "title": "Link in the CONTRIBUTING.md is broken",
    "url": "/github-discussions/dpv/182/",
    "categories": "w3c",
    "tags": "dpv",
    "date": "2024-08-15 01:22:02 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/dpv/issues/182Is this a regression?NoDescriptionSteps:  Got to https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/master/CONTRIBUTING.md  Click on the lin...",
    "content": "URL: https://github.com/w3c/dpv/issues/182Is this a regression?NoDescriptionSteps:  Got to https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/master/CONTRIBUTING.md  Click on the link on the line 53 “1. Follow all instructions in the template”  It will open this browser window: https://github.com/input-output-hk/atala-prism-wallet-sdk-ts/blob/main/.github/PULL_REQUEST_TEMPLATE.mdPlease provide the exception or error you sawThe error is that the file does not exist: 404 - page not foundThe master branch of atala-prism-wallet-sdk-ts does not contain the path CONTRIBUTING.md.Please provide the environment you discovered this bug inOn the GitHub remote site (corresponding to latest version v5.0.0), master branch.Anything else?No"
  },
  
  {
    "title": "I am not able to add v7.0.0 as a working dependency, 6.1.1 works",
    "url": "/github-discussions/dpv/180/",
    "categories": "w3c",
    "tags": "dpv",
    "date": "2024-08-08 07:38:47 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/dpv/issues/180Is this a regression?YesDescriptionIf I add v7.0.0 as a Package Dependency, it never fully resolves, leaving me in a state where I can’t link it to my targ...",
    "content": "URL: https://github.com/w3c/dpv/issues/180Is this a regression?YesDescriptionIf I add v7.0.0 as a Package Dependency, it never fully resolves, leaving me in a state where I can’t link it to my target, or import it into Swift files.This works fine with v6.1.1Please provide the exception or error you sawWhen adding the Swift SDK as a Package Dependency, it should resolve all the packages and it should show the display name of the package.  The package list should allow me to open each package and see its contents. This does not happen with v7.0.0 for me.v6.1.1 works fine.Please provide the environment you discovered this bug inUsing from the 7.0.0 Tag in Xcode Package Dependency screenAnything else?Here is how my Package Dependency screen looks when I tag it to 7.0.0:You can see that the packages aren’t fully resolved:v6.1.1 works fine, shows up as it’s name “EdgeAgentSDK” (not the slug name) :And 6.1.1 can be found when I add it to my Target, 7.0.0 does not load fully so it’s not available to this menu."
  },
  
  {
    "title": "Wallet recovery with a password-protected backup file (from a single point of failure to 2FA) in addition to Seed Phrase Recovery",
    "url": "/github-discussions/bbs-signature/322/",
    "categories": "decentralized-identity",
    "tags": "bbs-signature",
    "date": "2024-08-05 15:36:40 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/bbs-signature/issues/322Proposed featureWe propose to contribute to this repository to add a functionality to recover a wallet through a password-prot...",
    "content": "URL: https://github.com/decentralized-identity/bbs-signature/issues/322Proposed featureWe propose to contribute to this repository to add a functionality to recover a wallet through a password-protected backup file.We’ve already implemented this on the Socious Wallet.Demos:Backup wallet flow:https://drive.google.com/file/d/1ae7t0MfNhgFz4FKy3LfLVfibYimfUgR8/view?usp=drivesdkRestore wallet with a password-protected backup file flow:https://drive.google.com/file/d/1qXmEhtN3Z4IEPWdSzdVmRTUZgeOI-mwj/view?usp=drivesdkProblem: The reliance on seed phrase-based wallet recovery is hindering mass adoption.The widespread adoption of blockchain wallets is significantly hindered by the use of seed phrases for wallet recovery. Seed phrases, also known as recovery or mnemonic phrases, are a list of words required to recover a blockchain wallet. This applies to both crypto wallets for token transactions and identity wallets for managing Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). For security reasons, this phrase must be kept confidential[^1^].Backgrounds on seed phrasesSince a private key consists of random binaries, it’s not human-readable, so it must be stored digitally. However, due to hacking risks, BIP39 was created to allow these keys to be written down on paper[^2^].However, the seed phrase being a single point of failure poses several challenges. Firstly, users may forget their seed phrases or misplace the physical copy containing it[^3^]. Secondly, if another person acquires the seed phrase, they can access the wallet and its funds[^4^]. Lastly, non-technical users may find the concept of a seed phrase difficult to comprehend and manage[^5^].These challenges are discussed in several sources. For instance, [this Cointelegraph article](https://cointelegraph.com/learn/how-to-recover-a-crypto-wallet) states that seed phrase recovery is a hindrance to mass adoption: “As the Web3 space looks to onboard its first billion users, intuitive wallet experiences are critical. Seed phrases are a hindrance to that experience.” In addition, [this Blockworks article](https://blockworks.co/news/what-are-seed-phrases) states that seed phrases have become a “major pain point for users”.Currently, the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) only supports wallet recovery based on seed phrases. This limitation hinders mass adoption.Alternatives to seed phrase-based recovery:Two primary alternatives to seed phrase-based recovery exist: social recovery and multifactor recovery involving backup files. Social recovery, which has been endorsed by Ethereum co-founder Vitalik Buterin[^1^], utilizes trusted contacts to help users regain access to their accounts. A prominent example of a wallet employing this method is the Argent wallet[^2^].On the other hand, multifactor recovery involves the use of backup files in addition to other authentication measures. Wallets using this method are rare, especially within the Cardano ecosystem. However, some examples do exist outside of it. For instance, the [Dock.io](http://dock.io/) identity wallet uses a recovery system involving a password-protected backup file[^3^]. Our plan includes implementing a similar solution to enhance the security and user experience of our wallet.See also:https://wirexapp.com/https://www.cypherock.com/features/no-backuphttps://medium.com/@bitizenwallet/private-keys-single-point-of-failure-a20b5f00a67dSolution: We improve the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase.The solution aims to address the vulnerability of seed phrases by enhancing the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase. Essentially, this wallet eliminates a single point of failure through the use of two-factor authentication, i.e., a password and a backup file. Consequently, even if someone acquires your backup file, they can’t decrypt it without your password. Similarly, a password alone is useless without access to your backup file. Moreover, you can always change your password. Implementing two-factor authentication for recovery significantly improves both security and user experience.Wallets with multi-factor authentication are rare, but they do exist outside the Cardano ecosystem. For example, the [Dock.io](http://dock.io/) identity wallet uses a recovery system with a [password-protected backup file](https://drive.google.com/file/d/1qatflQ6aDrQOqx8QlBtda5GlnILuckyV/view?usp=drive_link). We plan to implement a similar solution.Specifically, we will contribute to the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) repository. We aim to add new features without affecting the existing wallet recovery feature which uses seed phrases. The new features include the following:  Users do not see seed phrases when creating a wallet.  Users see an alert: “Please secure your wallet by backing up the wallet”.  Users select a secure password to encrypt the backup file.  Users have the freedom to save the backup file wherever they prefer, including on an external hard drive or cloud.  Users can restore a wallet by decrypting the backup file with the password.This plan has been discussed with IOG’s Atala PRISM team. They have confirmed that this improvement is not part of their roadmap and would welcome this additional feature to the SDK.This solution allows projects in the Cardano ecosystem to create their own wallets using this SDK. They can use a password-protected backup file for wallet recovery. This method is not only user-friendly but also secure. It will contribute to the widespread adoption of identity wallets and Self-Sovereign Identity.With this enhanced SDK, we’ll boost Socious Wallet’s security by shifting from seed phrase recovery to multifactor file backup recovery. This will let end-users enjoy the advantages of SSI, DID, and VC without the complexity of managing seed phrases or the risk of a single point of failure. Upon completion of this project, users will have a secure identity wallet on their iOS and Android mobile devices without the need to manage seed phrases.Feature descriptionWe propose to contribute to this repository to add a functionality to recover a wallet through a password-protected backup file.We’ve already implemented this on the Socious Wallet.Demos:Backup wallet flow:https://drive.google.com/file/d/1ae7t0MfNhgFz4FKy3LfLVfibYimfUgR8/view?usp=drivesdkRestore wallet with a password-protected backup file flow:https://drive.google.com/file/d/1qXmEhtN3Z4IEPWdSzdVmRTUZgeOI-mwj/view?usp=drivesdkProblem: The reliance on seed phrase-based wallet recovery is hindering mass adoption.The widespread adoption of blockchain wallets is significantly hindered by the use of seed phrases for wallet recovery. Seed phrases, also known as recovery or mnemonic phrases, are a list of words required to recover a blockchain wallet. This applies to both crypto wallets for token transactions and identity wallets for managing Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs). For security reasons, this phrase must be kept confidential[^1^].Backgrounds on seed phrasesSince a private key consists of random binaries, it’s not human-readable, so it must be stored digitally. However, due to hacking risks, BIP39 was created to allow these keys to be written down on paper[^2^].However, the seed phrase being a single point of failure poses several challenges. Firstly, users may forget their seed phrases or misplace the physical copy containing it[^3^]. Secondly, if another person acquires the seed phrase, they can access the wallet and its funds[^4^]. Lastly, non-technical users may find the concept of a seed phrase difficult to comprehend and manage[^5^].These challenges are discussed in several sources. For instance, [this Cointelegraph article](https://cointelegraph.com/learn/how-to-recover-a-crypto-wallet) states that seed phrase recovery is a hindrance to mass adoption: “As the Web3 space looks to onboard its first billion users, intuitive wallet experiences are critical. Seed phrases are a hindrance to that experience.” In addition, [this Blockworks article](https://blockworks.co/news/what-are-seed-phrases) states that seed phrases have become a “major pain point for users”.Currently, the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) only supports wallet recovery based on seed phrases. This limitation hinders mass adoption.Alternatives to seed phrase-based recovery:Two primary alternatives to seed phrase-based recovery exist: social recovery and multifactor recovery involving backup files. Social recovery, which has been endorsed by Ethereum co-founder Vitalik Buterin[^1^], utilizes trusted contacts to help users regain access to their accounts. A prominent example of a wallet employing this method is the Argent wallet[^2^].On the other hand, multifactor recovery involves the use of backup files in addition to other authentication measures. Wallets using this method are rare, especially within the Cardano ecosystem. However, some examples do exist outside of it. For instance, the [Dock.io](http://dock.io/) identity wallet uses a recovery system involving a password-protected backup file[^3^]. Our plan includes implementing a similar solution to enhance the security and user experience of our wallet.See also:https://wirexapp.com/https://www.cypherock.com/features/no-backuphttps://medium.com/@bitizenwallet/private-keys-single-point-of-failure-a20b5f00a67dSolution: We improve the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase.The solution aims to address the vulnerability of seed phrases by enhancing the Atala identity wallet SDK to allow wallet recovery using a password-protected backup file instead of a seed phrase. Essentially, this wallet eliminates a single point of failure through the use of two-factor authentication, i.e., a password and a backup file. Consequently, even if someone acquires your backup file, they can’t decrypt it without your password. Similarly, a password alone is useless without access to your backup file. Moreover, you can always change your password. Implementing two-factor authentication for recovery significantly improves both security and user experience.Wallets with multi-factor authentication are rare, but they do exist outside the Cardano ecosystem. For example, the [Dock.io](http://dock.io/) identity wallet uses a recovery system with a [password-protected backup file](https://drive.google.com/file/d/1qatflQ6aDrQOqx8QlBtda5GlnILuckyV/view?usp=drive_link). We plan to implement a similar solution.Specifically, we will contribute to the [Atala PRISM Identity Wallet SDK](https://github.com/input-output-hk/atala-prism-wallet-sdk-ts) repository. We aim to add new features without affecting the existing wallet recovery feature which uses seed phrases. The new features include the following:  Users do not see seed phrases when creating a wallet.  Users see an alert: “Please secure your wallet by backing up the wallet”.  Users select a secure password to encrypt the backup file.  Users have the freedom to save the backup file wherever they prefer, including on an external hard drive or cloud.  Users can restore a wallet by decrypting the backup file with the password.This plan has been discussed with IOG’s Atala PRISM team. They have confirmed that this improvement is not part of their roadmap and would welcome this additional feature to the SDK.This solution allows projects in the Cardano ecosystem to create their own wallets using this SDK. They can use a password-protected backup file for wallet recovery. This method is not only user-friendly but also secure. It will contribute to the widespread adoption of identity wallets and Self-Sovereign Identity.With this enhanced SDK, we’ll boost Socious Wallet’s security by shifting from seed phrase recovery to multifactor file backup recovery. This will let end-users enjoy the advantages of SSI, DID, and VC without the complexity of managing seed phrases or the risk of a single point of failure. Upon completion of this project, users will have a secure identity wallet on their iOS and Android mobile devices without the need to manage seed phrases.Anything else?No response"
  },
  
  {
    "title": "Failed deployment is shown as successful",
    "url": "/github-discussions/did-resolution/80/",
    "categories": "w3c",
    "tags": "did-resolution",
    "date": "2024-07-29 09:04:08 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/did-resolution/issues/80In order to deploy the docs corresponding to prism v2.9, https://github.com/input-output-hk/atala-releases/blob/master/Atala%20PRISM/2.9.md, I ha...",
    "content": "URL: https://github.com/w3c/did-resolution/issues/80In order to deploy the docs corresponding to prism v2.9, https://github.com/input-output-hk/atala-releases/blob/master/Atala%20PRISM/2.9.md, I have chosen the wrong version (OEA version instead of the documentation version).In https://github.com/input-output-hk/atala-prism-docs/actions, click on Deployment and then Run workflowI chose: main branch, v1.25.0 and production and click Run workflow.It gave a successful deployment when looking after but the docs.atalaprism.io was still not updated as it showed in API –&gt; Agent API the same old version v1.22.0. See attached screenshot.The expectation is that as the workflow failed, the status should show as failed. If you look at the workflow file, there is no information that would give any indication of what was run.If you look at the https://github.com/input-output-hk/atala-prism-docs/actions/runs/7959863521/job/21727672596 , there is no information on the parsing of the version for example."
  },
  
  {
    "title": "Adding concepts from the EU General-Purpose AI Code of Practice",
    "url": "/github-discussions/tswg-keri-specification/199/",
    "categories": "trustoverip",
    "tags": "tswg-keri-specification",
    "date": "2024-07-13 22:41:43 -0700",
    





    
    "snippet": "URL: https://github.com/trustoverip/tswg-keri-specification/issues/199Adding concepts from the EU General-Purpose AI Code of Practice upon its publication (expected to be published  in April 2025).",
    "content": "URL: https://github.com/trustoverip/tswg-keri-specification/issues/199Adding concepts from the EU General-Purpose AI Code of Practice upon its publication (expected to be published  in April 2025)."
  },
  
  {
    "title": "Adding labels and triage process",
    "url": "/github-discussions/dwn-user-guide/3/",
    "categories": "decentralized-identity",
    "tags": "dwn-user-guide",
    "date": "2024-07-10 10:51:17 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/dwn-user-guide/issues/3Is your feature request related to a problem? Please describe.As the number of contributors is growing, the number of issues is...",
    "content": "URL: https://github.com/decentralized-identity/dwn-user-guide/issues/3Is your feature request related to a problem? Please describe.As the number of contributors is growing, the number of issues is growing. We need a triage process with a labelling system in place.Describe the solution you’d likeLabels to be added in contributing.md (or another file that will be referred in contributing triage part) in Identus repo.Each label should have a prefix: for example:  Type: bug, docs, enhancement, support, research, maintenance, chore, ci, refactor, perf, test  Priority: critical, major, normal, minor  Component: cloud-agent, infrastructure, mediator, edge-agent-SDK-swift, edge-agent-SDK-KMP, edge-agent-SDK-TS, node, VDR, …  Team: marketing, product, engineering, management, dev-ops, security  Triage: needs-repro, needs-fix, stale, good-first-issue/up-for-graps, help-wanted, question/query, tech-debt  Closed: out-of-scope, can’t-repro, duplicate, won’t-fix, design-limitation  Status: new, ready, in-review, in-progress, fixed, qa-ready, qa-progress, qa-support (to indicate QA team needs support), stale, done/closed/terminatedColors for labels should follow a rule to be described.Each label should have a description associated to it.All Identus repos will use the same labels.Triage process needs to be written down: Have a look at Identus Technical Charter as reference first.Describe alternatives you’ve consideredWe need to check if the status are labels or customised fields.Best practices to be looked at as well so the solution is practical.Additional contextThe triage should be efficient and regularly done (recommendation is every 2 days) and it should be linked closely to the release process and cadence.Follow: https://docs.github.com/en/issues/using-labels-and-milestones-to-track-work/managing-labelsUse Conventional commit to match some labels"
  },
  
  {
    "title": "Threat model / Trust over IP introduction",
    "url": "/github-discussions/dwn-user-guide/2/",
    "categories": "decentralized-identity",
    "tags": "dwn-user-guide",
    "date": "2024-07-10 10:48:23 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/dwn-user-guide/issues/2(With caveat that I’m writing this after having read only from start to the end of section 2.2.4, and read the last use-case, a...",
    "content": "URL: https://github.com/decentralized-identity/dwn-user-guide/issues/2(With caveat that I’m writing this after having read only from start to the end of section 2.2.4, and read the last use-case, and that perhaps somewhere in between lies the key to this issue. If that is the case, it means that the key needs to be brought earlier. If not, disregard the caveat and proceed to reading the below as though I had finished proof-reading the entire doc.)If the Threat Model summarized in the last use-case is of importance, I suggest it be more clearly stated.It is introduced at the very end of section 2.2.4 by a Note that says “W3C is handling this issue with a Threat Model.” (which is problematic as it implies endorsement; see #1 )But then the use case merely summarizes a 35-page document that lacks a clear standing and is hosted elsewhere.There is a discrepancy between the implied endorsement of a threat model and a use-case which summarizes what appears to be introductory slides from 2021.If the threat model that is summarized is what the W3C Team recommends “W3C as an org” considers to handle the issue, then it needs to be framed in such a way. Furthermore, for the recommendation to have teeth, the reader has to understand the path W3C would take to handle the issue and to trust the threat model’s standing.Also “the issue” is unclear. Re-reading again section 2.2.4, it appears that “the issue” is [from the first “note” in this section] “enabling this technological innovation by being aware of the threats to Privacy, security, and Human Rights”, where “this technological innovation” refers to “digital identities and credentials”."
  },
  
  {
    "title": "Add the identus release process",
    "url": "/github-discussions/credential-schemas/4/",
    "categories": "decentralized-identity",
    "tags": "credential-schemas",
    "date": "2024-07-03 16:27:23 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-schemas/issues/4Is your feature request related to a problem? Please describe.Identus is an eco-system and the release process should be de...",
    "content": "URL: https://github.com/decentralized-identity/credential-schemas/issues/4Is your feature request related to a problem? Please describe.Identus is an eco-system and the release process should be described in this repository. Explaining who and what steps are being followed.See ATL-7060 as well.Describe the solution you’d likeMake a release vx.y:  Go to Identus repo hyperledger/identus  Check the latest release version; it should be Identus va.b format. E.g Identus v2.12.  Click on Release and Draft a new release button          In Choose a tag button, create the tag vx.y      Target = main      Previous tag Auto        Click on Generate change log: this will generate the log for this repository only, which should be reviewed.  Fill the release note in this change log,          Copy the template (from the previous release if a template file is not existing yet)      For each component, add the change log according to each component (it should be already available from the component release).      Select Set as a pre-release and click on Save Draft        Ask component owner to review: this is the critical step. The release owner should get an approval from each of the component: Cloud Agent, Edge Agent SDK Swift, KMP, TS, Mediator, Node, Docs.Note: This is not that convenient as having a PR where all can contribute: see alternatives considered  Ask QA team to validate the release by confirming there is no regression and critical bugs have been fixed.  Once all component owners have accepted (with a check in the release note? TBC)), publish the release by editing it and unselect Set as a pre-release and click on Publish release button: the release Identus vx.y should be seen as the latest; if not, fix it.Describe alternatives you’ve considered  Previously, we have a file and a PR was submitted for review. See atala-releases.  We should have a nice way to get the feedback from the component owners, maybe with a checkbox in the release.Or a PR can be actually raise, with the checkbox that all the component owners have reviewed. Only then, the release is accepted. We shall have also the QA team to validate the eco-system.  Using automated release would be a nice follow-up iteration.Additional contextUntil Identus v2.12, the release was done as a PR in another repository: https://github.com/input-output-hk/atala-releases"
  },
  
  {
    "title": "Implement user level events in SDKs",
    "url": "/github-discussions/identus/22/",
    "categories": "hyperledger",
    "tags": "identus",
    "date": "2024-07-03 06:27:43 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus/issues/22No content available",
    "content": "URL: https://github.com/hyperledger/identus/issues/22No content available"
  },
  
  {
    "title": "Simplify abstract data model to be more concrete",
    "url": "/github-discussions/did-core/855/",
    "categories": "w3c",
    "tags": "did-core",
    "date": "2024-07-01 06:07:19 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/did-core/issues/855It has been suggested that the abstract data model in DID Core creates unnecessary complexity and that a more concrete data model should be selected, ...",
    "content": "URL: https://github.com/w3c/did-core/issues/855It has been suggested that the abstract data model in DID Core creates unnecessary complexity and that a more concrete data model should be selected, based on implementation experience over the past two years. This issue is to track the discussion of how that simplification might occur."
  },
  
  {
    "title": "DWN (Decentralized Web Node)",
    "url": "/github-discussions/linked-vp/53/",
    "categories": "decentralized-identity",
    "tags": "linked-vp",
    "date": "2024-06-30 05:28:40 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/linked-vp/issues/53Is your feature request related to a problem? Please describe.Expanding Identus capabilities through seamless connectivity with dec...",
    "content": "URL: https://github.com/decentralized-identity/linked-vp/issues/53Is your feature request related to a problem? Please describe.Expanding Identus capabilities through seamless connectivity with decentralized web nodes, enabling a versatile and distributed self-sovereign identity ecosystem.Describe the solution you’d likeIntegrating Identus agents with decentralized web nodes enhances the self-sovereign identity ecosystem by offering diverse features and functionality across multiple DID methods and verifiable credential formats. Our Users benefit from an enriched experience with expanded capabilities such as integrated payments, autonomous credential exchange based on defined ACLs and rules, and customizable interfaces and hooks. For example, machine learning and artificial intelligence are moving towards intelligent Identus agents. This versatile solution fosters a more resilient, distributed, and innovative identity management platform that caters to the evolving needs of the decentralized web.  #54  #55  #56  #57  #58  #59"
  },
  
  {
    "title": "Should there be a registry? Process to migrate to a W3C Registry?",
    "url": "/github-discussions/did-extensions/565/",
    "categories": "w3c",
    "tags": "did-extensions",
    "date": "2024-06-27 08:52:48 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/did-extensions/issues/565Please share your ideas.",
    "content": "URL: https://github.com/w3c/did-extensions/issues/565Please share your ideas."
  },
  
  {
    "title": "URI in Profile triggers CORS Unsafe Request Header Byte rule",
    "url": "/github-discussions/json-ld-syntax/436/",
    "categories": "w3c",
    "tags": "json-ld-syntax",
    "date": "2024-06-24 14:08:08 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/json-ld-syntax/issues/436In the IANA registration [1], we define a media type parameter called ‘profile’. Its value is a space separated list of URIs, for which we regis...",
    "content": "URL: https://github.com/w3c/json-ld-syntax/issues/436In the IANA registration [1], we define a media type parameter called ‘profile’. Its value is a space separated list of URIs, for which we registered six initial values. These can be composed together, and new values can be added for other “constraints or conventions”.The IIIF specifications use this functionality, for example to define the specific structure of the response in an API [2] as part of the media type. Similarly in Linked Art, we do the same [3].However, in the WHATWG specification for fetch [4], it says that the value for the Accept header is NOT CORS safe, if it has more than 128 bytes (which multiple URIs might easily cause) or (more importantly) if the value contains an unsafe header byte. The unsafe header bytes include the character “:” … which prevents any URI or CURIE with a namespace prefix separate by : from being CORS safe.This means that we cannot use the JSON-LD media type as registered for content negotiation via the accept header according to the fetch specification, which was much of the rationale for the profile parameter.To resolve this, either WHATWG would need to change fetch, or W3C/IANA would need to change the definition of the media type and give some registration function for possible profile values, then all downstream specifications would need to register a safe profile value to use.I’ve added the tag-needs-resolution label, as I think that’s the level this would need to run up to :([1] https://www.w3.org/TR/json-ld11/#iana-considerations[2] https://iiif.io/api/presentation/3.0/#63-responses [3] https://linked.art/api/1.0/json-ld/#introduction[4] https://fetch.spec.whatwg.org/#ref-for-cors-unsafe-request-header-byte"
  },
  
  {
    "title": "List of Adopters",
    "url": "/github-discussions/credential-schemas/1/",
    "categories": "decentralized-identity",
    "tags": "credential-schemas",
    "date": "2024-06-18 19:36:22 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-schemas/issues/1Is your feature request related to a problem? Please describe.For newcomers would be nice to know what else is out there th...",
    "content": "URL: https://github.com/decentralized-identity/credential-schemas/issues/1Is your feature request related to a problem? Please describe.For newcomers would be nice to know what else is out there that is already using Identus.Describe the solution you’d likeWould be nice to have a list of specific applications that adopted and using this technology/libraries.Can be real applications are just demos.Additional contextThis question was mention on the end of the Identus Community outreach call meeting (2024/04/23)"
  },
  
  {
    "title": "Test",
    "url": "/github-discussions/spec-up/65/",
    "categories": "decentralized-identity",
    "tags": "spec-up",
    "date": "2024-06-11 09:45:29 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/spec-up/issues/65Short DescriptiontestValue statementtestComponentstestTeam memberstestArchitectNo responseQA MemberNo responseOwnertest  #66  task 2 ...",
    "content": "URL: https://github.com/decentralized-identity/spec-up/issues/65Short DescriptiontestValue statementtestComponentstestTeam memberstestArchitectNo responseQA MemberNo responseOwnertest  #66  task 2  task 3"
  },
  
  {
    "title": "Pollux as a plugin interface and new credentials type plugins can be inserted into the Agent",
    "url": "/github-discussions/tswg-keri-specification/178/",
    "categories": "trustoverip",
    "tags": "tswg-keri-specification",
    "date": "2024-05-21 07:59:32 -0700",
    





    
    "snippet": "URL: https://github.com/trustoverip/tswg-keri-specification/issues/178Proposed featurePollux will become a plugin interface, this will enable more control over the available credentials type that c...",
    "content": "URL: https://github.com/trustoverip/tswg-keri-specification/issues/178Proposed featurePollux will become a plugin interface, this will enable more control over the available credentials type that can be used by the agent. It will as well enable developers to provide their own Plugins for credential types that are not by default supported by the Agent.Feature descriptionPollux will become more inline with a plugin interface. It will be adapted so each plugin as versioning and version support.Each plugin can identify itself and identify the application/types it supports.The agent will receive an array of Pollux plugins and pick the plugin that supports a type of credential to run the flow.Anything else?No response"
  },
  
  {
    "title": "An asynchronous issuance",
    "url": "/github-discussions/json-ld-syntax/432/",
    "categories": "w3c",
    "tags": "json-ld-syntax",
    "date": "2024-05-15 03:12:27 -0700",
    





    
    "snippet": "URL: https://github.com/w3c/json-ld-syntax/issues/432Hi,it might be out of the scope of this spec, it’s not a microservice, but asynchronous issuing is crucial in order to enable:  an approval proc...",
    "content": "URL: https://github.com/w3c/json-ld-syntax/issues/432Hi,it might be out of the scope of this spec, it’s not a microservice, but asynchronous issuing is crucial in order to enable:  an approval process - a process that might involve collecting additional information, checks, and even human involvement  optimal infrastructure utilization - e.g. a queue of requests scheduled to be processed on an issuer’s termsTo keep this spec simple, perhaps, simply allowing to return 202 Accepted code without specifying any further details, leaving the further interaction details on an implementer for now, could be enough to keep the issuance interface being used for advanced use-cases without a need to introduce a proprietary endpoint on issuer’s side."
  },
  
  {
    "title": "Timeout on OPTIONS (cors preflight)",
    "url": "/github-discussions/vc-api/383/",
    "categories": "w3c-ccg",
    "tags": "vc-api",
    "date": "2024-05-14 09:12:53 -0700",
    





    
    "snippet": "URL: https://github.com/w3c-ccg/vc-api/issues/383Seems like the mediator is responding like this:atala-prism-mediator-identus-mediator-1  | 2024-11-24_00:56:53.696 WARN  f.d.f.TransportDispatcher@L...",
    "content": "URL: https://github.com/w3c-ccg/vc-api/issues/383Seems like the mediator is responding like this:atala-prism-mediator-identus-mediator-1  | 2024-11-24_00:56:53.696 WARN  f.d.f.TransportDispatcher@L167:[ZScheduler-Worker-1] {version=1.0.0, msg_sha256=c4946137e7ddb36a3261fd6dfb6b0b4265280b0a3dfc91c3e449513dd2c7ed10} - zio-fiber-1940542155 No url to send messageo.h.i.m.DIDCommRoutes@L167:[ZScheduler-Worker-2] {version=1.0.0} - zio-fiber-1688384339 Request TimeoutFor a CORS check from the browser, this is causing Safari 18 to stop polling the endpoint since it triggers a CORS failureOther browsers seems to just ignore this timeout and work fine.In order for this bug to reproduce you need to run Safari 18 (Sequoia) on mediator v1.0.0."
  },
  
  {
    "title": "chore: upgrade package from AFJ to credo-ts",
    "url": "/github-discussions/didcomm-demo/76/",
    "categories": "decentralized-identity",
    "tags": "didcomm-demo",
    "date": "2024-05-07 06:43:52 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/didcomm-demo/pull/76  Replaced AFJ package with credo-ts across the codebase  Updated relevant imports and dependencies to ensure compatibility with c...",
    "content": "URL: https://github.com/decentralized-identity/didcomm-demo/pull/76  Replaced AFJ package with credo-ts across the codebase  Updated relevant imports and dependencies to ensure compatibility with credo-ts  Refactored code to align with any breaking changes or differences between AFJ and credo-ts Tested the changes to confirm that the upgrade works as expected without any issues."
  },
  
  {
    "title": "VCDM Improvements Phase 2: Add versioning to the API to support multiple versions at the same time",
    "url": "/github-discussions/didcomm-demo/74/",
    "categories": "decentralized-identity",
    "tags": "didcomm-demo",
    "date": "2024-05-06 04:09:29 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/didcomm-demo/issues/74Short DescriptionThis phase we integrate versioning support while we will still be using 1.1, we change the source to be able to...",
    "content": "URL: https://github.com/decentralized-identity/didcomm-demo/issues/74Short DescriptionThis phase we integrate versioning support while we will still be using 1.1, we change the source to be able to plug more modern versions of the spec soon.Value statementTBDComponents  OASTeam members@hyperledger/identusArchitect@hyperledger/identus-maintainersQA Member@hyperledger/identus-maintainersOwner@hyperledger/identus-maintainers"
  },
  
  {
    "title": "Tagging this repo",
    "url": "/github-discussions/org/37/",
    "categories": "decentralized-identity",
    "tags": "org",
    "date": "2024-04-20 18:16:24 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/org/issues/37The concept of tagging this repo came up on the Aries WG call on Nov. 15, 2023. I wanted to continue that discussion here:As prior art, c...",
    "content": "URL: https://github.com/decentralized-identity/org/issues/37The concept of tagging this repo came up on the Aries WG call on Nov. 15, 2023. I wanted to continue that discussion here:As prior art, consider this text from: https://github.com/hyperledger/aries-acapy-plugin-toolbox#aca-py-version-compatibility  ACA-Py Version Compatibility  To avoid a confusing pseudo-lock-step release, this plugin is versioned independent of ACA-Py. Plugin releases will follow standard semver but each release will also be tagged with a mapping to an ACA-Py version with the format acapy-X.Y.Z-J where X.Y.Z corresponds to the ACA-Py version supported and J is an incrementing number for each new plugin release that targets the same version of ACA-Py.  You should look for the most recent release tagged with the version of ACA-Py you are using (with the highest value for J).This was a convention that the toolbox plugin adopted (back when we were actively working on it). I think tagging the whole repo will be challenging to do meaningfully; for the toolbox plugin, we needed to keep track changes of the plugin itself as well as the versions of ACA-Py it was compatible with. The plugins should be able to evolve and gain features and be able to version themselves to communicate when new features are added."
  },
  
  {
    "title": "Minor Bug Fixes",
    "url": "/github-discussions/aries-vcx/1182/",
    "categories": "hyperledger",
    "tags": "aries-vcx",
    "date": "2024-04-18 22:37:21 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/aries-vcx/pull/1182In our testing, we’ve come across a few minor bugs that this PR intends to sort out",
    "content": "URL: https://github.com/hyperledger/aries-vcx/pull/1182In our testing, we’ve come across a few minor bugs that this PR intends to sort out"
  },
  
  {
    "title": "Separate \"Security and Privacy Considerations\"",
    "url": "/github-discussions/tswg-cesr-specification/91/",
    "categories": "trustoverip",
    "tags": "tswg-cesr-specification",
    "date": "2024-04-11 07:19:46 -0700",
    





    
    "snippet": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/91At the moment, the specification has a “Security and Privacy Considerations” section.In a W3C specification, these should be sep...",
    "content": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/91At the moment, the specification has a “Security and Privacy Considerations” section.In a W3C specification, these should be separated into a “Security Considerations” section and a “Privacy Considerations” section."
  },
  
  {
    "title": "Typo in appendix A: `eddsa-rdfc-2022` is wrongly named `edssa-2022`",
    "url": "/github-discussions/tswg-cesr-specification/90/",
    "categories": "trustoverip",
    "tags": "tswg-cesr-specification",
    "date": "2024-04-11 07:10:47 -0700",
    





    
    "snippet": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/90Hi, I think to have spotted a typo in the first paragraph of appendix A, where eddsa-rdfc-2022 is wrongly named edssa-2022. The ...",
    "content": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/90Hi, I think to have spotted a typo in the first paragraph of appendix A, where eddsa-rdfc-2022 is wrongly named edssa-2022. The link correctly points to eddsa-rdfc-2022."
  },
  
  {
    "title": "task 1",
    "url": "/github-discussions/spec-up/64/",
    "categories": "decentralized-identity",
    "tags": "spec-up",
    "date": "2024-04-08 22:47:46 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/spec-up/issues/64No content available",
    "content": "URL: https://github.com/decentralized-identity/spec-up/issues/64No content available"
  },
  
  {
    "title": "Problem reporting for the Agent and Mediator",
    "url": "/github-discussions/didcomm-book/20/",
    "categories": "decentralized-identity",
    "tags": "didcomm-book",
    "date": "2024-04-03 08:06:47 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/didcomm-book/issues/20No content available",
    "content": "URL: https://github.com/decentralized-identity/didcomm-book/issues/20No content available"
  },
  
  {
    "title": "Cloud Agent to publish PrismDID on behalf of external wallet into VDR",
    "url": "/github-discussions/org/33/",
    "categories": "decentralized-identity",
    "tags": "org",
    "date": "2024-03-23 12:27:01 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/org/issues/33Is your feature request related to a problem? Please describe.Currently, Cloud Agent can only publish PrismDIDs that are created by the s...",
    "content": "URL: https://github.com/decentralized-identity/org/issues/33Is your feature request related to a problem? Please describe.Currently, Cloud Agent can only publish PrismDIDs that are created by the same Cloud Agent into the VDR. Most Edge Clients will never be connected to a full node in order to publish their PrismDIDs to the VDR and it could be useful for certain use cases.Describe the solution you’d likeIt would be great to ask the Cloud Agent to publish a PrismDID created from my Edge Client Wallet through the REST API.Describe alternatives you’ve consideredAllowing the Edge SDK to connect directly to icarus (like the cloud agent does) and prepare the right payload which I would need to reverse engineer anyways from the cloud agent code :)"
  },
  
  {
    "title": "Bugfix: vc.credentialSubject.id, vc.issuer, iss, and sub should be DID itself",
    "url": "/github-discussions/aries-acapy-docs/99/",
    "categories": "hyperledger",
    "tags": "aries-acapy-docs",
    "date": "2024-03-22 07:55:16 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/aries-acapy-docs/pull/99[OID4VCI]credentialSubject.id, iss, and sub should be DID, not DID URLs pointing to verification methods.",
    "content": "URL: https://github.com/hyperledger/aries-acapy-docs/pull/99[OID4VCI]credentialSubject.id, iss, and sub should be DID, not DID URLs pointing to verification methods."
  },
  
  {
    "title": "OpenID4VP SD-JWT is not verifying the holder signature (KB-JWT)",
    "url": "/github-discussions/aries-vcx/1163/",
    "categories": "hyperledger",
    "tags": "aries-vcx",
    "date": "2024-03-22 04:12:01 -0700",
    





    
    "snippet": "URL: https://github.com/hyperledger/aries-vcx/issues/1163I believe the SD-JWT cred processor verify_presentation is not actually checking the holder’s signature (KB-JWT) on the presented SD-JWT. Me...",
    "content": "URL: https://github.com/hyperledger/aries-vcx/issues/1163I believe the SD-JWT cred processor verify_presentation is not actually checking the holder’s signature (KB-JWT) on the presented SD-JWT. Meaning the SD-JWT holder does not have to prove they are bound to the SD-JWT.I tested this locally by using a malicious client that intentionally malforms the signature bytes of the KB-JWT it produces. The acapy plugin still reported verified=true (credo reported verified=false with logs that indicate the signature was invalid).I believe this happens because:  verify_presentation calls sd_jwt_verify with only 2 params; profile, presentation: https://github.com/openwallet-foundation/acapy-plugins/blob/main/oid4vc/sd_jwt_vc/cred_processor.py#L205  sd_jwt_verify has 2 additional optional params, expected_aud &amp; expected_nonce. so verify_presentation sets those as None  sd_jwt_verify initializes SDJWTVerifierACAPy with those null values for self.expected_aud &amp; self.expected_nonce  sd_jwt_verify then calls SDJWTVerifierACAPy.verify(), which checks the SD-JWT VC signature, and then only IF if self.expected_aud or self.expected_nonce: does it check the KB JWT:     if self.expected_aud or self.expected_nonce:          if not (self.expected_aud and self.expected_nonce):              raise ValueError(                  \"Either both expected_aud and expected_nonce must be provided \"                  \"or both must be None\"              )          await self._verify_key_binding_jwt(              self.expected_aud,              self.expected_nonce,          )        meaning the KB-JWT signature (holder binding/proof) is not checked"
  },
  
  {
    "title": "Able to create an in-memory sqlite database?",
    "url": "/github-discussions/bbs-signature/318/",
    "categories": "decentralized-identity",
    "tags": "bbs-signature",
    "date": "2024-03-19 02:13:15 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/bbs-signature/issues/318From the python library is there a way to create an in-memory sqlite database?I see this https://github.com/hyperledger/aries-...",
    "content": "URL: https://github.com/decentralized-identity/bbs-signature/issues/318From the python library is there a way to create an in-memory sqlite database?I see this https://github.com/hyperledger/aries-askar/blob/main/askar-storage/src/backend/sqlite/provision.rs#L50 and will try and figure it out myself. Just posting this here is anyone knows off the to of their head.context: We’re trying to rely on askar fully in aca-py and remove the existing in-memory wallet that was created for testing. Having the option to create an in-memory wallet that is askar based would really help speed up the tests and prevent file IO errors."
  },
  
  {
    "title": "fix: indyNamespace",
    "url": "/github-discussions/universal-registrar/81/",
    "categories": "decentralized-identity",
    "tags": "universal-registrar",
    "date": "2024-03-18 09:21:41 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/universal-registrar/pull/81Fixes indy name spaces to get the issue credential flows working for the Indicio Testnet and Candy",
    "content": "URL: https://github.com/decentralized-identity/universal-registrar/pull/81Fixes indy name spaces to get the issue credential flows working for the Indicio Testnet and Candy"
  },
  
  {
    "title": "Running cargo test shows failure status for most of the test cases",
    "url": "/github-discussions/labs/7/",
    "categories": "decentralized-identity",
    "tags": "labs",
    "date": "2024-03-18 09:16:27 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/labs/issues/7Fork repository using main branch and clone it on my system. Then execute following:-cargo build =&gt; successfulcargo test =&gt; many te...",
    "content": "URL: https://github.com/decentralized-identity/labs/issues/7Fork repository using main branch and clone it on my system. Then execute following:-cargo build =&gt; successfulcargo test =&gt; many test cases reported failedBuild system : Fedora 38rustc version: rustc 1.72.0 (5680fa18f 2023-08-23)cargo version: cargo 1.72.0 (103a7ff2e 2023-08-15)"
  },
  
  {
    "title": "Link to identus-cloud-agent example / documentation",
    "url": "/github-discussions/labs/6/",
    "categories": "decentralized-identity",
    "tags": "labs",
    "date": "2024-03-18 09:16:02 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/labs/issues/6The “README - getting started” with plugin is not too actionable given it can’t do meaningful thing by itself alone. There should be a po...",
    "content": "URL: https://github.com/decentralized-identity/labs/issues/6The “README - getting started” with plugin is not too actionable given it can’t do meaningful thing by itself alone. There should be a pointer to identus-cloud-agent documentation / example where the plugin is actually used."
  },
  
  {
    "title": "NGrok setup for local use with indy tails server",
    "url": "/github-discussions/linked-vp/51/",
    "categories": "decentralized-identity",
    "tags": "linked-vp",
    "date": "2024-02-29 00:54:34 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/linked-vp/issues/51Using the startup instructions in:https://github.com/hyperledger/aries-endorser-service?tab=readme-ov-file#running-locallywon’t rea...",
    "content": "URL: https://github.com/decentralized-identity/linked-vp/issues/51Using the startup instructions in:https://github.com/hyperledger/aries-endorser-service?tab=readme-ov-file#running-locallywon’t really work as-is any more as Indy Tails Server needs the ngrok auth token as well. And if you use the same auth token in the 2 contexts  Indy Tails Server  Endorser ServiceYou will get the issue about simultaneous ngrok agent sessionsfrom docker-ngrok-endorser-agent container:2024-02-16 16:16:45 ERROR:  authentication failed: Your account is limited to 1 simultaneous ngrok agent session.2024-02-16 16:16:45 ERROR:  You can run multiple tunnels on a single agent session using a configuration file.2024-02-16 16:16:45 ERROR:  To learn more, see https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config/2024-02-16 16:16:45 ERROR:  2024-02-16 16:16:45 ERROR:  Active ngrok agent sessions in region 'us-cal-1':2024-02-16 16:16:45 ERROR:    - ts_2cTI2njhg4tmt7Qe1cltNsx3kxT (23.16.82.223)2024-02-16 16:16:45 ERROR:  2024-02-16 16:16:45 ERROR:  ERR_NGROK_1082024-02-16 16:16:45 ERROR:Not sure if we could adjust to have one environment that shares it, or at least need to adjust documentation."
  },
  
  {
    "title": "Consider if things should be switched over to Credo",
    "url": "/github-discussions/linked-vp/50/",
    "categories": "decentralized-identity",
    "tags": "linked-vp",
    "date": "2024-02-29 00:53:59 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/linked-vp/issues/50Instructions, git command to pull the repo, documentation, comments etc all refer to Aries-Framework-Javascript. This has been repl...",
    "content": "URL: https://github.com/decentralized-identity/linked-vp/issues/50Instructions, git command to pull the repo, documentation, comments etc all refer to Aries-Framework-Javascript. This has been replaced by the move to Credo-TS so Akrida should(?) reference that instead.As well imports in the package.json like @aries-framework/core, @aries-framework/node on 0.4.0 versions do not continue to be updated and the 0.5.x updates look to be released and updated under @credo-ts/node etc on npm."
  },
  
  {
    "title": "Issues handling didcomm message errors",
    "url": "/github-discussions/did-jwt/308/",
    "categories": "decentralized-identity",
    "tags": "did-jwt",
    "date": "2024-02-28 04:47:17 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/did-jwt/issues/308Is this a regression?YesDescriptionBriefWhen didcomm message returns a http status code other than ok the message becomes undefined ...",
    "content": "URL: https://github.com/decentralized-identity/did-jwt/issues/308Is this a regression?YesDescriptionBriefWhen didcomm message returns a http status code other than ok the message becomes undefined due a try-catch block. This issue’s goal is to enable an error management for didcomm errors.Spec: https://identity.foundation/didcomm-messaging/spec/#problem-reportsFetchApi.ts  async request&lt;T&gt;(    method: HttpMethod,    urlStr: string,    urlParameters: Map&lt;string, string&gt; = new Map(),    httpHeaders: Map&lt;string, string&gt; = new Map(),    body?: string | Record&lt;string, any&gt;  ): Promise&lt;ApiResponse&lt;T&gt;&gt; {    // ...    if (response.ok) {      return new ApiResponse(        data,        response.status,        response.statusText,        response.headers      );    }    throw new ApiError(response.status, response.statusText, data);}Mercury.ts  async sendMessageParseMessage(    message: Domain.Message  ): Promise&lt;Domain.Message | undefined&gt; {    const responseBody = await this.sendMessage&lt;any&gt;(message);    try {      const responseJSON = JSON.stringify(responseBody);      return await this.unpackMessage(responseJSON);    } catch (err) {      return undefined    }  }Any ApiError thrown will cause message to return undefined as per described in the Mercury.ts#sendMessageParseMessage methodPlease provide the exception or error you sawNo responsePlease provide the environment you discovered this bug inNo responseAnything else?No response"
  },
  
  {
    "title": "docs: connectionless proof",
    "url": "/github-discussions/vc-data-model/1448/",
    "categories": "w3c",
    "tags": "vc-data-model",
    "date": "2024-02-27 11:04:35 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/vc-data-model/pull/1448Base branch: https://github.com/hyperledger/identus-cloud-agent/pull/1447(merge first)See diff : https://github.com/hyperledger/identus-cloud-agen...",
    "content": "URL: https://github.com/w3c/vc-data-model/pull/1448Base branch: https://github.com/hyperledger/identus-cloud-agent/pull/1447(merge first)See diff : https://github.com/hyperledger/identus-cloud-agent/commit/b5efc5f62c12dc712458a58c38e0b43f26ae1251Adds  a page for connectionless proof  link in sidebar"
  },
  
  {
    "title": "SDJWT SDK to SDK Verification",
    "url": "/github-discussions/bbs-signature/315/",
    "categories": "decentralized-identity",
    "tags": "bbs-signature",
    "date": "2024-02-16 15:54:22 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/bbs-signature/issues/315Proposed featureOur aim is to bring verification capabilities across the different SDK platforms. We will do so by allowing Ed...",
    "content": "URL: https://github.com/decentralized-identity/bbs-signature/issues/315Proposed featureOur aim is to bring verification capabilities across the different SDK platforms. We will do so by allowing Edge Wallets to initiate a ProofRequest to a known Identifier (DID), also this same Edge wallet need to be capable of Generating the Proof and send it back. This would basically allow any Edge wallet to initiate and complete verification requests by itself with Credential Type SD JWT. As this is a Selective Disclosure JWT, during the verification process the Verifier will receive both the shared disclosures and the SD JWT Credential.User CasesHigh level description SD-JWT-Based Verifiable Credentials: An Introduction (criipto.com)Current Draft Spec https://datatracker.ietf.org/doc/draft-ietf-oauth-selective-disclosure-jwt/EBSI Spec https://hub.ebsi.eu/vc-framework/did/selective-disclosure-sd-jwtAge Verification: For services that require age verification, such as venues where entrants need to be over 18. Entrants can share their driving licence as verifiable presentation and security can receive on a mobile device and automatically confirm that they are over the age of 18 without actually disclosing their age.Voting Systems: In digital voting systems, edge wallets can store digital identities, allowing citizens to vote securely and anonymously, ensuring the integrity of the electoral process.Feature descriptionUsing Presentation exchange protocol we add the ability for any SDK Verifier to now request SDJWT Presentation with all the disclosure capabilities bundled in.The verification will only pass if the claims we asked have been provided by the user, and disclosed correctlyAnything else?No response"
  },
  
  {
    "title": "MySQL Support",
    "url": "/github-discussions/identus-edge-agent-sdk-ts/174/",
    "categories": "hyperledger",
    "tags": "identus-edge-agent-sdk-ts",
    "date": "2024-02-15 07:55:21 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-edge-agent-sdk-ts/issues/174Our team currently uses vdr-tools as the underlying framework to support AFJ on our mediator. The reasoning is better support...",
    "content": "URL: https://github.com/hyperledger/identus-edge-agent-sdk-ts/issues/174Our team currently uses vdr-tools as the underlying framework to support AFJ on our mediator. The reasoning is better support for concurrency, as well as MySQL support.We are now looking to upgrade AFJ to 0.4.x, and in by doing so upgrade to use Aries Askar etc.Askar only supports SqlLite and Postgres - is there a workaround so that we can continue using MySQL?"
  },
  
  {
    "title": "About resolving protocol question",
    "url": "/github-discussions/tswg-cesr-specification/60/",
    "categories": "trustoverip",
    "tags": "tswg-cesr-specification",
    "date": "2024-02-15 07:49:35 -0800",
    





    
    "snippet": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/60Hi, I’ve been following did for a long time, I want to know besides HTTP (s) + JSON, is there any plan to support COAP + CBOR fo...",
    "content": "URL: https://github.com/trustoverip/tswg-cesr-specification/issues/60Hi, I’ve been following did for a long time, I want to know besides HTTP (s) + JSON, is there any plan to support COAP + CBOR for did resolution ?"
  },
  
  {
    "title": "fix: Kafka consumer not picking messages",
    "url": "/github-discussions/vc-data-model/1441/",
    "categories": "w3c",
    "tags": "vc-data-model",
    "date": "2024-02-15 05:31:14 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/vc-data-model/pull/1441No content available",
    "content": "URL: https://github.com/w3c/vc-data-model/pull/1441No content available"
  },
  
  {
    "title": "Migration to new AnonCreds object format",
    "url": "/github-discussions/credential-trust-establishment/35/",
    "categories": "decentralized-identity",
    "tags": "credential-trust-establishment",
    "date": "2024-02-12 10:05:40 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/35ACA-Py will eventually move a feature that is currently experimental to ready-for-use status: AnonCreds RS sup...",
    "content": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/35ACA-Py will eventually move a feature that is currently experimental to ready-for-use status: AnonCreds RS support. With this change, the migration strategy used in the wallet upgrade tool will require tweaks to migrate an Indy wallet to the new AnonCreds format.Is this something we should worry about? It should be technically possible to upgrade using this tool as is and then use the upgrade endpoint @jamshale is working on in https://github.com/hyperledger/aries-cloudagent-python/pull/2922.cc: @swcurran"
  },
  
  {
    "title": "Many errors in rocksdb/_rocksdb.pyx cause build failure",
    "url": "/github-discussions/uni-resolver-driver-did-key/9/",
    "categories": "decentralized-identity",
    "tags": "uni-resolver-driver-did-key",
    "date": "2024-02-06 23:19:56 -0800",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/uni-resolver-driver-did-key/issues/9The first error is:/tmp/pip-build-clvy4twe/python-rocksdb/.eggs/Cython-3.0.8-py3.5.egg/Cython/Compiler/Main.py:381...",
    "content": "URL: https://github.com/decentralized-identity/uni-resolver-driver-did-key/issues/9The first error is:/tmp/pip-build-clvy4twe/python-rocksdb/.eggs/Cython-3.0.8-py3.5.egg/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /tmp/pip-build-clvy4twe/python-rocksdb/rocksdb/_rocksdb.pyxAfter that, there are hundreds of errors in the module — many referencing a missing “gil”."
  },
  
  {
    "title": "DIDComm Message Decryption + Disruption by `eth_getLogs`/`eth_getChainId` calls",
    "url": "/github-discussions/vc-data-model/1432/",
    "categories": "w3c",
    "tags": "vc-data-model",
    "date": "2024-02-03 10:43:05 -0800",
    





    
    "snippet": "URL: https://github.com/w3c/vc-data-model/issues/1432ProblemIn our use case we are decrypting didcomm messages within the context of our custom MetaMask Snap. This process is quite time consuming (...",
    "content": "URL: https://github.com/w3c/vc-data-model/issues/1432ProblemIn our use case we are decrypting didcomm messages within the context of our custom MetaMask Snap. This process is quite time consuming (up to approx. 100 seconds). Our specific use case does not invoke calls to the network, however, Veramo (via the provider) does invoke the eth_getLogs and eth_getChainId calls using ethers. In the case of their failure (i.e. in the case the RPC provider comes back with an error, for example, a rate limit), the long running decryption process (i.e. the decryption) is interrupted. Therefore, there are two components to this issue we are facing:  Decryption Time: Why would the decryption take so long? In our case decrypting the DIDComm message (jwe encoded) takes around or over 100 seconds;  Error Handling/Unnecessary Calls: Where calls to the network are not required, such as the case described above, what is the case for these calls?SolutionAs it relates to the decryption time any feedback or insight you can provide on the matter is greatly appreciated. As it pertains to the provider calls on eth_getChainId and eth_getLogs errors bubbling up and cancelling the other processes - even when the aforementioned calls do not appear to be required - it would appear that these could be deactivated.Other QuestionsAny information you can provide on this is greatly appreciated. If we can align on the solution, we would be happy to present a PR, but wanted to sync up here first.ScreenshotExample of offending calls within the background.html in the MetaMask Snap. "
  },
  
  {
    "title": "Missing MAINTAINERS.md",
    "url": "/github-discussions/identus-cloud-agent/864/",
    "categories": "hyperledger",
    "tags": "identus-cloud-agent",
    "date": "2024-01-25 01:23:55 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/864Is this a regression?NoDescriptionAs part of Hyperledger - we MUST have a MAINTAINERS.md file (as per https://toc.hyperledger.org/g...",
    "content": "URL: https://github.com/hyperledger/identus-cloud-agent/issues/864Is this a regression?NoDescriptionAs part of Hyperledger - we MUST have a MAINTAINERS.md file (as per https://toc.hyperledger.org/guidelines/MAINTAINERS-guidelines.html)The repository is currently missing this file, we must create this file and populate according to the expecations defined in the guidelinesSome content may already be defined in other files in the repositor (from CONTRIBUTING.md)Please provide the exception or error you sawN/APlease provide the environment you discovered this bug inN/AAnything else?No response"
  },
  
  {
    "title": "Support DID Exchange Protocol",
    "url": "/github-discussions/aries-acapy-docs/93/",
    "categories": "hyperledger",
    "tags": "aries-acapy-docs",
    "date": "2024-01-09 10:41:08 -0800",
    





    
    "snippet": "URL: https://github.com/hyperledger/aries-acapy-docs/issues/93  Support only did:peer  Swift did:peer library: https://github.com/beatt83/peerdid-swift  Will not support public DID",
    "content": "URL: https://github.com/hyperledger/aries-acapy-docs/issues/93  Support only did:peer  Swift did:peer library: https://github.com/beatt83/peerdid-swift  Will not support public DID"
  },
  
  {
    "title": "Unclear use of `tag` in key derivation and wrapping algorithm",
    "url": "/github-discussions/presentation-exchange/457/",
    "categories": "decentralized-identity",
    "tags": "presentation-exchange",
    "date": "2023-11-02 11:00:26 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/presentation-exchange/issues/457I don’t understand how to use a tag in key derivation/wrapping algorithm as described in sections:  5.1.9 ECDH-1PU key...",
    "content": "URL: https://github.com/decentralized-identity/presentation-exchange/issues/457I don’t understand how to use a tag in key derivation/wrapping algorithm as described in sections:  5.1.9 ECDH-1PU key wrapping and common protected headers  5.1.10 ECDH-ES key wrapping and common protected headersThere is a mention“As per this requirement, the JWE building must first encrypt the payload, then use the resulting tag as part of the key derivation process when wrapping the cek.”But I don’t see any information on how that tag should be used in derivation of kek  or wrapping of cek with kek. Am I missing something?"
  },
  
  {
    "title": "Rewrite PRISM node",
    "url": "/github-discussions/veramo-plugin/28/",
    "categories": "decentralized-identity",
    "tags": "veramo-plugin",
    "date": "2023-10-29 10:01:48 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/veramo-plugin/issues/28No content available",
    "content": "URL: https://github.com/decentralized-identity/veramo-plugin/issues/28No content available"
  },
  
  {
    "title": "Error handling and Problem reporting for SDKs",
    "url": "/github-discussions/didcomm-demo/19/",
    "categories": "decentralized-identity",
    "tags": "didcomm-demo",
    "date": "2023-10-03 10:34:16 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/didcomm-demo/issues/19No content available",
    "content": "URL: https://github.com/decentralized-identity/didcomm-demo/issues/19No content available"
  },
  
  {
    "title": "Update maintainers `w3cid` value in documents",
    "url": "/github-discussions/traceability-interop/589/",
    "categories": "w3c-ccg",
    "tags": "traceability-interop",
    "date": "2023-08-23 06:13:40 -0700",
    





    
    "snippet": "URL: https://github.com/w3c-ccg/traceability-interop/issues/589Hi @apuchitnis @stenreijers @gatemezing @adam-burns @Steffytan @MizukiSonoko @rajivrajani @genaris @ajile-in and @KDean-Dolphin,Public...",
    "content": "URL: https://github.com/w3c-ccg/traceability-interop/issues/589Hi @apuchitnis @stenreijers @gatemezing @adam-burns @Steffytan @MizukiSonoko @rajivrajani @genaris @ajile-in and @KDean-Dolphin,Publication of did-extensions is currently failing because some of you don’t have w3cid values listed in your Editor’s entry in each specification. I need each of you to update your w3cid value in the “Editors” section of each document listed below:  https://github.com/w3c/did-extensions/blob/main/index.html#L54-L95  https://github.com/w3c/did-extensions/blob/main/methods/index.html#L95-L136  https://github.com/w3c/did-extensions/blob/main/properties/index.html#L54-L96  https://github.com/w3c/did-extensions/blob/main/resolution/index.html#L54-L96If you don’t have a free w3.org account, you can get one here:https://www.w3.org/account/request/You can then see your w3cid value by logging into w3.org and going to this link:https://www.w3.org/users/myprofile/The value will be in the URL in your web browser address bar. For example, when I go to the URL above, I get redirected to this URL (and my w3cid value is 41758):https://www.w3.org/users/41758/Just raise a PR on all four documents above and I’ll merge them as they come in."
  },
  
  {
    "title": "Identus Cloud Agent Scalability - Background Jobs",
    "url": "/github-discussions/credential-trust-establishment/18/",
    "categories": "decentralized-identity",
    "tags": "credential-trust-establishment",
    "date": "2023-08-21 10:44:33 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/18This Epic aims to investigate ZIO Stream and ZIO Kafka as a replacement for the mechanism behind the execution...",
    "content": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/18This Epic aims to investigate ZIO Stream and ZIO Kafka as a replacement for the mechanism behind the execution of background jobs.Currently, each background job is a recurrent ZIO effect created using ZIO#repeat that processes a configurable number of records in parallel during each iteration. This will inevitably lead to conflicts and race conditions as soon as we run two instances of the cloud agent in parallel, as the same record will be processed by those two agents sharing the same DB. The related flows will be executed multiple times, and the same DIDComm message will be sent several times to the DIDComm peer.This can be solved using a message queueing system like Kafka and leveraging Kafka’s consumer groups capability to concurrently distribute the load among multiple agent instances.At a later stage, using a queuing mechanism like Kafka would allow us to better control - and allocate resources to - the execution of the resource-intensive tasks that put pressure on the system (e.g., generation of AnonCreds credential definitions via the Rust library)."
  },
  
  {
    "title": "User can backup and restore Wallet (KMM)",
    "url": "/github-discussions/credential-trust-establishment/8/",
    "categories": "decentralized-identity",
    "tags": "credential-trust-establishment",
    "date": "2023-05-25 15:58:54 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/8Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable develo...",
    "content": "URL: https://github.com/decentralized-identity/credential-trust-establishment/issues/8Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/ARelease notes -Prism documentation - Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/ARelease notes -Prism documentation - Context | Functionality for backup and restoring wallet data will be available in the KMM SDK– | –Enable developers to create wallets that will allow the secure backup and restoration of wallets including all of the wallet dataS&amp;T TBDWe believe that -for wallet users  we will provide functionality to allow them to easily and securely backup and restore their wallet (and its data)and we’ll know this is true when we see:Users can easily backup their wallet (and its data) as an encrypted backup file Users can install a wallet on another device and using the seed can restore their wallet (and its data) Wallet data is encrypted to backup and includes keys, credentials, messages, dids, did-pairsWallet data is decrypted and restored from backup and includes keys, credentials, messages, dids, did-pairsBDD ExampleScenario: Backup wallet data as an encrypted file Given the user has a wallet with data (keys, credentials, messages, dids, did-pairs) When the user initiates a backup operation Then the wallet data is encrypted And saved as a backup file  Scenario: Restore wallet data from an encrypted backup file using a seed Given the user has an encrypted wallet backup file And the user has the seed for the wallet When the user initiates a restore operation on another device Then the wallet data is decrypted And the wallet (including keys, credentials, messages, dids, did-pairs) is restored accurately  Scenario: Validate encryption of wallet data during backup Given the user initiates a backup operation for their wallet When the backup file is created Then the backup file should not be readable without proper decryption And include all wallet data (keys, credentials, messages, dids, did-pairs)  Scenario: Validate decryption and integrity of wallet data during restoration Given the user has an encrypted backup file and the correct seed When the user restores the wallet on a new device Then all wallet data (keys, credentials, messages, dids, did-pairs) is decrypted and restored accurately And matches the original wallet’s data before backup  Scenario: Security of the backup file Given the user has created a backup file of their wallet When an unauthorized person accesses the backup file Then they should not be able to decrypt the wallet data without the seedN/A "
  },
  
  {
    "title": "Error handling for the Agent",
    "url": "/github-discussions/SIG-IoT/17/",
    "categories": "decentralized-identity",
    "tags": "SIG-IoT",
    "date": "2023-03-15 10:24:28 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/SIG-IoT/issues/17Although PRISM already has some errors defined and returned by our Cloud Agent RestAPI calls, we do not have any mechanism to handle ...",
    "content": "URL: https://github.com/decentralized-identity/SIG-IoT/issues/17Although PRISM already has some errors defined and returned by our Cloud Agent RestAPI calls, we do not have any mechanism to handle and report errors when they are happening during record processing or sending/receiving DIDComm messages. It is required to implement a mechanism of error handling for Cloud Agent to log, update records in the database, and report errors in the right way.  hyperledger/identus-edge-agent-sdk-ts/issues/308"
  },
  
  {
    "title": "Infinite loop in Release process",
    "url": "/github-discussions/did-resolver/97/",
    "categories": "decentralized-identity",
    "tags": "did-resolver",
    "date": "2021-08-30 02:14:56 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/did-resolver/issues/97Go to https://handbook.atalaprism.io/engineering/sdlc/release/release-process-overview.And go at the bottom of the page. The lin...",
    "content": "URL: https://github.com/decentralized-identity/did-resolver/issues/97Go to https://handbook.atalaprism.io/engineering/sdlc/release/release-process-overview.And go at the bottom of the page. The link on the right is Release process anew, so it is an infinite loop."
  },
  
  {
    "title": "Cleanup the GitHub workflows after moving to the GitHub pages",
    "url": "/github-discussions/did-jwt/194/",
    "categories": "decentralized-identity",
    "tags": "did-jwt",
    "date": "2021-08-24 21:51:03 -0700",
    





    
    "snippet": "URL: https://github.com/decentralized-identity/did-jwt/issues/194The workflow files should be cleaned up: the docker image with the documentation portal and the corresponding helm chart are not nee...",
    "content": "URL: https://github.com/decentralized-identity/did-jwt/issues/194The workflow files should be cleaned up: the docker image with the documentation portal and the corresponding helm chart are not needed anymore."
  }
  
]

